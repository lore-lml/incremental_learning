{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "IL_progressive_layers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "tvETQMX1ipNf",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1yCGTGds7yo29ypI-Mo6asXkSDrEDbLZH#scrollTo=wwN82ZV7ipNg\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab Account AI\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-LoM_h1IXAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "88d40673-26a0-4f56-a856-bc7c73e377b4"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "print(gpu.name)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "wwN82ZV7ipNg",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RSnex0bmipNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_ROOT = 'cifar-100-python'\n",
        "CODE_ROOT = 'libs'\n",
        "import os\n",
        "if not os.path.isdir(DATASET_ROOT):\n",
        "    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "    !tar -xf 'cifar-100-python.tar.gz'  \n",
        "    !rm -rf 'cifar-100-python.tar.gz'\n",
        "\n",
        "if not os.path.isdir(CODE_ROOT):\n",
        "  !git clone https://lore-lml:4d3df3df629abc4ffdc94c8a85591d294de89b2d@github.com/lore-lml/machine-learning2020-incremental_learning.git\n",
        "  !mv 'machine-learning2020-incremental_learning/libs' '.'\n",
        "  !rm -rf 'machine-learning2020-incremental_learning'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Subset\n",
        "from torch.backends import cudnn\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import libs.utils as utils\n",
        "\n",
        "from libs.variation.icarl_variation2 import iCaRLModel\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7W9y67yoipNk",
        "colab_type": "text"
      },
      "source": [
        "**SET ARGUMENTS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "r0hjWAP3ipNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "arguments = utils.get_arguments()\n",
        "\n",
        "DEVICE = arguments['DEVICE']\n",
        "NUM_CLASSES = arguments[\"NUM_CLASSES\"] \n",
        "\n",
        "BATCH_SIZE = arguments[\"BATCH_SIZE\"]        # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                                            # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = 2 #arguments[\"LR\"]                        # The initial Learning Rate\n",
        "MOMENTUM = arguments[\"MOMENTUM\"]            # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = arguments[\"WEIGHT_DECAY\"]    # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = arguments[\"NUM_EPOCHS\"]        # Total number of training epochs (iterations over dataset)\n",
        "GAMMA = arguments[\"GAMMA\"]                  # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = arguments[\"LOG_FREQUENCY\"]\n",
        "MILESTONES = arguments[\"MILESTONES\"]\n",
        "SEED = 1993 #arguments[\"SEED\"]\n",
        "\n",
        "CLASSIFY = \"wa\"\n",
        "LAYER = \"linear\"\n",
        "GAMMA_METHOD = 'multi'\n",
        "HERDING = True\n",
        "\n",
        "OUTPUT_PATH = f\"RUN1_PL+CE_{CLASSIFY}_{LAYER}_layer_\" + (\"herding_\" if HERDING else \"random\") + f\"seed{SEED}\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "SaT8eFDNipNm",
        "colab_type": "text"
      },
      "source": [
        "**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "m-ydAGw4ipNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transforms, eval_transforms = utils.get_train_eval_transforms()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "X7Naz_DdipNp",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "G-Xct5sNipNp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2a5d4b6f-4540-4e25-cc64-f227d0580699"
      },
      "source": [
        "train_val_dataset = utils.get_cifar_with_seed(DATASET_ROOT, train_transforms, src='train', seed=SEED)\n",
        "test_dataset = utils.get_cifar_with_seed(DATASET_ROOT, eval_transforms, src='test', seed=SEED)\n",
        "\n",
        "print(f\"Size Training Set: {len(train_val_dataset)}\")\n",
        "print(f\"Size Test Set: {len(test_dataset)}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size Training Set: 50000\n",
            "Size Test Set: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xZDP5yXBipNt",
        "colab_type": "text"
      },
      "source": [
        "**Train, Test, Validation functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "secPALBtipNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(net: iCaRLModel, test_loader, device=DEVICE):\n",
        "    # confusion matrix\n",
        "    y_true = []\n",
        "    y_preds = []\n",
        "\n",
        "    running_corrects = 0\n",
        "    for images, labels in tqdm(test_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        preds = net.classify(images, CLASSIFY)\n",
        "        \n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "        # confusion matrix\n",
        "        y_true.extend(labels.data.tolist())\n",
        "        y_preds.extend(preds.tolist())\n",
        "\n",
        "   \n",
        "    return running_corrects, y_true, y_preds\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "s5SroLpaipNw",
        "colab_type": "text"
      },
      "source": [
        "**iCaRL FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "clnGi_eLipNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def icarl_training(train_dataset, test_dataset, max_epoch=NUM_EPOCHS, device=DEVICE):\n",
        "    import time\n",
        "    \n",
        "    train_mean_accuracies = []\n",
        "    test_accuracies = []\n",
        "    \n",
        "    cudnn.benchmark\n",
        "    net = iCaRLModel(train_dataset, batch_size=BATCH_SIZE, device=DEVICE, layer=LAYER, gamma_method=GAMMA_METHOD)\n",
        "    incremental_test = []\n",
        "    start_time = time.time()\n",
        "    for stage in range(10):\n",
        "        print(f\"STARTING STAGE {stage+1}...\")\n",
        "        optimizer, scheduler = utils.get_otpmizer_scheduler(net.parameters(), LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA)\n",
        "        \n",
        "        train_idx_per_class, test_idx = utils.get_idxs_per_class_of_kth_batch(train_val_dataset, test_dataset, stage)\n",
        "        \n",
        "        # Make test set incremental\n",
        "        incremental_test.extend(np.ravel(test_idx))\n",
        "        images_per_class = [train_dataset.get_items_of(idx_per_class) for idx_per_class in train_idx_per_class]\n",
        "        train_idx = np.ravel(train_idx_per_class)\n",
        "        train_set, test_set = Subset(train_val_dataset, train_idx), Subset(test_dataset, incremental_test)\n",
        "        \n",
        "        _, train_accuracy = net.update_representation(train_set, optimizer, scheduler, max_epoch)\n",
        "        train_mean_accuracies.append(train_accuracy)\n",
        "        net.increment_known_classes()\n",
        "        \n",
        "        m = int(net.memory / net.known_classes)\n",
        "        distribute = net.memory % net.known_classes\n",
        "        ms = [m] * net.known_classes\n",
        "        for i in range(distribute):\n",
        "            ms[i] += 1\n",
        "        \n",
        "        assert sum(ms) == net.memory\n",
        "        \n",
        "        for i in range(net.known_classes-10):\n",
        "            net.reduce_exemplar_set(ms[i], i)\n",
        "        \n",
        "        i=0\n",
        "        for m, (imgs, labels), indexes in zip(ms[net.known_classes-10:], images_per_class, train_idx_per_class):\n",
        "            print(i)\n",
        "            i+=1\n",
        "            net.construct_exemplar_set(indexes, imgs, labels.iloc[0], m, herding=HERDING)\n",
        "        \n",
        "        test_loader = utils.get_eval_loader(test_set, BATCH_SIZE)\n",
        "        corrects, y_true, y_preds = test(net, test_loader, device)\n",
        "        epoch_test_accuracy = corrects / float(len(test_set))\n",
        "        test_accuracies.append(epoch_test_accuracy)\n",
        "        \n",
        "        print(f\"\\n\\tResults STAGE {stage+1}:\")\n",
        "        print(f\"\\t\\tTrain Mean Accuracy: {train_mean_accuracies[stage]}\")\n",
        "        print(f\"\\t\\tTest Accuracy: {test_accuracies[stage]}\\n\")\n",
        "    \n",
        "    total_time = int(time.time() - start_time)\n",
        "    min = int(total_time / 60)\n",
        "    sec = total_time % 60\n",
        "    print(f\"\\nTotal time: {min} min {sec} sec\\n\")\n",
        "    \n",
        "    return train_mean_accuracies,\\\n",
        "           test_accuracies,\\\n",
        "           y_true, y_preds\n",
        "        \n",
        "        "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "bvaYg8SiipNy",
        "colab_type": "text"
      },
      "source": [
        "**iCaRL START**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "i_ejvvl4ipNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "374e2015-923f-4def-ffb7-385a50bd2fb2"
      },
      "source": [
        "train_accuracies,\\\n",
        "test_accuracies,\\\n",
        "y_true, y_preds = icarl_training(train_val_dataset, test_dataset, NUM_EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "STARTING STAGE 1...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n",
            "\t\tEpoch 1: Train_loss = 0.03681633993983269\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.06257056477479636 - Train Accuracy: 0.151\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tEpoch 2: Train_loss = 0.028333935886621475\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.027500936668366192 - Train Accuracy: 0.3214\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tEpoch 3: Train_loss = 0.025647185742855072\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.0247178899589926 - Train Accuracy: 0.4184\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tEpoch 4: Train_loss = 0.02044990286231041\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.02262642290443182 - Train Accuracy: 0.4826\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tEpoch 5: Train_loss = 0.022088203579187393\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.020693894615396856 - Train Accuracy: 0.5376\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tEpoch 6: Train_loss = 0.018672896549105644\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.019252613466233016 - Train Accuracy: 0.5764\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tEpoch 7: Train_loss = 0.021206293255090714\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.018527035508304833 - Train Accuracy: 0.6068\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tEpoch 8: Train_loss = 0.016469405964016914\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.017134725442156197 - Train Accuracy: 0.6278\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tEpoch 9: Train_loss = 0.01689477078616619\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.017131379479542373 - Train Accuracy: 0.6228\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tEpoch 10: Train_loss = 0.016008934006094933\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.01589903053827584 - Train Accuracy: 0.6614\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tEpoch 11: Train_loss = 0.013057527132332325\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.014942967961542309 - Train Accuracy: 0.6866\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tEpoch 12: Train_loss = 0.017447829246520996\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.015540159703232349 - Train Accuracy: 0.675\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tEpoch 13: Train_loss = 0.013965808786451817\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.014423667010851205 - Train Accuracy: 0.7008\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tEpoch 14: Train_loss = 0.012474248185753822\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.013069706526584924 - Train Accuracy: 0.736\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tEpoch 15: Train_loss = 0.012008709833025932\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.01443981274496764 - Train Accuracy: 0.7088\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tEpoch 16: Train_loss = 0.013390649110078812\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.013459127303212881 - Train Accuracy: 0.7338\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tEpoch 17: Train_loss = 0.011524510569870472\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.01226787434425205 - Train Accuracy: 0.7606\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tEpoch 18: Train_loss = 0.013425171375274658\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.012829203088767827 - Train Accuracy: 0.7478\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tEpoch 19: Train_loss = 0.012339405715465546\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.011711982055567205 - Train Accuracy: 0.7652\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tEpoch 20: Train_loss = 0.00920338649302721\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.010786415613256394 - Train Accuracy: 0.793\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tEpoch 21: Train_loss = 0.01159697026014328\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.0110151685657911 - Train Accuracy: 0.7756\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tEpoch 22: Train_loss = 0.008996563032269478\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.009966335142962635 - Train Accuracy: 0.8052\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tEpoch 23: Train_loss = 0.010521586053073406\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.009371143497992307 - Train Accuracy: 0.8178\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tEpoch 24: Train_loss = 0.009858201257884502\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.010665928747039288 - Train Accuracy: 0.7894\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tEpoch 25: Train_loss = 0.00883265770971775\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.008897006500046701 - Train Accuracy: 0.8226\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tEpoch 26: Train_loss = 0.010389775037765503\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.009628610347863286 - Train Accuracy: 0.8068\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tEpoch 27: Train_loss = 0.008948935195803642\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.00817334740422666 - Train Accuracy: 0.838\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tEpoch 28: Train_loss = 0.008492699824273586\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.00887978308601305 - Train Accuracy: 0.8408\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tEpoch 29: Train_loss = 0.0073919459246098995\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.0095633695833385 - Train Accuracy: 0.8124\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tEpoch 30: Train_loss = 0.011081714183092117\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.009805482451338322 - Train Accuracy: 0.8184\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tEpoch 31: Train_loss = 0.00919212494045496\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.00952527931658551 - Train Accuracy: 0.8134\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tEpoch 32: Train_loss = 0.00756330881267786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciGlvEWabcbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import libs.plots as plots\n",
        "\n",
        "method = f\"PL_{CLASSIFY}_{LAYER}_layer_\" + \"herding\" if HERDING else \"random\"\n",
        "plots.plot_accuracy_trend(test_accuracies, method, SEED)\n",
        "plots.plot_confusion_matrix(y_true, y_preds, method, SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amC8Qy-yVw8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_accuracies(train_accuracies, test_accuracies, output=OUTPUT_PATH):\n",
        "  with open(f\"{output}_accuracies.csv\", \"w\", encoding=\"utf8\") as f:\n",
        "    f.write(\"mean_train_acc,test_acc\\n\")\n",
        "    for train, test in zip(train_accuracies, test_accuracies):\n",
        "      f.write(f\"{train},{test}\\n\")\n",
        "    print(\"********** FILE SAVED **********\")\n",
        "\n",
        "\n",
        "save_accuracies(train_accuracies, test_accuracies)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}