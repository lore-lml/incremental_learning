{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "IL_lwf.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "tvETQMX1ipNf",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1Odgmkpmjsp2tkXXJ3Yoxyukvr2QaEAMA\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab Account AI\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-LoM_h1IXAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a468cfc5-d9d7-4caa-f6a3-8b345f9e40fc"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "print(gpu.name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "wwN82ZV7ipNg",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RSnex0bmipNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_ROOT = 'cifar-100-python'\n",
        "CODE_ROOT = 'libs'\n",
        "import os\n",
        "if not os.path.isdir(DATASET_ROOT):\n",
        "    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "    !tar -xf 'cifar-100-python.tar.gz'  \n",
        "    !rm -rf 'cifar-100-python.tar.gz'\n",
        "\n",
        "if not os.path.isdir(CODE_ROOT):\n",
        "  !git clone https://lore-lml:29f601e814e0446c5b17a9f6c3684d1cbd316bcf@github.com/lore-lml/machine-learning2020-incremental_learning.git\n",
        "  !mv 'machine-learning2020-incremental_learning/libs' '.'\n",
        "  !rm -rf 'machine-learning2020-incremental_learning'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Subset\n",
        "from torch.backends import cudnn\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import libs.utils as utils\n",
        "from libs.utils import get_one_hot\n",
        "\n",
        "from libs.models.lwf import LwfModel\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7W9y67yoipNk",
        "colab_type": "text"
      },
      "source": [
        "**SET ARGUMENTS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "r0hjWAP3ipNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "arguments = utils.get_arguments()\n",
        "\n",
        "DEVICE = arguments['DEVICE']\n",
        "NUM_CLASSES = arguments[\"NUM_CLASSES\"] \n",
        "\n",
        "BATCH_SIZE = arguments[\"BATCH_SIZE\"]        # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                                            # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = arguments[\"LR\"]                        # The initial Learning Rate\n",
        "MOMENTUM = arguments[\"MOMENTUM\"]            # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = arguments[\"WEIGHT_DECAY\"]    # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = arguments[\"NUM_EPOCHS\"]        # Total number of training epochs (iterations over dataset)\n",
        "GAMMA = arguments[\"GAMMA\"]                  # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = arguments[\"LOG_FREQUENCY\"]\n",
        "MILESTONES = arguments[\"MILESTONES\"]\n",
        "SEED = 1993 #arguments[\"SEED\"]\n",
        "\n",
        "OUTPUT_PATH = f\"RUN1_lwf_seed{SEED}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "SaT8eFDNipNm",
        "colab_type": "text"
      },
      "source": [
        "**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "m-ydAGw4ipNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transforms, eval_transforms = utils.get_train_eval_transforms()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "X7Naz_DdipNp",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "G-Xct5sNipNp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bcb8f782-50f6-42f7-cf2b-bdabb899c7b0"
      },
      "source": [
        "train_val_dataset = utils.get_cifar_with_seed(DATASET_ROOT, train_transforms, src='train', seed=SEED)\n",
        "test_dataset = utils.get_cifar_with_seed(DATASET_ROOT, eval_transforms, src='test', seed=SEED)\n",
        "\n",
        "print(f\"Size Training Set: {len(train_val_dataset)}\")\n",
        "print(f\"Size Test Set: {len(test_dataset)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size Training Set: 50000\n",
            "Size Test Set: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xZDP5yXBipNt",
        "colab_type": "text"
      },
      "source": [
        "**Train, Test, Validation functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "secPALBtipNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_batch(net: LwfModel, train_loader, optimizer, current_step, device=DEVICE):\n",
        "    net.train()\n",
        "    cumulative_loss =.0\n",
        "    running_corrects = 0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(images)\n",
        "        \n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        \n",
        "        loss = net.compute_distillation_loss(images, labels, outputs, DEVICE)\n",
        "        cumulative_loss += loss.item()\n",
        "        \n",
        "        if current_step != 0 and current_step % LOG_FREQUENCY == 0:\n",
        "                print('\\t\\tTrain step - Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_step += 1\n",
        "\n",
        "    return cumulative_loss / len(train_loader), running_corrects, current_step\n",
        "\n",
        "def test(net, test_loader, device=DEVICE):\n",
        "    \n",
        "    # confusion matrix\n",
        "    y_true = []\n",
        "    y_preds = []\n",
        "\n",
        "    running_corrects = 0\n",
        "    for images, labels in tqdm(test_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        net.eval()\n",
        "        outputs = net(images)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "        # confusion matrix\n",
        "        y_true.extend(labels.data.tolist())\n",
        "        y_preds.extend(preds.tolist())\n",
        "\n",
        "   \n",
        "    return running_corrects, y_true, y_preds\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "s5SroLpaipNw",
        "colab_type": "text"
      },
      "source": [
        "**FINE TUNING FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "clnGi_eLipNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lwf_training(train_dataset, test_dataset, max_epoch=NUM_EPOCHS, file_path=OUTPUT_PATH, device=DEVICE):\n",
        "    import math, time\n",
        "    incremental_test = []\n",
        "    train_mean_stage_accuracies = []\n",
        "    test_stage_accuracies = []\n",
        "    cudnn.benchmark\n",
        "    net = LwfModel(100)\n",
        "    criterion = utils.get_criterion('bce')\n",
        "    start_time = time.time()\n",
        "    for stage in range(10):\n",
        "        optimizer, scheduler = utils.get_otpmizer_scheduler(net.parameters(), LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA)\n",
        "        print(f\"STARTING FINE TUNING STAGE {stage+1}...\")\n",
        "        # Get indices\n",
        "        train_idx, test_idx = utils.get_idxs_per_class_of_kth_batch(train_dataset, test_dataset, stage)\n",
        "        \n",
        "        # Make test set incremental\n",
        "        incremental_test.extend(np.ravel(test_idx))\n",
        "        train_idx = np.ravel(train_idx)\n",
        "        train_set, test_set = Subset(train_val_dataset, train_idx), Subset(test_dataset, incremental_test)\n",
        "\n",
        "        # Build data loaders\n",
        "        curr_train_loader = utils.get_train_loader(train_set,batch_size=BATCH_SIZE)\n",
        "        curr_test_loader = utils.get_eval_loader(test_set, batch_size=BATCH_SIZE)\n",
        "\n",
        "        # Init results\n",
        "        train_losses = []\n",
        "        train_accuracies = []\n",
        "        current_step = 0\n",
        "        \n",
        "        net.before_train(DEVICE)\n",
        "        for epoch in range(max_epoch):\n",
        "            print(f\"\\tSTARTING EPOCH {epoch+1} - LR={scheduler.get_last_lr()}...\")\n",
        "            curr_result = train_batch(net, curr_train_loader, optimizer, current_step, device)\n",
        "            curr_train_loss = curr_result[0]\n",
        "            curr_train_accuracy = curr_result[1] / float(BATCH_SIZE * len(curr_train_loader))\n",
        "            current_step = curr_result[2]\n",
        "            \n",
        "            train_losses.append(curr_train_loss)\n",
        "            train_accuracies.append(curr_train_accuracy)\n",
        "            scheduler.step()\n",
        "            \n",
        "            print(f\"\\t\\tRESULT EPOCH {epoch+1}:\")\n",
        "            print(f\"\\t\\t\\tTrain Loss: {curr_train_loss} - Train Accuracy: {curr_train_accuracy}\\n\")\n",
        "            \n",
        "        \n",
        "        net.after_train(10)\n",
        "        corrects, y_true, y_preds = test(net, curr_test_loader, device)\n",
        "        epoch_test_accuracy = corrects / float(len(test_set))\n",
        "        test_stage_accuracies.append(epoch_test_accuracy)\n",
        "        train_mean_stage_accuracies.append(np.mean(train_accuracies))\n",
        "        \n",
        "        print(f\"\\n\\tResults STAGE {stage+1}:\")\n",
        "        print(f\"\\t\\tTrain Mean Accuracy: {train_mean_stage_accuracies[stage]}\")\n",
        "        print(f\"\\t\\tTest Accuracy: {test_stage_accuracies[stage]}\\n\")\n",
        "\n",
        "\n",
        "    total_time = int(time.time() - start_time)\n",
        "    min = int(total_time / 60)\n",
        "    sec = total_time % 60\n",
        "    print(f\"\\nTotal time: {min} min {sec} sec\\n\")\n",
        "        \n",
        "    return train_mean_stage_accuracies,\\\n",
        "           test_stage_accuracies,\\\n",
        "           y_true, y_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "bvaYg8SiipNy",
        "colab_type": "text"
      },
      "source": [
        "**LEARNING WITHOUT FORGETTING START**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "i_ejvvl4ipNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4c70679a-515c-447b-83af-fc048c137a12"
      },
      "source": [
        "train_accuracies,\\\n",
        "test_accuracies,\\\n",
        "y_true, y_preds = lwf_training(train_val_dataset, test_dataset, NUM_EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "STARTING FINE TUNING STAGE 1...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n",
            "\t\tTrain step - Step 30, Loss 0.030350886285305023\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.063112423205987 - Train Accuracy: 0.1672676282051282\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.02484544739127159\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.026199182495474815 - Train Accuracy: 0.37740384615384615\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.023450864478945732\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.02297255549675379 - Train Accuracy: 0.47636217948717946\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.02512771636247635\n",
            "\t\tTrain step - Step 150, Loss 0.019817691296339035\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.021251829484334357 - Train Accuracy: 0.524238782051282\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.019590234383940697\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.019764262084395457 - Train Accuracy: 0.5578926282051282\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.021082701161503792\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.01834657083814725 - Train Accuracy: 0.5907451923076923\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 240, Loss 0.017482368275523186\n",
            "\t\tTrain step - Step 270, Loss 0.01571442186832428\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.017662895556825858 - Train Accuracy: 0.6153846153846154\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.016283029690384865\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.016446691340742968 - Train Accuracy: 0.647636217948718\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.013224918395280838\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.01571189447377737 - Train Accuracy: 0.6572516025641025\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.013926208019256592\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.014959887482034855 - Train Accuracy: 0.6814903846153846\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.016219252720475197\n",
            "\t\tTrain step - Step 420, Loss 0.013793960213661194\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.014192186487026704 - Train Accuracy: 0.7033253205128205\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 450, Loss 0.013315891847014427\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.013420921368285632 - Train Accuracy: 0.717948717948718\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.013365860097110271\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.012810089792578649 - Train Accuracy: 0.7357772435897436\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.010384761728346348\n",
            "\t\tTrain step - Step 540, Loss 0.013218153268098831\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.011923718313949231 - Train Accuracy: 0.7584134615384616\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.01308564841747284\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.01187529352804025 - Train Accuracy: 0.7588141025641025\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.011053294874727726\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.011150348262909131 - Train Accuracy: 0.7752403846153846\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.010001447051763535\n",
            "\t\tTrain step - Step 660, Loss 0.010623370297253132\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.01080264552281453 - Train Accuracy: 0.78125\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.010329659096896648\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.010718331505090762 - Train Accuracy: 0.7836538461538461\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.008379869163036346\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.0098899944494359 - Train Accuracy: 0.8034855769230769\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.009945142082870007\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.009864691704607163 - Train Accuracy: 0.8028846153846154\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.01113957166671753\n",
            "\t\tTrain step - Step 810, Loss 0.007465030997991562\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.009372038384660697 - Train Accuracy: 0.8167067307692307\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.007580646779388189\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.009364201460415736 - Train Accuracy: 0.8131009615384616\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 870, Loss 0.00945352017879486\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.008713690110315114 - Train Accuracy: 0.8327323717948718\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.008418028242886066\n",
            "\t\tTrain step - Step 930, Loss 0.007676994428038597\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.008364279491779132 - Train Accuracy: 0.8409455128205128\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.007975032553076744\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.008104354453583559 - Train Accuracy: 0.8421474358974359\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.006264750380069017\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.007947134618193675 - Train Accuracy: 0.8497596153846154\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.007387434598058462\n",
            "\t\tTrain step - Step 1050, Loss 0.0073828063905239105\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.00760817570755115 - Train Accuracy: 0.8529647435897436\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 1080, Loss 0.006170023698359728\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.007294855176065213 - Train Accuracy: 0.8563701923076923\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.006577770691365004\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.007575938287071693 - Train Accuracy: 0.8537660256410257\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.004470386542379856\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.007219648752839138 - Train Accuracy: 0.8643830128205128\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.008190232329070568\n",
            "\t\tTrain step - Step 1200, Loss 0.008153649047017097\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.007002035239472603 - Train Accuracy: 0.8667868589743589\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.006106529850512743\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.0067881397926845615 - Train Accuracy: 0.875\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.006338754668831825\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.007012647409469654 - Train Accuracy: 0.8629807692307693\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1290, Loss 0.0042155953124165535\n",
            "\t\tTrain step - Step 1320, Loss 0.009754668921232224\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.006600480562505813 - Train Accuracy: 0.8745993589743589\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.0067220511846244335\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.006219494013259044 - Train Accuracy: 0.8810096153846154\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.006255154497921467\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.006000524464373787 - Train Accuracy: 0.8858173076923077\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.003710350254550576\n",
            "\t\tTrain step - Step 1440, Loss 0.004947318229824305\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.0061888497931739455 - Train Accuracy: 0.8822115384615384\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.003516977885738015\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.0056960340469884565 - Train Accuracy: 0.8948317307692307\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1500, Loss 0.004536330234259367\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.0049677502531080674 - Train Accuracy: 0.9074519230769231\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.005885917227715254\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.0059351904902798245 - Train Accuracy: 0.8936298076923077\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.007021893281489611\n",
            "\t\tTrain step - Step 1590, Loss 0.005929036531597376\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.005517568773566148 - Train Accuracy: 0.8934294871794872\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.0047546266578137875\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.004988754239793007 - Train Accuracy: 0.9082532051282052\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.005577496252954006\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.005258408667615209 - Train Accuracy: 0.8996394230769231\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.007434411905705929\n",
            "\t\tTrain step - Step 1710, Loss 0.006251738406717777\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.005144542083144188 - Train Accuracy: 0.9024439102564102\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1740, Loss 0.003886699676513672\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.005127539643301413 - Train Accuracy: 0.9032451923076923\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1770, Loss 0.0038628694601356983\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.0043326166983789355 - Train Accuracy: 0.9202724358974359\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1800, Loss 0.0028468191158026457\n",
            "\t\tTrain step - Step 1830, Loss 0.0059422277845442295\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.004542110034097464 - Train Accuracy: 0.9180689102564102\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1860, Loss 0.004563672002404928\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.004753527219574421 - Train Accuracy: 0.9134615384615384\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1890, Loss 0.003311293665319681\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.004454946175265389 - Train Accuracy: 0.9208733974358975\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1920, Loss 0.0032919037621468306\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.003215160835773135 - Train Accuracy: 0.9463141025641025\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.0026708112563937902\n",
            "\t\tTrain step - Step 1980, Loss 0.001982061192393303\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.0024621055777877187 - Train Accuracy: 0.9631410256410257\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.002005562651902437\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.0020992565237415526 - Train Accuracy: 0.9725560897435898\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.0017145952442660928\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.0020544096851387085 - Train Accuracy: 0.9709535256410257\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.00228614523075521\n",
            "\t\tTrain step - Step 2100, Loss 0.001933279330842197\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.0018936173530677573 - Train Accuracy: 0.9753605769230769\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2130, Loss 0.0013302606530487537\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.0017426194509682364 - Train Accuracy: 0.9761618589743589\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.0021345012355595827\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.0017238185391761363 - Train Accuracy: 0.9741586538461539\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.001318615977652371\n",
            "\t\tTrain step - Step 2220, Loss 0.0022771302610635757\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.0016848956031772571 - Train Accuracy: 0.9771634615384616\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2250, Loss 0.0021124938502907753\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.0016227890617954426 - Train Accuracy: 0.9771634615384616\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2280, Loss 0.0011269466485828161\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.0015719996538395302 - Train Accuracy: 0.9789663461538461\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2310, Loss 0.0008464754791930318\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.0015313906911521768 - Train Accuracy: 0.9793669871794872\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2340, Loss 0.0014177685370668769\n",
            "\t\tTrain step - Step 2370, Loss 0.001266257488168776\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.0014116115978536888 - Train Accuracy: 0.9819711538461539\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2400, Loss 0.0017044023843482137\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.0013324355688662482 - Train Accuracy: 0.984375\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2430, Loss 0.0015087670180946589\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.0013262803997629536 - Train Accuracy: 0.9823717948717948\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2460, Loss 0.0013627838343381882\n",
            "\t\tTrain step - Step 2490, Loss 0.0016224798746407032\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.0012384497124749499 - Train Accuracy: 0.9849759615384616\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2520, Loss 0.0007942900410853326\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.001144680618427885 - Train Accuracy: 0.9869791666666666\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2550, Loss 0.002056149998679757\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.0011338853360846257 - Train Accuracy: 0.9855769230769231\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2580, Loss 0.0007728782948106527\n",
            "\t\tTrain step - Step 2610, Loss 0.0008317680330947042\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.0010884073921121084 - Train Accuracy: 0.9879807692307693\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2640, Loss 0.0007452095742337406\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.001098009056220643 - Train Accuracy: 0.9873798076923077\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2670, Loss 0.0007867105305194855\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.0010609013873200195 - Train Accuracy: 0.9867788461538461\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2700, Loss 0.0007331331144087017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.001061334680670347 - Train Accuracy: 0.9893830128205128\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 16.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 1:\n",
            "\t\tTrain Mean Accuracy: 0.8413203983516482\n",
            "\t\tTest Accuracy: 0.878\n",
            "\n",
            "STARTING FINE TUNING STAGE 2...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.04204556345939636\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.056970485796531044 - Train Accuracy: 0.06710737179487179\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.04045148193836212\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.038642872315950885 - Train Accuracy: 0.17828525641025642\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.03495809808373451\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.03499973641756254 - Train Accuracy: 0.2578125\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.03405913710594177\n",
            "\t\tTrain step - Step 150, Loss 0.033921681344509125\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.033699299567020856 - Train Accuracy: 0.3141025641025641\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.0317610427737236\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.03290599847260194 - Train Accuracy: 0.36498397435897434\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.03198827803134918\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.03164127817711769 - Train Accuracy: 0.3996394230769231\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 240, Loss 0.031875189393758774\n",
            "\t\tTrain step - Step 270, Loss 0.03334086760878563\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.030989985721997727 - Train Accuracy: 0.4234775641025641\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.03107483871281147\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.030302500782104638 - Train Accuracy: 0.46113782051282054\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.02811291813850403\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.029639733238862112 - Train Accuracy: 0.48457532051282054\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.028746752068400383\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.029359080470525302 - Train Accuracy: 0.49439102564102566\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.03142648562788963\n",
            "\t\tTrain step - Step 420, Loss 0.026291850954294205\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.02809410948210802 - Train Accuracy: 0.5206330128205128\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 450, Loss 0.025863999500870705\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.02740933555058944 - Train Accuracy: 0.5428685897435898\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.02657184563577175\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.027807274212439854 - Train Accuracy: 0.5412660256410257\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.025667984038591385\n",
            "\t\tTrain step - Step 540, Loss 0.030111758038401604\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.026943678466173317 - Train Accuracy: 0.5635016025641025\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.0253074262291193\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.026245884262980558 - Train Accuracy: 0.5743189102564102\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.023338980972766876\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.026021897936096557 - Train Accuracy: 0.5909455128205128\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.024076266214251518\n",
            "\t\tTrain step - Step 660, Loss 0.025400647893548012\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.025880389393140107 - Train Accuracy: 0.6053685897435898\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.02525598742067814\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.025569076769244976 - Train Accuracy: 0.6207932692307693\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.027187880128622055\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.02505312845684015 - Train Accuracy: 0.6282051282051282\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.023571638390421867\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.024279034338318385 - Train Accuracy: 0.6470352564102564\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.024511441588401794\n",
            "\t\tTrain step - Step 810, Loss 0.02734355814754963\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.02496436157096655 - Train Accuracy: 0.6388221153846154\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.02353360690176487\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.024149867443320077 - Train Accuracy: 0.6452323717948718\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 870, Loss 0.02245262637734413\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.023532439787418414 - Train Accuracy: 0.6630608974358975\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.02107110433280468\n",
            "\t\tTrain step - Step 930, Loss 0.024546906352043152\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.02319159879325292 - Train Accuracy: 0.6784855769230769\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.02281254157423973\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.02308653209071893 - Train Accuracy: 0.6826923076923077\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.020662439987063408\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.02271645745405784 - Train Accuracy: 0.6901041666666666\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.023681344464421272\n",
            "\t\tTrain step - Step 1050, Loss 0.024490870535373688\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.022384673930131473 - Train Accuracy: 0.7053285256410257\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 1080, Loss 0.022472994402050972\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.0230798496840856 - Train Accuracy: 0.6907051282051282\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.023337649181485176\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.022398274535169967 - Train Accuracy: 0.711738782051282\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.0221260916441679\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.022330178998601742 - Train Accuracy: 0.71875\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.020287370309233665\n",
            "\t\tTrain step - Step 1200, Loss 0.02246863767504692\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.022311108951003123 - Train Accuracy: 0.7227564102564102\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.019848845899105072\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.02117354480119852 - Train Accuracy: 0.7315705128205128\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.021780306473374367\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.021406137217313815 - Train Accuracy: 0.7317708333333334\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1290, Loss 0.020922450348734856\n",
            "\t\tTrain step - Step 1320, Loss 0.020676331594586372\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.021456193704253588 - Train Accuracy: 0.7405849358974359\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.023060912266373634\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.0211714872947106 - Train Accuracy: 0.7512019230769231\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.019452843815088272\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.020859902103741963 - Train Accuracy: 0.7489983974358975\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.019522106274962425\n",
            "\t\tTrain step - Step 1440, Loss 0.021196985617280006\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.020991998987320144 - Train Accuracy: 0.7618189102564102\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.021277960389852524\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.020697774078983527 - Train Accuracy: 0.7560096153846154\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1500, Loss 0.020540650933980942\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.020432145931781866 - Train Accuracy: 0.7680288461538461\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.02028726600110531\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.020468196282402065 - Train Accuracy: 0.7836538461538461\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.02262623980641365\n",
            "\t\tTrain step - Step 1590, Loss 0.020731091499328613\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.02030521024687168 - Train Accuracy: 0.7594150641025641\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.02241278439760208\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.020124456295982387 - Train Accuracy: 0.7746394230769231\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.017589110881090164\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.020028615418152932 - Train Accuracy: 0.7798477564102564\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.01962987892329693\n",
            "\t\tTrain step - Step 1710, Loss 0.020802048966288567\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.019531647221018106 - Train Accuracy: 0.788261217948718\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1740, Loss 0.017790477722883224\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.01886770325020338 - Train Accuracy: 0.7986778846153846\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1770, Loss 0.018131375312805176\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.018762798454516973 - Train Accuracy: 0.8050881410256411\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1800, Loss 0.020315296947956085\n",
            "\t\tTrain step - Step 1830, Loss 0.019551392644643784\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.01904591402182212 - Train Accuracy: 0.8012820512820513\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1860, Loss 0.01990363746881485\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.019040789407415267 - Train Accuracy: 0.8034855769230769\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1890, Loss 0.018450822681188583\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.018283156009438712 - Train Accuracy: 0.8169070512820513\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1920, Loss 0.018275409936904907\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.016292804923768226 - Train Accuracy: 0.8567708333333334\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.014430176466703415\n",
            "\t\tTrain step - Step 1980, Loss 0.014026626944541931\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.01450660853431775 - Train Accuracy: 0.8766025641025641\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.014094342477619648\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.013983703290040676 - Train Accuracy: 0.8884214743589743\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.012869994156062603\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.013808548402709838 - Train Accuracy: 0.8856169871794872\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.014047661796212196\n",
            "\t\tTrain step - Step 2100, Loss 0.01356530375778675\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.013629382953811914 - Train Accuracy: 0.889823717948718\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2130, Loss 0.012360785156488419\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.013545037581561467 - Train Accuracy: 0.8948317307692307\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.0124350069090724\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.013438193246913262 - Train Accuracy: 0.8926282051282052\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.012279984541237354\n",
            "\t\tTrain step - Step 2220, Loss 0.013569960370659828\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.01317551896835749 - Train Accuracy: 0.9032451923076923\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2250, Loss 0.013472978956997395\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.01298176965270287 - Train Accuracy: 0.9044471153846154\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2280, Loss 0.01272769458591938\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.01277939748401061 - Train Accuracy: 0.9036458333333334\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2310, Loss 0.013883933424949646\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.01300164949722015 - Train Accuracy: 0.9044471153846154\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2340, Loss 0.01237423438578844\n",
            "\t\tTrain step - Step 2370, Loss 0.014120230451226234\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.012827950267073436 - Train Accuracy: 0.9026442307692307\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2400, Loss 0.014533979818224907\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.012658498536508817 - Train Accuracy: 0.9066506410256411\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2430, Loss 0.012590546160936356\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.01278038014872716 - Train Accuracy: 0.9120592948717948\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2460, Loss 0.011947953142225742\n",
            "\t\tTrain step - Step 2490, Loss 0.012599404901266098\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.012386874797252508 - Train Accuracy: 0.9202724358974359\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2520, Loss 0.011993024498224258\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.012382261455059052 - Train Accuracy: 0.9188701923076923\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2550, Loss 0.012036128900945187\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.01230086199939251 - Train Accuracy: 0.9156650641025641\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2580, Loss 0.012268075719475746\n",
            "\t\tTrain step - Step 2610, Loss 0.012916598469018936\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.01222510934353639 - Train Accuracy: 0.9214743589743589\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2640, Loss 0.012682950124144554\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.012124485909365691 - Train Accuracy: 0.921073717948718\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2670, Loss 0.012745554558932781\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.012115644004482489 - Train Accuracy: 0.9176682692307693\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2700, Loss 0.012039396911859512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/16 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.01202628818842081 - Train Accuracy: 0.9214743589743589\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:00<00:00, 21.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 2:\n",
            "\t\tTrain Mean Accuracy: 0.7098242902930402\n",
            "\t\tTest Accuracy: 0.635\n",
            "\n",
            "STARTING FINE TUNING STAGE 3...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.050184495747089386\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.06079544346684065 - Train Accuracy: 0.06470352564102565\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.041950736194849014\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.04481308945478537 - Train Accuracy: 0.2107371794871795\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.04326978698372841\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.04099023724213625 - Train Accuracy: 0.3046875\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.040160320699214935\n",
            "\t\tTrain step - Step 150, Loss 0.03820675611495972\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.03950810871827297 - Train Accuracy: 0.3719951923076923\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.04015302658081055\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.03839901796518228 - Train Accuracy: 0.4417067307692308\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.03868264704942703\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.037765818528639965 - Train Accuracy: 0.4827724358974359\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 240, Loss 0.0365055613219738\n",
            "\t\tTrain step - Step 270, Loss 0.03697419911623001\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.03656106203412398 - Train Accuracy: 0.5292467948717948\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.03753061592578888\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.0361236647153512 - Train Accuracy: 0.5703125\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.03533844277262688\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.035868400086959205 - Train Accuracy: 0.5923477564102564\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.03574185445904732\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.035243250811711334 - Train Accuracy: 0.6155849358974359\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.03463879972696304\n",
            "\t\tTrain step - Step 420, Loss 0.03298935666680336\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.03468042344619066 - Train Accuracy: 0.6412259615384616\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 450, Loss 0.03410086780786514\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.03443848943481079 - Train Accuracy: 0.6524439102564102\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.03409099951386452\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.03410750235884617 - Train Accuracy: 0.6772836538461539\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.03485271334648132\n",
            "\t\tTrain step - Step 540, Loss 0.03362321853637695\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.03370011148926539 - Train Accuracy: 0.6856971153846154\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.03292844071984291\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.03305266802318585 - Train Accuracy: 0.7015224358974359\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.03507555276155472\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.033481511359031386 - Train Accuracy: 0.7149439102564102\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.03195274993777275\n",
            "\t\tTrain step - Step 660, Loss 0.03258578106760979\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.03292219063792473 - Train Accuracy: 0.7417868589743589\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.034206245094537735\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.032367733951944574 - Train Accuracy: 0.7411858974358975\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.03290332853794098\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.032441153119389825 - Train Accuracy: 0.7473958333333334\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.03374997153878212\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.03203927735105539 - Train Accuracy: 0.7566105769230769\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.03243416175246239\n",
            "\t\tTrain step - Step 810, Loss 0.03229525312781334\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.03157323885422487 - Train Accuracy: 0.7576121794871795\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.03174571320414543\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.03162170468996733 - Train Accuracy: 0.7716346153846154\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 870, Loss 0.031184129416942596\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.03164379857480526 - Train Accuracy: 0.7730368589743589\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.03126624599099159\n",
            "\t\tTrain step - Step 930, Loss 0.032401230186223984\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.031326792704371303 - Train Accuracy: 0.7768429487179487\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.03266208991408348\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.031301165477205545 - Train Accuracy: 0.7910657051282052\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.032341912388801575\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.030821553216530725 - Train Accuracy: 0.7906650641025641\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.02948405221104622\n",
            "\t\tTrain step - Step 1050, Loss 0.03089897148311138\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.031400217555272274 - Train Accuracy: 0.7986778846153846\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 1080, Loss 0.02981874905526638\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.030991727725053445 - Train Accuracy: 0.8020833333333334\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.03047097846865654\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.030887950211763382 - Train Accuracy: 0.8000801282051282\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.030817842110991478\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.0313043554719442 - Train Accuracy: 0.8032852564102564\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.028960933908820152\n",
            "\t\tTrain step - Step 1200, Loss 0.02965799905359745\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.03030719932837364 - Train Accuracy: 0.8209134615384616\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.032582417130470276\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.030343823278179534 - Train Accuracy: 0.8100961538461539\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.029565293341875076\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.030556903292353336 - Train Accuracy: 0.8161057692307693\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1290, Loss 0.031141744926571846\n",
            "\t\tTrain step - Step 1320, Loss 0.031009038910269737\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.030027126511320088 - Train Accuracy: 0.8247195512820513\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.029308689758181572\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.029308387293265417 - Train Accuracy: 0.8245192307692307\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.02935919724404812\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.03027854296259391 - Train Accuracy: 0.8253205128205128\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.02926221489906311\n",
            "\t\tTrain step - Step 1440, Loss 0.02830563485622406\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.02957793664282713 - Train Accuracy: 0.8427483974358975\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.030567998066544533\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.0291913585880628 - Train Accuracy: 0.8373397435897436\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1500, Loss 0.03095926158130169\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.029808002309157297 - Train Accuracy: 0.8319310897435898\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.02939583919942379\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.02936340472063957 - Train Accuracy: 0.8481570512820513\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.03140328824520111\n",
            "\t\tTrain step - Step 1590, Loss 0.030037643387913704\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.029583663321458377 - Train Accuracy: 0.8415464743589743\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.029961852356791496\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.02932309679304942 - Train Accuracy: 0.8409455128205128\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.027307668700814247\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.029502457151046164 - Train Accuracy: 0.8397435897435898\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.028754305094480515\n",
            "\t\tTrain step - Step 1710, Loss 0.027891647070646286\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.029570302424522545 - Train Accuracy: 0.8589743589743589\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1740, Loss 0.029818769544363022\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.02924686374190526 - Train Accuracy: 0.858573717948718\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1770, Loss 0.02832258678972721\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.02849063282020581 - Train Accuracy: 0.8641826923076923\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1800, Loss 0.028281625360250473\n",
            "\t\tTrain step - Step 1830, Loss 0.029121411964297295\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.028697843400713723 - Train Accuracy: 0.8667868589743589\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1860, Loss 0.02838507667183876\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.028562379236786794 - Train Accuracy: 0.8687900641025641\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1890, Loss 0.027154922485351562\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.028952073831206713 - Train Accuracy: 0.8677884615384616\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1920, Loss 0.026669949293136597\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.0268141022668435 - Train Accuracy: 0.8946314102564102\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.02570338360965252\n",
            "\t\tTrain step - Step 1980, Loss 0.024960579350590706\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.02539705876738597 - Train Accuracy: 0.9004407051282052\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.0253306832164526\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.025008390442683145 - Train Accuracy: 0.9030448717948718\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.024532074108719826\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.024860724950065978 - Train Accuracy: 0.9066506410256411\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.023918410763144493\n",
            "\t\tTrain step - Step 2100, Loss 0.02388075739145279\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.02464109320098009 - Train Accuracy: 0.905448717948718\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2130, Loss 0.026473350822925568\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.02472938410937786 - Train Accuracy: 0.8956330128205128\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.025619106367230415\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.02452734771829385 - Train Accuracy: 0.8998397435897436\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.02442333661019802\n",
            "\t\tTrain step - Step 2220, Loss 0.024181757122278214\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.024239822123677302 - Train Accuracy: 0.90625\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2250, Loss 0.025099605321884155\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.024277179478070676 - Train Accuracy: 0.8994391025641025\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2280, Loss 0.024275660514831543\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.02433927338092755 - Train Accuracy: 0.907051282051282\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2310, Loss 0.0246905367821455\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.024308482471566934 - Train Accuracy: 0.9016426282051282\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2340, Loss 0.023815171793103218\n",
            "\t\tTrain step - Step 2370, Loss 0.023499535396695137\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.024257360169520743 - Train Accuracy: 0.9012419871794872\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2400, Loss 0.02459513396024704\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.024067942769481585 - Train Accuracy: 0.9052483974358975\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2430, Loss 0.02512313239276409\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.02409508924644727 - Train Accuracy: 0.9034455128205128\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2460, Loss 0.024651484563946724\n",
            "\t\tTrain step - Step 2490, Loss 0.022794246673583984\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.023699334130073205 - Train Accuracy: 0.9170673076923077\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2520, Loss 0.02353164181113243\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.02364626345344079 - Train Accuracy: 0.9180689102564102\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2550, Loss 0.023471269756555557\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.02382690779482707 - Train Accuracy: 0.9034455128205128\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2580, Loss 0.022743791341781616\n",
            "\t\tTrain step - Step 2610, Loss 0.023141540586948395\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.023649567117293675 - Train Accuracy: 0.9100560897435898\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2640, Loss 0.0247736107558012\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.02373670237377668 - Train Accuracy: 0.9088541666666666\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2670, Loss 0.02423282340168953\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.023721625646337483 - Train Accuracy: 0.9100560897435898\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2700, Loss 0.023535003885626793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/24 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.023652538657188416 - Train Accuracy: 0.9094551282051282\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [00:00<00:00, 25.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 3:\n",
            "\t\tTrain Mean Accuracy: 0.772933836996337\n",
            "\t\tTest Accuracy: 0.562\n",
            "\n",
            "STARTING FINE TUNING STAGE 4...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n",
            "\t\tTrain step - Step 30, Loss 0.057910799980163574\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.07045790629509167 - Train Accuracy: 0.03205128205128205\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.05572213605046272\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.05788534669539867 - Train Accuracy: 0.12319711538461539\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.05560506135225296\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.05491704149888112 - Train Accuracy: 0.17888621794871795\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.05456149950623512\n",
            "\t\tTrain step - Step 150, Loss 0.05469649285078049\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.053236854095489554 - Train Accuracy: 0.2297676282051282\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.0523676760494709\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.052274828537916526 - Train Accuracy: 0.25701121794871795\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.04945690929889679\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.051296283037234575 - Train Accuracy: 0.29707532051282054\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 240, Loss 0.048558883368968964\n",
            "\t\tTrain step - Step 270, Loss 0.04998080059885979\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.050761728714673944 - Train Accuracy: 0.3323317307692308\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.04977809637784958\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.050167605853997745 - Train Accuracy: 0.3762019230769231\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.04973601549863815\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.04981615661810606 - Train Accuracy: 0.3974358974358974\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.049161963164806366\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.04940034315372125 - Train Accuracy: 0.42588141025641024\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.050388820469379425\n",
            "\t\tTrain step - Step 420, Loss 0.05029312148690224\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.04901980264828755 - Train Accuracy: 0.45653044871794873\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 450, Loss 0.0459803007543087\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.0488666160366474 - Train Accuracy: 0.4735576923076923\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.0454215370118618\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.04860215615003537 - Train Accuracy: 0.49719551282051283\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.05229441449046135\n",
            "\t\tTrain step - Step 540, Loss 0.05112449452280998\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.04820202520260444 - Train Accuracy: 0.5120192307692307\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.04893064871430397\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.04776182264471666 - Train Accuracy: 0.5376602564102564\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.044759053736925125\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.047445633281499915 - Train Accuracy: 0.5532852564102564\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.04666444659233093\n",
            "\t\tTrain step - Step 660, Loss 0.04813814163208008\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.04752838850403444 - Train Accuracy: 0.5707131410256411\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.04754524305462837\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.04723283323722008 - Train Accuracy: 0.5805288461538461\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.04653172567486763\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.04680108871215429 - Train Accuracy: 0.6047676282051282\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.044507626444101334\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.04677330836271628 - Train Accuracy: 0.6217948717948718\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.04740314930677414\n",
            "\t\tTrain step - Step 810, Loss 0.04499371349811554\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.047035544919661984 - Train Accuracy: 0.6185897435897436\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.04419272392988205\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.0463785310395253 - Train Accuracy: 0.632011217948718\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 870, Loss 0.04566596820950508\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.04622714928327463 - Train Accuracy: 0.6434294871794872\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.04436414688825607\n",
            "\t\tTrain step - Step 930, Loss 0.048114433884620667\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.04576132542047745 - Train Accuracy: 0.655448717948718\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.04820498824119568\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.04620090958017569 - Train Accuracy: 0.6636618589743589\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.04657088965177536\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.04533789249566885 - Train Accuracy: 0.6798878205128205\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.04571758583188057\n",
            "\t\tTrain step - Step 1050, Loss 0.04748087003827095\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.04570320525612587 - Train Accuracy: 0.6822916666666666\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 1080, Loss 0.04483065381646156\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.04526672493188809 - Train Accuracy: 0.7065304487179487\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.04524731636047363\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.04505969813236824 - Train Accuracy: 0.6935096153846154\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.04601829871535301\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.045070989773823664 - Train Accuracy: 0.6963141025641025\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.0452948734164238\n",
            "\t\tTrain step - Step 1200, Loss 0.044446706771850586\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.04483038177474951 - Train Accuracy: 0.7171474358974359\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.04710783436894417\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.0454962765559172 - Train Accuracy: 0.7071314102564102\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.04587710276246071\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.044841572928887144 - Train Accuracy: 0.7295673076923077\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1290, Loss 0.04715019091963768\n",
            "\t\tTrain step - Step 1320, Loss 0.045759186148643494\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.04504267135873819 - Train Accuracy: 0.7215544871794872\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.043077047914266586\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.04470393711175674 - Train Accuracy: 0.7313701923076923\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.04323256388306618\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.044583349846876584 - Train Accuracy: 0.7243589743589743\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.043121155351400375\n",
            "\t\tTrain step - Step 1440, Loss 0.043427255004644394\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.04384059774187895 - Train Accuracy: 0.7451923076923077\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.0426461435854435\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.04379510411467308 - Train Accuracy: 0.757011217948718\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1500, Loss 0.04496120288968086\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.04444213058703985 - Train Accuracy: 0.7522035256410257\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.044095564633607864\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.0445338833408478 - Train Accuracy: 0.7355769230769231\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.04605253040790558\n",
            "\t\tTrain step - Step 1590, Loss 0.04215496405959129\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.04402059689164162 - Train Accuracy: 0.7626201923076923\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.04709003493189812\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.04441831576136442 - Train Accuracy: 0.7578125\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.04442580044269562\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.04401388458716564 - Train Accuracy: 0.7684294871794872\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.04436832293868065\n",
            "\t\tTrain step - Step 1710, Loss 0.04585978016257286\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.04401632255086532 - Train Accuracy: 0.7690304487179487\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1740, Loss 0.04384273290634155\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.043185574313004814 - Train Accuracy: 0.7724358974358975\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1770, Loss 0.041787613183259964\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.043217903528458036 - Train Accuracy: 0.7758413461538461\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1800, Loss 0.043799057602882385\n",
            "\t\tTrain step - Step 1830, Loss 0.04180457070469856\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.04365033102341187 - Train Accuracy: 0.7730368589743589\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1860, Loss 0.04247616231441498\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.04311342499195001 - Train Accuracy: 0.7810496794871795\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1890, Loss 0.04328332841396332\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.043479348031374127 - Train Accuracy: 0.7874599358974359\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1920, Loss 0.04261511191725731\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.04052973529085135 - Train Accuracy: 0.8269230769230769\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.03968236222863197\n",
            "\t\tTrain step - Step 1980, Loss 0.039964184165000916\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.03890554148417253 - Train Accuracy: 0.8435496794871795\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.03914472460746765\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.038466067268298224 - Train Accuracy: 0.8413461538461539\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.03869728744029999\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.03804058266373781 - Train Accuracy: 0.8409455128205128\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.03847414255142212\n",
            "\t\tTrain step - Step 2100, Loss 0.037445805966854095\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.03795325230711546 - Train Accuracy: 0.8409455128205128\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2130, Loss 0.03791288658976555\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.037692912782614045 - Train Accuracy: 0.8369391025641025\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.0371718592941761\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.03766147563090691 - Train Accuracy: 0.8425480769230769\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.03729654848575592\n",
            "\t\tTrain step - Step 2220, Loss 0.037094660103321075\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.037458845820182406 - Train Accuracy: 0.8515625\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2250, Loss 0.03686058893799782\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.03728080445375198 - Train Accuracy: 0.8451522435897436\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2280, Loss 0.03789341822266579\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.037452102662661135 - Train Accuracy: 0.8435496794871795\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2310, Loss 0.03757850453257561\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.03719755577353331 - Train Accuracy: 0.8479567307692307\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2340, Loss 0.03616848215460777\n",
            "\t\tTrain step - Step 2370, Loss 0.038103941828012466\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.03707768892248472 - Train Accuracy: 0.8543669871794872\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2400, Loss 0.03601289540529251\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.03692207256188759 - Train Accuracy: 0.8565705128205128\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2430, Loss 0.03750418499112129\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.0369819408425918 - Train Accuracy: 0.8511618589743589\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2460, Loss 0.036684878170490265\n",
            "\t\tTrain step - Step 2490, Loss 0.03583724424242973\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.03665941418745579 - Train Accuracy: 0.8533653846153846\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2520, Loss 0.03667047992348671\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.036628260826453186 - Train Accuracy: 0.8555689102564102\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2550, Loss 0.036073584109544754\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.03643604587668028 - Train Accuracy: 0.8611778846153846\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2580, Loss 0.0370236299932003\n",
            "\t\tTrain step - Step 2610, Loss 0.03655589744448662\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.036519659348787405 - Train Accuracy: 0.858573717948718\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2640, Loss 0.037097182124853134\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.03655864451176081 - Train Accuracy: 0.8595753205128205\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2670, Loss 0.03526341915130615\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.036610324604389 - Train Accuracy: 0.8537660256410257\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2700, Loss 0.037162430584430695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/32 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.03650673564810019 - Train Accuracy: 0.8621794871794872\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 26.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 4:\n",
            "\t\tTrain Mean Accuracy: 0.6689445970695972\n",
            "\t\tTest Accuracy: 0.4805\n",
            "\n",
            "STARTING FINE TUNING STAGE 5...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.06564906239509583\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.07841943739316402 - Train Accuracy: 0.08673878205128205\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.06276721507310867\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.06375582793202156 - Train Accuracy: 0.3313301282051282\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.06362063437700272\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.0617739716783548 - Train Accuracy: 0.4332932692307692\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.060707539319992065\n",
            "\t\tTrain step - Step 150, Loss 0.0581178180873394\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.05969979776403843 - Train Accuracy: 0.4671474358974359\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.05677115172147751\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.058614808397415355 - Train Accuracy: 0.5244391025641025\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.05718080326914787\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.05803938076282159 - Train Accuracy: 0.5434695512820513\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 240, Loss 0.05590835586190224\n",
            "\t\tTrain step - Step 270, Loss 0.05965317040681839\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.057958943817095876 - Train Accuracy: 0.5713141025641025\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.05761949345469475\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.05756705645949413 - Train Accuracy: 0.5973557692307693\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.057548027485609055\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.05721697373650013 - Train Accuracy: 0.6173878205128205\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.05555228143930435\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.05675910480129413 - Train Accuracy: 0.6402243589743589\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.05429769307374954\n",
            "\t\tTrain step - Step 420, Loss 0.056324224919080734\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.05664201424672054 - Train Accuracy: 0.6566506410256411\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 450, Loss 0.05857577174901962\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.05674073348442713 - Train Accuracy: 0.6700721153846154\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.05549095198512077\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.05624334294444475 - Train Accuracy: 0.6828926282051282\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.05600255727767944\n",
            "\t\tTrain step - Step 540, Loss 0.05717412009835243\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.056417604382985674 - Train Accuracy: 0.6959134615384616\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.055692434310913086\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.05561186077120977 - Train Accuracy: 0.702323717948718\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.055907901376485825\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.05535015272788513 - Train Accuracy: 0.717948717948718\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.056411292403936386\n",
            "\t\tTrain step - Step 660, Loss 0.055335573852062225\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.05531943971529985 - Train Accuracy: 0.7255608974358975\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.05430885776877403\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.055240970582534105 - Train Accuracy: 0.7293669871794872\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.05529901385307312\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.05536858116587003 - Train Accuracy: 0.7341746794871795\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.05644286051392555\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.05529519323355112 - Train Accuracy: 0.742988782051282\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.05571572110056877\n",
            "\t\tTrain step - Step 810, Loss 0.05669889971613884\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.05510488945322159 - Train Accuracy: 0.7550080128205128\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.05427534878253937\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.05496529059914442 - Train Accuracy: 0.7562099358974359\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 870, Loss 0.05301965773105621\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.054495662164229616 - Train Accuracy: 0.7646233974358975\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.05433342978358269\n",
            "\t\tTrain step - Step 930, Loss 0.05458836257457733\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.05485051001111666 - Train Accuracy: 0.7764423076923077\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.05478997156023979\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.05434367414086293 - Train Accuracy: 0.7762419871794872\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.05675290524959564\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.05447197122833668 - Train Accuracy: 0.7808493589743589\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.054359450936317444\n",
            "\t\tTrain step - Step 1050, Loss 0.05347175523638725\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.054827539871136345 - Train Accuracy: 0.7790464743589743\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 1080, Loss 0.05492625758051872\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.054118286340664595 - Train Accuracy: 0.8018830128205128\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.055002450942993164\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.05375994961613264 - Train Accuracy: 0.7994791666666666\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.05486803501844406\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.05431948201014446 - Train Accuracy: 0.7938701923076923\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.053895287215709686\n",
            "\t\tTrain step - Step 1200, Loss 0.0539754219353199\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.05387397540303377 - Train Accuracy: 0.8060897435897436\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.05479251593351364\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.0545617265579028 - Train Accuracy: 0.7934695512820513\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.05344773083925247\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.054135468430244006 - Train Accuracy: 0.8098958333333334\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1290, Loss 0.05412493646144867\n",
            "\t\tTrain step - Step 1320, Loss 0.052703551948070526\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.053739344175809466 - Train Accuracy: 0.8175080128205128\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.05428270623087883\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.05338107708555002 - Train Accuracy: 0.8221153846153846\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.05440757796168327\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.05340056274181757 - Train Accuracy: 0.8187099358974359\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.05522410199046135\n",
            "\t\tTrain step - Step 1440, Loss 0.05661601945757866\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.05391829241162691 - Train Accuracy: 0.8233173076923077\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.05371220409870148\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.053594096444356136 - Train Accuracy: 0.8181089743589743\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1500, Loss 0.05341370403766632\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.05352924496699602 - Train Accuracy: 0.8303285256410257\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.05199972912669182\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.053479205148342326 - Train Accuracy: 0.8259214743589743\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.053055182099342346\n",
            "\t\tTrain step - Step 1590, Loss 0.05362546816468239\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.05316759798771296 - Train Accuracy: 0.8335336538461539\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.05546633526682854\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.053956618771339074 - Train Accuracy: 0.8309294871794872\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.05111327022314072\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.05327005082598099 - Train Accuracy: 0.8435496794871795\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.05422714725136757\n",
            "\t\tTrain step - Step 1710, Loss 0.05410431697964668\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.053592849331788525 - Train Accuracy: 0.8309294871794872\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1740, Loss 0.052553534507751465\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.053641316695855215 - Train Accuracy: 0.8295272435897436\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1770, Loss 0.052972469478845596\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.05331147720034306 - Train Accuracy: 0.8385416666666666\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1800, Loss 0.054473455995321274\n",
            "\t\tTrain step - Step 1830, Loss 0.05377080291509628\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.053211845457553864 - Train Accuracy: 0.8463541666666666\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1860, Loss 0.05256485939025879\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.052992607634036966 - Train Accuracy: 0.84375\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1890, Loss 0.05311170592904091\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.05299898810111559 - Train Accuracy: 0.850761217948718\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1920, Loss 0.050264663994312286\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.05095079522102307 - Train Accuracy: 0.8707932692307693\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.05016617476940155\n",
            "\t\tTrain step - Step 1980, Loss 0.05097462609410286\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.04971671658448684 - Train Accuracy: 0.8675881410256411\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.049293261021375656\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.04926459863781929 - Train Accuracy: 0.8764022435897436\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.049370378255844116\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.049225182296373904 - Train Accuracy: 0.8715945512820513\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.04901896417140961\n",
            "\t\tTrain step - Step 2100, Loss 0.0489460825920105\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.048898616853432775 - Train Accuracy: 0.882011217948718\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2130, Loss 0.048057299107313156\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.04876935816346071 - Train Accuracy: 0.8764022435897436\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.04853695258498192\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.04884879100017059 - Train Accuracy: 0.8856169871794872\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.04877261444926262\n",
            "\t\tTrain step - Step 2220, Loss 0.048829130828380585\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.04877740058761377 - Train Accuracy: 0.8725961538461539\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2250, Loss 0.04999564215540886\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.048523590637323186 - Train Accuracy: 0.8800080128205128\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2280, Loss 0.0495992973446846\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.048692269776112 - Train Accuracy: 0.8762019230769231\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2310, Loss 0.04913415014743805\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.048458524143848665 - Train Accuracy: 0.8770032051282052\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2340, Loss 0.04840613156557083\n",
            "\t\tTrain step - Step 2370, Loss 0.04883444309234619\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.04844869759220343 - Train Accuracy: 0.8695913461538461\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2400, Loss 0.048499248921871185\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.04838865498701731 - Train Accuracy: 0.8778044871794872\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2430, Loss 0.04918326437473297\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.04834409325550764 - Train Accuracy: 0.8691907051282052\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2460, Loss 0.04808293282985687\n",
            "\t\tTrain step - Step 2490, Loss 0.04870595037937164\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.0483203374613554 - Train Accuracy: 0.8739983974358975\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2520, Loss 0.049666304141283035\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.048124791433413826 - Train Accuracy: 0.8792067307692307\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2550, Loss 0.04864490404725075\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.048067002246777214 - Train Accuracy: 0.8814102564102564\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2580, Loss 0.04785243049263954\n",
            "\t\tTrain step - Step 2610, Loss 0.04748043790459633\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.04800812432017082 - Train Accuracy: 0.8796073717948718\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2640, Loss 0.04913397505879402\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.048062366648362234 - Train Accuracy: 0.8727964743589743\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2670, Loss 0.04922608286142349\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.047880334158738456 - Train Accuracy: 0.8842147435897436\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2700, Loss 0.046985216438770294\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.048047555944858454 - Train Accuracy: 0.8739983974358975\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:01<00:00, 27.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 5:\n",
            "\t\tTrain Mean Accuracy: 0.7680803571428572\n",
            "\t\tTest Accuracy: 0.455\n",
            "\n",
            "STARTING FINE TUNING STAGE 6...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.07799679040908813\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.0920800119638443 - Train Accuracy: 0.06650641025641026\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.07992897927761078\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.07942446397665219 - Train Accuracy: 0.18249198717948717\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.0792359784245491\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.07878926243537511 - Train Accuracy: 0.23517628205128205\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.07607956230640411\n",
            "\t\tTrain step - Step 150, Loss 0.07780830562114716\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.07686255967769867 - Train Accuracy: 0.2826522435897436\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.07444294542074203\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.07604557600540993 - Train Accuracy: 0.30969551282051283\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.0750153437256813\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.07600360421034005 - Train Accuracy: 0.35697115384615385\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 240, Loss 0.07228783518075943\n",
            "\t\tTrain step - Step 270, Loss 0.07243143022060394\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.0750872022830523 - Train Accuracy: 0.3776041666666667\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.07674957066774368\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.07530025010689712 - Train Accuracy: 0.4110576923076923\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.07327084243297577\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.07453060990724808 - Train Accuracy: 0.42748397435897434\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.0727686658501625\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.07419736989033528 - Train Accuracy: 0.44771634615384615\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.07302653789520264\n",
            "\t\tTrain step - Step 420, Loss 0.07342547178268433\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.07428878870530006 - Train Accuracy: 0.46854967948717946\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 450, Loss 0.07213549315929413\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.0739230800133485 - Train Accuracy: 0.5028044871794872\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.0712285190820694\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.07325242841855073 - Train Accuracy: 0.5236378205128205\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.07356270402669907\n",
            "\t\tTrain step - Step 540, Loss 0.07389841973781586\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.0729483879911594 - Train Accuracy: 0.5310496794871795\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.07529624551534653\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.07275473823149999 - Train Accuracy: 0.5528846153846154\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.07125642895698547\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.0726804202183699 - Train Accuracy: 0.5580929487179487\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.06988219916820526\n",
            "\t\tTrain step - Step 660, Loss 0.07342419773340225\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.07233201846098289 - Train Accuracy: 0.5803285256410257\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.0744585394859314\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.07223208382343635 - Train Accuracy: 0.5943509615384616\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.07359923422336578\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.0714583484790264 - Train Accuracy: 0.6276041666666666\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.07074480503797531\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.07145089407761891 - Train Accuracy: 0.6332131410256411\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.07151495665311813\n",
            "\t\tTrain step - Step 810, Loss 0.07147300243377686\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.07199184004312907 - Train Accuracy: 0.6410256410256411\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.0723155289888382\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.07149068801066814 - Train Accuracy: 0.6480368589743589\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 870, Loss 0.06976786255836487\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.0713740539474365 - Train Accuracy: 0.655448717948718\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.06924799084663391\n",
            "\t\tTrain step - Step 930, Loss 0.07232754677534103\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.0710915025228109 - Train Accuracy: 0.6694711538461539\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.0714033767580986\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.07113536218037972 - Train Accuracy: 0.6832932692307693\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.06971219927072525\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.07096565954196148 - Train Accuracy: 0.6905048076923077\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.06859034299850464\n",
            "\t\tTrain step - Step 1050, Loss 0.0710822194814682\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.071030525633922 - Train Accuracy: 0.6947115384615384\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 1080, Loss 0.06993913650512695\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.0710048652612246 - Train Accuracy: 0.7005208333333334\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.07032191008329391\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.0702935652090953 - Train Accuracy: 0.7133413461538461\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.06938723474740982\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.07007382599971233 - Train Accuracy: 0.7229567307692307\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.0701608657836914\n",
            "\t\tTrain step - Step 1200, Loss 0.07106464356184006\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.07020767434285237 - Train Accuracy: 0.7215544871794872\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.07096706330776215\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.07039301651410568 - Train Accuracy: 0.7251602564102564\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.06999693065881729\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.07023866837605452 - Train Accuracy: 0.7295673076923077\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1290, Loss 0.07291252166032791\n",
            "\t\tTrain step - Step 1320, Loss 0.06918700784444809\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.0699453116991581 - Train Accuracy: 0.7347756410256411\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.0700184777379036\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.06990026396054488 - Train Accuracy: 0.7377804487179487\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.06901220977306366\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.07042999584705402 - Train Accuracy: 0.7389823717948718\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.07021372765302658\n",
            "\t\tTrain step - Step 1440, Loss 0.07308906316757202\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.06974760939677556 - Train Accuracy: 0.7471955128205128\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.07125037163496017\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.06960238478122613 - Train Accuracy: 0.7674278846153846\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1500, Loss 0.07011955231428146\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.06962355092549935 - Train Accuracy: 0.7658253205128205\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.06879811733961105\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.06986953757512264 - Train Accuracy: 0.7708333333333334\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.06794770061969757\n",
            "\t\tTrain step - Step 1590, Loss 0.0698653981089592\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.06955305181252651 - Train Accuracy: 0.7682291666666666\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.07056698948144913\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.06896829624206592 - Train Accuracy: 0.772636217948718\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.06808657199144363\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.06862170535784501 - Train Accuracy: 0.7784455128205128\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.06893189996480942\n",
            "\t\tTrain step - Step 1710, Loss 0.06961756944656372\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.06845866735929097 - Train Accuracy: 0.8002804487179487\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1740, Loss 0.06728474795818329\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.0681747501859298 - Train Accuracy: 0.7940705128205128\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1770, Loss 0.0699591264128685\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.06873020224082164 - Train Accuracy: 0.7906650641025641\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1800, Loss 0.06772945076227188\n",
            "\t\tTrain step - Step 1830, Loss 0.07110368460416794\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.06840973366529514 - Train Accuracy: 0.7958733974358975\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1860, Loss 0.069745734333992\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.06839680385131103 - Train Accuracy: 0.8002804487179487\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1890, Loss 0.06687061488628387\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.06829067950065319 - Train Accuracy: 0.8030849358974359\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1920, Loss 0.06710654497146606\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.0655194668051524 - Train Accuracy: 0.8411458333333334\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.06296716630458832\n",
            "\t\tTrain step - Step 1980, Loss 0.06393998861312866\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.06397510253084011 - Train Accuracy: 0.8473557692307693\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.06463229656219482\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.06358619034290314 - Train Accuracy: 0.859375\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.06381906569004059\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.06317477787916477 - Train Accuracy: 0.8543669871794872\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.0643153190612793\n",
            "\t\tTrain step - Step 2100, Loss 0.06261250376701355\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.06304405600978778 - Train Accuracy: 0.8521634615384616\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2130, Loss 0.06106502562761307\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.0628290457221178 - Train Accuracy: 0.8513621794871795\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.06264419108629227\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.06281184997314061 - Train Accuracy: 0.8503605769230769\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.06018979847431183\n",
            "\t\tTrain step - Step 2220, Loss 0.062000732868909836\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.06265917496803479 - Train Accuracy: 0.8617788461538461\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2250, Loss 0.061590876430273056\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.06235785629504766 - Train Accuracy: 0.8493589743589743\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2280, Loss 0.06162847951054573\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.06245578376528544 - Train Accuracy: 0.8581730769230769\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2310, Loss 0.06187928095459938\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.062315455613992154 - Train Accuracy: 0.8579727564102564\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2340, Loss 0.06246117502450943\n",
            "\t\tTrain step - Step 2370, Loss 0.0632329061627388\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.06227441227588898 - Train Accuracy: 0.8625801282051282\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2400, Loss 0.06136969476938248\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.06210142584183277 - Train Accuracy: 0.8501602564102564\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2430, Loss 0.0627862736582756\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.06232302932020945 - Train Accuracy: 0.8517628205128205\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2460, Loss 0.06237081438302994\n",
            "\t\tTrain step - Step 2490, Loss 0.06030479446053505\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.06203257617277977 - Train Accuracy: 0.8615785256410257\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2520, Loss 0.06170032545924187\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.061867618981080175 - Train Accuracy: 0.8587740384615384\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2550, Loss 0.061458948999643326\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.06181865624892406 - Train Accuracy: 0.8647836538461539\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2580, Loss 0.06150612235069275\n",
            "\t\tTrain step - Step 2610, Loss 0.06062993034720421\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.06179892892638842 - Train Accuracy: 0.8625801282051282\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2640, Loss 0.0627320259809494\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.06187554181386263 - Train Accuracy: 0.8623798076923077\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2670, Loss 0.06158259138464928\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.06165143665977013 - Train Accuracy: 0.8657852564102564\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2700, Loss 0.061074282974004745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/47 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.0616715846535487 - Train Accuracy: 0.859375\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 47/47 [00:01<00:00, 27.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 6:\n",
            "\t\tTrain Mean Accuracy: 0.6859289148351647\n",
            "\t\tTest Accuracy: 0.39116666666666666\n",
            "\n",
            "STARTING FINE TUNING STAGE 7...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.09355411678552628\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.10580838987460503 - Train Accuracy: 0.08473557692307693\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.09316430240869522\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.09234390751673625 - Train Accuracy: 0.234375\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.08953844010829926\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.09101780045490998 - Train Accuracy: 0.2864583333333333\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.09089900553226471\n",
            "\t\tTrain step - Step 150, Loss 0.08768390119075775\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.08967304153320117 - Train Accuracy: 0.3389423076923077\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.08844521641731262\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.0887977971862524 - Train Accuracy: 0.367588141025641\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.0885271206498146\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.08813168280399762 - Train Accuracy: 0.39903846153846156\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 240, Loss 0.08617671579122543\n",
            "\t\tTrain step - Step 270, Loss 0.08645661175251007\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.08796221342606422 - Train Accuracy: 0.4296875\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.08737017214298248\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.08720808380689377 - Train Accuracy: 0.4639423076923077\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.08638511598110199\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.08692520321943821 - Train Accuracy: 0.47676282051282054\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.08574335277080536\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.08629348797675891 - Train Accuracy: 0.5010016025641025\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.08751416951417923\n",
            "\t\tTrain step - Step 420, Loss 0.08525766432285309\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.08578895548215279 - Train Accuracy: 0.5278445512820513\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 450, Loss 0.08775704354047775\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.08567317403279819 - Train Accuracy: 0.5424679487179487\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.08684053272008896\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.08585730233253577 - Train Accuracy: 0.563301282051282\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.0824458971619606\n",
            "\t\tTrain step - Step 540, Loss 0.08679567277431488\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.08510845823165698 - Train Accuracy: 0.5823317307692307\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.08374035358428955\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.08539027395920876 - Train Accuracy: 0.5975560897435898\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.08543189615011215\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.08505096859656848 - Train Accuracy: 0.6075721153846154\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.08275371044874191\n",
            "\t\tTrain step - Step 660, Loss 0.08593543618917465\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.08553765332087493 - Train Accuracy: 0.624198717948718\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.08628062903881073\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.0845022140405117 - Train Accuracy: 0.6264022435897436\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.08440845459699631\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.08445889483659695 - Train Accuracy: 0.6422275641025641\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.08308980613946915\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.08421591631112954 - Train Accuracy: 0.6566506410256411\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.08357034623622894\n",
            "\t\tTrain step - Step 810, Loss 0.08155084401369095\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.08392843508567566 - Train Accuracy: 0.6664663461538461\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.08388781547546387\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.08385061415342185 - Train Accuracy: 0.6692708333333334\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 870, Loss 0.08428636193275452\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.08399500659643075 - Train Accuracy: 0.6742788461538461\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.0844103991985321\n",
            "\t\tTrain step - Step 930, Loss 0.08280542492866516\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.08404788374900818 - Train Accuracy: 0.7049278846153846\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.08254600316286087\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.08367620064662053 - Train Accuracy: 0.7017227564102564\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.08316656202077866\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.0833766221618041 - Train Accuracy: 0.7223557692307693\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.08110614866018295\n",
            "\t\tTrain step - Step 1050, Loss 0.08324210345745087\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.0832112974081284 - Train Accuracy: 0.7193509615384616\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 1080, Loss 0.08395992964506149\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.08301340502042037 - Train Accuracy: 0.7277644230769231\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.08392921090126038\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.08309599623466149 - Train Accuracy: 0.7293669871794872\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.08182185888290405\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.08304466211642975 - Train Accuracy: 0.7391826923076923\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.08350229263305664\n",
            "\t\tTrain step - Step 1200, Loss 0.08322910219430923\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.08326648290340717 - Train Accuracy: 0.7407852564102564\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.0825984850525856\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.08296667765348385 - Train Accuracy: 0.7461939102564102\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.08242819458246231\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.08262270287825511 - Train Accuracy: 0.7544070512820513\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1290, Loss 0.08150555193424225\n",
            "\t\tTrain step - Step 1320, Loss 0.08252029865980148\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.08267865158044375 - Train Accuracy: 0.7516025641025641\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.08134529739618301\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.08198553113601147 - Train Accuracy: 0.7682291666666666\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.08278622478246689\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.08235827336708705 - Train Accuracy: 0.7658253205128205\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.08221423625946045\n",
            "\t\tTrain step - Step 1440, Loss 0.08080463111400604\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.08194358360308868 - Train Accuracy: 0.7754407051282052\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.08044248074293137\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.08178531703276512 - Train Accuracy: 0.7728365384615384\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1500, Loss 0.07999727874994278\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.08168936979312164 - Train Accuracy: 0.7858573717948718\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.0816783681511879\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.08147316406934689 - Train Accuracy: 0.7872596153846154\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.08057473599910736\n",
            "\t\tTrain step - Step 1590, Loss 0.08277776837348938\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.08173262729094578 - Train Accuracy: 0.7862580128205128\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.08185166120529175\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.08219498644272487 - Train Accuracy: 0.7850560897435898\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.08419530838727951\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.0823211941199425 - Train Accuracy: 0.7868589743589743\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.08339475095272064\n",
            "\t\tTrain step - Step 1710, Loss 0.08123251050710678\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.08170231068745637 - Train Accuracy: 0.7904647435897436\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1740, Loss 0.08140669763088226\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.0818541197058482 - Train Accuracy: 0.7980769230769231\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1770, Loss 0.08188226819038391\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.08165907859802246 - Train Accuracy: 0.7978766025641025\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1800, Loss 0.0823487639427185\n",
            "\t\tTrain step - Step 1830, Loss 0.0812520757317543\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.08160216475908573 - Train Accuracy: 0.8034855769230769\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1860, Loss 0.08245766162872314\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.08144144408213787 - Train Accuracy: 0.8094951923076923\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1890, Loss 0.07981999963521957\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.08106399614077348 - Train Accuracy: 0.8122996794871795\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1920, Loss 0.08085355907678604\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.07881554235250522 - Train Accuracy: 0.8441506410256411\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.07761082798242569\n",
            "\t\tTrain step - Step 1980, Loss 0.07537841796875\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.07718245188395183 - Train Accuracy: 0.8595753205128205\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.07665754854679108\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.07676672878173682 - Train Accuracy: 0.8509615384615384\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.0776265412569046\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.07667692330403206 - Train Accuracy: 0.8513621794871795\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.07752873748540878\n",
            "\t\tTrain step - Step 2100, Loss 0.07730752974748611\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.07619085143773983 - Train Accuracy: 0.8575721153846154\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2130, Loss 0.07693668454885483\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.07628876314713405 - Train Accuracy: 0.8543669871794872\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.07723639905452728\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.0762633849412967 - Train Accuracy: 0.8505608974358975\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.07606512308120728\n",
            "\t\tTrain step - Step 2220, Loss 0.07682039588689804\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.07610763208224224 - Train Accuracy: 0.8595753205128205\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2250, Loss 0.07551229000091553\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.0761714247174752 - Train Accuracy: 0.8535657051282052\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2280, Loss 0.07556561380624771\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.0759178503201558 - Train Accuracy: 0.8517628205128205\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2310, Loss 0.07558594644069672\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.07595116511369362 - Train Accuracy: 0.8497596153846154\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2340, Loss 0.07583580166101456\n",
            "\t\tTrain step - Step 2370, Loss 0.07463345676660538\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.07582611304063064 - Train Accuracy: 0.8577724358974359\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2400, Loss 0.07500720769166946\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.0757080125503051 - Train Accuracy: 0.850761217948718\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2430, Loss 0.07525338977575302\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.07558820052788807 - Train Accuracy: 0.8547676282051282\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2460, Loss 0.07730887085199356\n",
            "\t\tTrain step - Step 2490, Loss 0.07506368309259415\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.07544436592322129 - Train Accuracy: 0.8639823717948718\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2520, Loss 0.07487156987190247\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.0753112752468158 - Train Accuracy: 0.8591746794871795\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2550, Loss 0.07754561305046082\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.0752849647632012 - Train Accuracy: 0.8559695512820513\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2580, Loss 0.07483534514904022\n",
            "\t\tTrain step - Step 2610, Loss 0.0737728402018547\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.07535517597809815 - Train Accuracy: 0.8641826923076923\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2640, Loss 0.0750778466463089\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.07539529124131569 - Train Accuracy: 0.8581730769230769\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2670, Loss 0.07605960965156555\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.07539174113518153 - Train Accuracy: 0.8579727564102564\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2700, Loss 0.07489999383687973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/55 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.07526686481940441 - Train Accuracy: 0.8639823717948718\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 55/55 [00:01<00:00, 29.18it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 7:\n",
            "\t\tTrain Mean Accuracy: 0.7056576236263736\n",
            "\t\tTest Accuracy: 0.38757142857142857\n",
            "\n",
            "STARTING FINE TUNING STAGE 8...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n",
            "\t\tTrain step - Step 30, Loss 0.10251908749341965\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.11742571817758755 - Train Accuracy: 0.08393429487179487\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.104041188955307\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.10390253269519562 - Train Accuracy: 0.20192307692307693\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.10322429239749908\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.10289465941679783 - Train Accuracy: 0.2483974358974359\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.10238239169120789\n",
            "\t\tTrain step - Step 150, Loss 0.10086394846439362\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.10200818761801109 - Train Accuracy: 0.2750400641025641\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.10153094679117203\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.10134903914653338 - Train Accuracy: 0.2994791666666667\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.09927263110876083\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.1008974884947141 - Train Accuracy: 0.3217147435897436\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 240, Loss 0.1019151508808136\n",
            "\t\tTrain step - Step 270, Loss 0.10019168257713318\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.10040904963627839 - Train Accuracy: 0.3489583333333333\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.098324716091156\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.09986145641559209 - Train Accuracy: 0.3719951923076923\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.1010071337223053\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.09969368901772377 - Train Accuracy: 0.3948317307692308\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.10183805972337723\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.0997132406784938 - Train Accuracy: 0.40905448717948717\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.10139212012290955\n",
            "\t\tTrain step - Step 420, Loss 0.10186069458723068\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.0995104404596182 - Train Accuracy: 0.4286858974358974\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 450, Loss 0.09846913069486618\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.09885271122822395 - Train Accuracy: 0.43249198717948717\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.09775438159704208\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.09900647153457005 - Train Accuracy: 0.46794871794871795\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.09833701699972153\n",
            "\t\tTrain step - Step 540, Loss 0.09961042553186417\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.09910860523963586 - Train Accuracy: 0.46654647435897434\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.09977760910987854\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.098848734719631 - Train Accuracy: 0.48257211538461536\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.10046185553073883\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.09882012544534145 - Train Accuracy: 0.4969951923076923\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.09611226618289948\n",
            "\t\tTrain step - Step 660, Loss 0.09707728028297424\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.09810537329086891 - Train Accuracy: 0.5072115384615384\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.09818319976329803\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.09839572050632575 - Train Accuracy: 0.530448717948718\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.09738853573799133\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.09845893963789329 - Train Accuracy: 0.5384615384615384\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.10043083131313324\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.09833161609295087 - Train Accuracy: 0.5414663461538461\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.10279931128025055\n",
            "\t\tTrain step - Step 810, Loss 0.09742200374603271\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.09792300734000328 - Train Accuracy: 0.5691105769230769\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.09778252243995667\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.09734145953105046 - Train Accuracy: 0.5839342948717948\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 870, Loss 0.09815338999032974\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.09808754347837888 - Train Accuracy: 0.5767227564102564\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.09490504860877991\n",
            "\t\tTrain step - Step 930, Loss 0.09955001622438431\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.09804182117566085 - Train Accuracy: 0.5911458333333334\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.09705507010221481\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.09799942527061854 - Train Accuracy: 0.608573717948718\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.09502492845058441\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.09707629623321387 - Train Accuracy: 0.616386217948718\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.09336274862289429\n",
            "\t\tTrain step - Step 1050, Loss 0.09959731996059418\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.09706197526210393 - Train Accuracy: 0.6294070512820513\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 1080, Loss 0.0960930809378624\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.09746686865886052 - Train Accuracy: 0.6400240384615384\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.09718316048383713\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.09721402651988544 - Train Accuracy: 0.6348157051282052\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.09670097380876541\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.09730809525801586 - Train Accuracy: 0.6448317307692307\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.09601518511772156\n",
            "\t\tTrain step - Step 1200, Loss 0.09753917157649994\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.09675213331595445 - Train Accuracy: 0.6806891025641025\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.09848915785551071\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.09672562223978531 - Train Accuracy: 0.6782852564102564\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.09703061729669571\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.09681909283002217 - Train Accuracy: 0.6830929487179487\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1290, Loss 0.09727784991264343\n",
            "\t\tTrain step - Step 1320, Loss 0.0974312499165535\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.09704204075611554 - Train Accuracy: 0.6812900641025641\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.09935484081506729\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.09661641869789515 - Train Accuracy: 0.6824919871794872\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.1009468138217926\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.09683242745888539 - Train Accuracy: 0.6959134615384616\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.09588780999183655\n",
            "\t\tTrain step - Step 1440, Loss 0.09874092042446136\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.09682205090155968 - Train Accuracy: 0.6981169871794872\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.09655259549617767\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.09658591487468818 - Train Accuracy: 0.7147435897435898\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1500, Loss 0.09855495393276215\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.09657175552386504 - Train Accuracy: 0.7141426282051282\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.09914965182542801\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.09665703429625584 - Train Accuracy: 0.7189503205128205\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.09354373067617416\n",
            "\t\tTrain step - Step 1590, Loss 0.09777702391147614\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.09634921642450187 - Train Accuracy: 0.7237580128205128\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.09785701334476471\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.09641954340995887 - Train Accuracy: 0.7165464743589743\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.09696614742279053\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.09607441608722393 - Train Accuracy: 0.734375\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.09593238681554794\n",
            "\t\tTrain step - Step 1710, Loss 0.09786561131477356\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.09609776123976096 - Train Accuracy: 0.7457932692307693\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1740, Loss 0.09602361172437668\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.0959817858842703 - Train Accuracy: 0.7355769230769231\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1770, Loss 0.09577217698097229\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.09637972005666831 - Train Accuracy: 0.7373798076923077\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1800, Loss 0.09669904410839081\n",
            "\t\tTrain step - Step 1830, Loss 0.09685321897268295\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.09612471954180644 - Train Accuracy: 0.7397836538461539\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1860, Loss 0.09587111324071884\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.09541383347450158 - Train Accuracy: 0.7686298076923077\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1890, Loss 0.09627969563007355\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.09521860648424198 - Train Accuracy: 0.7690304487179487\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1920, Loss 0.09344861656427383\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.09237144753718987 - Train Accuracy: 0.7884615384615384\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.09064821153879166\n",
            "\t\tTrain step - Step 1980, Loss 0.09180495887994766\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.09096164237230252 - Train Accuracy: 0.8050881410256411\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.09101811796426773\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.09049526945902751 - Train Accuracy: 0.7996794871794872\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.08962913602590561\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.08998528466774867 - Train Accuracy: 0.8104967948717948\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.08940847218036652\n",
            "\t\tTrain step - Step 2100, Loss 0.09016098082065582\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.08994318640384918 - Train Accuracy: 0.8066907051282052\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2130, Loss 0.08933980762958527\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.08993407988395447 - Train Accuracy: 0.8139022435897436\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.09043330699205399\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.08996951408111133 - Train Accuracy: 0.8098958333333334\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.09158815443515778\n",
            "\t\tTrain step - Step 2220, Loss 0.08942556381225586\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.08968249536477603 - Train Accuracy: 0.8143028846153846\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2250, Loss 0.09059272706508636\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.08971937421040657 - Train Accuracy: 0.8062900641025641\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2280, Loss 0.08977964520454407\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.0895518347238883 - Train Accuracy: 0.8137019230769231\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2310, Loss 0.08933880925178528\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.08948719577911572 - Train Accuracy: 0.8088942307692307\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2340, Loss 0.08779110759496689\n",
            "\t\tTrain step - Step 2370, Loss 0.08951272070407867\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.08948015173276265 - Train Accuracy: 0.8139022435897436\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2400, Loss 0.08888104557991028\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.0892630383754388 - Train Accuracy: 0.8131009615384616\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2430, Loss 0.08942168951034546\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.08928624445047134 - Train Accuracy: 0.8163060897435898\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2460, Loss 0.08886794745922089\n",
            "\t\tTrain step - Step 2490, Loss 0.08891662210226059\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.08908223379880954 - Train Accuracy: 0.8165064102564102\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2520, Loss 0.08867226541042328\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.0891385806294588 - Train Accuracy: 0.8235176282051282\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2550, Loss 0.08826829493045807\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.0890115363857685 - Train Accuracy: 0.8327323717948718\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2580, Loss 0.09051074087619781\n",
            "\t\tTrain step - Step 2610, Loss 0.08846267312765121\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.0890825927639619 - Train Accuracy: 0.8223157051282052\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2640, Loss 0.09035911411046982\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.08887705608056141 - Train Accuracy: 0.8153044871794872\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2670, Loss 0.0878644734621048\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.0888490120951946 - Train Accuracy: 0.8269230769230769\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2700, Loss 0.08907747268676758\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/63 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.08873887111743291 - Train Accuracy: 0.8259214743589743\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 63/63 [00:02<00:00, 28.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 8:\n",
            "\t\tTrain Mean Accuracy: 0.6377947573260074\n",
            "\t\tTest Accuracy: 0.34575\n",
            "\n",
            "STARTING FINE TUNING STAGE 9...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.11386514455080032\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.12996806586400056 - Train Accuracy: 0.10616987179487179\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.11746755242347717\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.11569970846176147 - Train Accuracy: 0.27564102564102566\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.11580441147089005\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.11534556517234215 - Train Accuracy: 0.31330128205128205\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.11348264664411545\n",
            "\t\tTrain step - Step 150, Loss 0.11101028323173523\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.11436708137775078 - Train Accuracy: 0.36017628205128205\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.11521047353744507\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.11361028502384822 - Train Accuracy: 0.38882211538461536\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.11671555042266846\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.1132706310122441 - Train Accuracy: 0.4244791666666667\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 240, Loss 0.11078191548585892\n",
            "\t\tTrain step - Step 270, Loss 0.10967250913381577\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.11242616520478176 - Train Accuracy: 0.4421073717948718\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.11294219642877579\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.11209124689682937 - Train Accuracy: 0.4717548076923077\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.11157483607530594\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.1119947727674093 - Train Accuracy: 0.4857772435897436\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.11186136305332184\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.11156727526432429 - Train Accuracy: 0.5074118589743589\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.11152072995901108\n",
            "\t\tTrain step - Step 420, Loss 0.11667586863040924\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.11151608882042077 - Train Accuracy: 0.5262419871794872\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 450, Loss 0.11215800791978836\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.11114673966016525 - Train Accuracy: 0.5516826923076923\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.1124337762594223\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.11094769185934311 - Train Accuracy: 0.5673076923076923\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.11379662901163101\n",
            "\t\tTrain step - Step 540, Loss 0.11345557868480682\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.1108931962114114 - Train Accuracy: 0.5751201923076923\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.11127567291259766\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.11064867713512519 - Train Accuracy: 0.59375\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.10976505279541016\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.11005921814686213 - Train Accuracy: 0.6053685897435898\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.11062072217464447\n",
            "\t\tTrain step - Step 660, Loss 0.11290288716554642\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.11007936566303937 - Train Accuracy: 0.6111778846153846\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.11232463270425797\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.11043452395078464 - Train Accuracy: 0.625\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.1102997213602066\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.11017845647457318 - Train Accuracy: 0.6408253205128205\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.11102738976478577\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.10991901216598657 - Train Accuracy: 0.6442307692307693\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.10893138498067856\n",
            "\t\tTrain step - Step 810, Loss 0.10960301011800766\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.10954769204060237 - Train Accuracy: 0.6510416666666666\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.11226624995470047\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.10928240571266566 - Train Accuracy: 0.6604567307692307\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 870, Loss 0.1111886203289032\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.10950602132540482 - Train Accuracy: 0.6684695512820513\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.10726632922887802\n",
            "\t\tTrain step - Step 930, Loss 0.11002751439809799\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.10944819469482471 - Train Accuracy: 0.6858974358974359\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.10869817435741425\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.10917422079887146 - Train Accuracy: 0.6953125\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.11079684644937515\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.10905761348131375 - Train Accuracy: 0.6856971153846154\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.11146225780248642\n",
            "\t\tTrain step - Step 1050, Loss 0.11052419245243073\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.10961555746885446 - Train Accuracy: 0.7029246794871795\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 1080, Loss 0.10908021777868271\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.10933290058985734 - Train Accuracy: 0.7073317307692307\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.11082931607961655\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.1096722302146447 - Train Accuracy: 0.7137419871794872\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.10948992520570755\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.10880221388278863 - Train Accuracy: 0.7213541666666666\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.11044968664646149\n",
            "\t\tTrain step - Step 1200, Loss 0.10850664228200912\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.10879821693285918 - Train Accuracy: 0.7261618589743589\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.1096910610795021\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.10897892942795387 - Train Accuracy: 0.7365785256410257\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.10976213216781616\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.10888089296909478 - Train Accuracy: 0.727363782051282\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1290, Loss 0.10878850519657135\n",
            "\t\tTrain step - Step 1320, Loss 0.10718156397342682\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.10838837100145145 - Train Accuracy: 0.7481971153846154\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.11002162098884583\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.10837269727236186 - Train Accuracy: 0.7447916666666666\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.1070287898182869\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.10868263760438332 - Train Accuracy: 0.758613782051282\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.10890807956457138\n",
            "\t\tTrain step - Step 1440, Loss 0.10992040485143661\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.1089676612844834 - Train Accuracy: 0.7524038461538461\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.11007192730903625\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.10794669810013893 - Train Accuracy: 0.7706330128205128\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1500, Loss 0.10742086172103882\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.10815625886122386 - Train Accuracy: 0.7710336538461539\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.1089622750878334\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.1081689831155997 - Train Accuracy: 0.7696314102564102\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.1065530851483345\n",
            "\t\tTrain step - Step 1590, Loss 0.1078038215637207\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.10797648380200069 - Train Accuracy: 0.7852564102564102\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.10865429788827896\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.10794352988402049 - Train Accuracy: 0.782051282051282\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.10697226971387863\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.10801256409822366 - Train Accuracy: 0.7810496794871795\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.10809370130300522\n",
            "\t\tTrain step - Step 1710, Loss 0.10678108036518097\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.10751646241316429 - Train Accuracy: 0.7868589743589743\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1740, Loss 0.10851798951625824\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.1075605604893122 - Train Accuracy: 0.7880608974358975\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1770, Loss 0.10942596197128296\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.10779691888735844 - Train Accuracy: 0.7838541666666666\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1800, Loss 0.10705610364675522\n",
            "\t\tTrain step - Step 1830, Loss 0.1069498136639595\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.10738692910243304 - Train Accuracy: 0.7938701923076923\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1860, Loss 0.10750924795866013\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.10724710443845162 - Train Accuracy: 0.797676282051282\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1890, Loss 0.10742443054914474\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.1070335899025966 - Train Accuracy: 0.8012820512820513\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1920, Loss 0.1045110672712326\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.10470452790076916 - Train Accuracy: 0.8263221153846154\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.1028217300772667\n",
            "\t\tTrain step - Step 1980, Loss 0.10250354558229446\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.10303200628512944 - Train Accuracy: 0.8433493589743589\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.10383376479148865\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.1027426303197176 - Train Accuracy: 0.8369391025641025\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.10266049206256866\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.10265214129900321 - Train Accuracy: 0.8393429487179487\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.10187354683876038\n",
            "\t\tTrain step - Step 2100, Loss 0.10321372747421265\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.10229421789065385 - Train Accuracy: 0.8405448717948718\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2130, Loss 0.1017300933599472\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.10223040213951698 - Train Accuracy: 0.8365384615384616\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.10322777181863785\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.10202000519404045 - Train Accuracy: 0.8421474358974359\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.10205671936273575\n",
            "\t\tTrain step - Step 2220, Loss 0.1014777347445488\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.10197009642918904 - Train Accuracy: 0.8493589743589743\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2250, Loss 0.10318757593631744\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.10208062139841226 - Train Accuracy: 0.8421474358974359\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2280, Loss 0.10177060961723328\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.10186680444540122 - Train Accuracy: 0.8483573717948718\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2310, Loss 0.10028553009033203\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.1017662647825021 - Train Accuracy: 0.8333333333333334\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2340, Loss 0.10184823721647263\n",
            "\t\tTrain step - Step 2370, Loss 0.10289963334798813\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.10175529638162026 - Train Accuracy: 0.8433493589743589\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2400, Loss 0.10153083503246307\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.101604951497836 - Train Accuracy: 0.8493589743589743\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2430, Loss 0.10110625624656677\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.10196255968931393 - Train Accuracy: 0.8405448717948718\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2460, Loss 0.10010141134262085\n",
            "\t\tTrain step - Step 2490, Loss 0.10094046592712402\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.10133630705949588 - Train Accuracy: 0.8493589743589743\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2520, Loss 0.10257993638515472\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.10133692794121228 - Train Accuracy: 0.8527644230769231\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2550, Loss 0.10115692019462585\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.10118872423966725 - Train Accuracy: 0.8549679487179487\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2580, Loss 0.10076933354139328\n",
            "\t\tTrain step - Step 2610, Loss 0.10297399014234543\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.10127505927513807 - Train Accuracy: 0.8465544871794872\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2640, Loss 0.10192891955375671\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.10122099022070567 - Train Accuracy: 0.8521634615384616\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2670, Loss 0.1020520031452179\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.1010606743586369 - Train Accuracy: 0.8551682692307693\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2700, Loss 0.1005011722445488\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/71 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.10096422793009342 - Train Accuracy: 0.8505608974358975\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 71/71 [00:02<00:00, 29.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 9:\n",
            "\t\tTrain Mean Accuracy: 0.6992445054945055\n",
            "\t\tTest Accuracy: 0.3228888888888889\n",
            "\n",
            "STARTING FINE TUNING STAGE 10...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.1318495273590088\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.14578223266662696 - Train Accuracy: 0.0889423076923077\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.1308930367231369\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.13293213187119898 - Train Accuracy: 0.21314102564102563\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.13096213340759277\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.1324401738551947 - Train Accuracy: 0.24959935897435898\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.1293598860502243\n",
            "\t\tTrain step - Step 150, Loss 0.12795795500278473\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.13072092219805106 - Train Accuracy: 0.2916666666666667\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.1286398470401764\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.12979186192536965 - Train Accuracy: 0.30749198717948717\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.12678134441375732\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.12881015890683883 - Train Accuracy: 0.32471955128205127\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 240, Loss 0.13111469149589539\n",
            "\t\tTrain step - Step 270, Loss 0.13017362356185913\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.12834892746729729 - Train Accuracy: 0.35697115384615385\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.1298987865447998\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.12850961413903114 - Train Accuracy: 0.36939102564102566\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.12760455906391144\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.1277640693080731 - Train Accuracy: 0.38501602564102566\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.12943656742572784\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.12796178784890053 - Train Accuracy: 0.4098557692307692\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.12864816188812256\n",
            "\t\tTrain step - Step 420, Loss 0.12696251273155212\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.1282335204573778 - Train Accuracy: 0.42467948717948717\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 450, Loss 0.12860383093357086\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.12737112874403977 - Train Accuracy: 0.44250801282051283\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.1275404542684555\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.1268455894329609 - Train Accuracy: 0.44971955128205127\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.12718957662582397\n",
            "\t\tTrain step - Step 540, Loss 0.1260768324136734\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.1269526760547589 - Train Accuracy: 0.4577323717948718\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.1267901360988617\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.1267001116887117 - Train Accuracy: 0.47876602564102566\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.1274728775024414\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.12677332300406235 - Train Accuracy: 0.476161858974359\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.1256791055202484\n",
            "\t\tTrain step - Step 660, Loss 0.12537407875061035\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.12630291092090118 - Train Accuracy: 0.49559294871794873\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.12427736073732376\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.12654306414799812 - Train Accuracy: 0.5042067307692307\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.12764480710029602\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.1263772251132207 - Train Accuracy: 0.5282451923076923\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.12470388412475586\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.1264742998740612 - Train Accuracy: 0.5264423076923077\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.1261700540781021\n",
            "\t\tTrain step - Step 810, Loss 0.12457334250211716\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.1261078547208737 - Train Accuracy: 0.53125\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.12511464953422546\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.1254784210752218 - Train Accuracy: 0.5490785256410257\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 870, Loss 0.12722013890743256\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.12589717484437501 - Train Accuracy: 0.5572916666666666\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.12581950426101685\n",
            "\t\tTrain step - Step 930, Loss 0.12572985887527466\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.1253687729820227 - Train Accuracy: 0.5610977564102564\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.12414861470460892\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.12576100650506142 - Train Accuracy: 0.5805288461538461\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.12599904835224152\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.12542563543105736 - Train Accuracy: 0.5939503205128205\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.1257394403219223\n",
            "\t\tTrain step - Step 1050, Loss 0.12704943120479584\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.12545963625113168 - Train Accuracy: 0.5787259615384616\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 1080, Loss 0.12307903915643692\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.12542443359509492 - Train Accuracy: 0.6049679487179487\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.1241145133972168\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.12534239964607435 - Train Accuracy: 0.6135817307692307\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.12786662578582764\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.12502082246236312 - Train Accuracy: 0.6119791666666666\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.12636622786521912\n",
            "\t\tTrain step - Step 1200, Loss 0.1255105584859848\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.12542751202216515 - Train Accuracy: 0.6294070512820513\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.1264028698205948\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.1247704036724873 - Train Accuracy: 0.6374198717948718\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.1251007467508316\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.1249202440182368 - Train Accuracy: 0.6386217948717948\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1290, Loss 0.12451072782278061\n",
            "\t\tTrain step - Step 1320, Loss 0.12837068736553192\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.1250803237542128 - Train Accuracy: 0.6262019230769231\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.12566280364990234\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.12492639399491824 - Train Accuracy: 0.6532451923076923\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.12599273025989532\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.1246080083342699 - Train Accuracy: 0.6606570512820513\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.1242210641503334\n",
            "\t\tTrain step - Step 1440, Loss 0.12527677416801453\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.12416377300635362 - Train Accuracy: 0.6588541666666666\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.12765076756477356\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.1245575392475495 - Train Accuracy: 0.6620592948717948\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1500, Loss 0.1256127655506134\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.12410578188987878 - Train Accuracy: 0.6704727564102564\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.12348151952028275\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.12353208833015882 - Train Accuracy: 0.6790865384615384\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.12301410734653473\n",
            "\t\tTrain step - Step 1590, Loss 0.1237005963921547\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.1240685482819875 - Train Accuracy: 0.6784855769230769\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.12608666718006134\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.12424437319621062 - Train Accuracy: 0.6780849358974359\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.12171219289302826\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.12392542587640958 - Train Accuracy: 0.7007211538461539\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.12304003536701202\n",
            "\t\tTrain step - Step 1710, Loss 0.12414367496967316\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.12356380163094936 - Train Accuracy: 0.6931089743589743\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1740, Loss 0.12374967336654663\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.12357247200531837 - Train Accuracy: 0.6915064102564102\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1770, Loss 0.12501631677150726\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.12398936656805185 - Train Accuracy: 0.6995192307692307\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1800, Loss 0.1226971372961998\n",
            "\t\tTrain step - Step 1830, Loss 0.12512128055095673\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.1241277834543815 - Train Accuracy: 0.7087339743589743\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1860, Loss 0.12356170266866684\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.12322048728282635 - Train Accuracy: 0.7077323717948718\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1890, Loss 0.12438890337944031\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.12421101006941918 - Train Accuracy: 0.7109375\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1920, Loss 0.12035678327083588\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.12030379053873894 - Train Accuracy: 0.7359775641025641\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.11819252371788025\n",
            "\t\tTrain step - Step 1980, Loss 0.11633220314979553\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.11822314636829571 - Train Accuracy: 0.7514022435897436\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.12045619636774063\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.11797761515929149 - Train Accuracy: 0.75\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.1202813908457756\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.1176684347864909 - Train Accuracy: 0.7489983974358975\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.11790895462036133\n",
            "\t\tTrain step - Step 2100, Loss 0.11683055013418198\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.11741044888129601 - Train Accuracy: 0.7650240384615384\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2130, Loss 0.11647115647792816\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.11714874379909955 - Train Accuracy: 0.7684294871794872\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.11663077026605606\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.11702008965687874 - Train Accuracy: 0.765625\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.11642371863126755\n",
            "\t\tTrain step - Step 2220, Loss 0.1163291335105896\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.11697316074218506 - Train Accuracy: 0.757011217948718\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2250, Loss 0.11764594167470932\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.11699304500451455 - Train Accuracy: 0.7650240384615384\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2280, Loss 0.11669855564832687\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.11690502422742355 - Train Accuracy: 0.7638221153846154\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2310, Loss 0.11608009785413742\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.11680946690149796 - Train Accuracy: 0.7734375\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2340, Loss 0.11474030464887619\n",
            "\t\tTrain step - Step 2370, Loss 0.11632973700761795\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.11661703330584061 - Train Accuracy: 0.7712339743589743\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2400, Loss 0.11445846408605576\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.11641716995300391 - Train Accuracy: 0.7788461538461539\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2430, Loss 0.1153753250837326\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.1164745168808179 - Train Accuracy: 0.7710336538461539\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2460, Loss 0.11681633442640305\n",
            "\t\tTrain step - Step 2490, Loss 0.11608411371707916\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.11623375901044944 - Train Accuracy: 0.7790464743589743\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2520, Loss 0.11565341055393219\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.11603838511002369 - Train Accuracy: 0.7852564102564102\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2550, Loss 0.11622310429811478\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.11614064146310855 - Train Accuracy: 0.7794471153846154\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2580, Loss 0.1159052923321724\n",
            "\t\tTrain step - Step 2610, Loss 0.11537820845842361\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.11595063427319893 - Train Accuracy: 0.7780448717948718\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2640, Loss 0.11668011546134949\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.11595266923690453 - Train Accuracy: 0.782051282051282\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2670, Loss 0.11522947251796722\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.1159266451230416 - Train Accuracy: 0.7782451923076923\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2700, Loss 0.11626847833395004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/79 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.11590177107315797 - Train Accuracy: 0.7846554487179487\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [00:02<00:00, 28.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 10:\n",
            "\t\tTrain Mean Accuracy: 0.6068681318681318\n",
            "\t\tTest Accuracy: 0.2914\n",
            "\n",
            "\n",
            "Total time: 32 min 50 sec\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciGlvEWabcbD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a708095-cee9-4000-e830-ddec069deb50"
      },
      "source": [
        "import libs.plots as plots\n",
        "\n",
        "method = f\"lwf_\"\n",
        "plots.plot_accuracy_trend(test_accuracies, method, SEED)\n",
        "plots.plot_confusion_matrix(y_true, y_preds, method, SEED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amC8Qy-yVw8W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa40a2f3-f9cf-49ea-ca67-4a39ef87ccf2"
      },
      "source": [
        "def save_accuracies(train_accuracies, test_accuracies, output=OUTPUT_PATH):\n",
        "  with open(f\"{output}_accuracies.csv\", \"w\", encoding=\"utf8\") as f:\n",
        "    f.write(\"mean_train_acc,test_acc\\n\")\n",
        "    for train, test in zip(train_accuracies, test_accuracies):\n",
        "      f.write(f\"{train},{test}\\n\")\n",
        "    print(\"********** FILE SAVED **********\")\n",
        "\n",
        "\n",
        "save_accuracies(train_accuracies, test_accuracies)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "********** FILE SAVED **********\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}