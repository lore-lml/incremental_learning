{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "IL_fine_tuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "tvETQMX1ipNf",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1Df_YvI2mdf9SoeA1GZLecH_3_mthCWei\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab Account AI\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-LoM_h1IXAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f96f528d-d40f-4c04-c328-ffc9adadc687"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "print(gpu.name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "wwN82ZV7ipNg",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RSnex0bmipNh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "6a690c00-4bb1-420f-ba21-a4bef786d39e"
      },
      "source": [
        "DATASET_ROOT = 'cifar-100-python'\n",
        "CODE_ROOT = 'libs'\n",
        "import os\n",
        "if not os.path.isdir(DATASET_ROOT):\n",
        "    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "    !tar -xf 'cifar-100-python.tar.gz'  \n",
        "    !rm -rf 'cifar-100-python.tar.gz'\n",
        "\n",
        "if not os.path.isdir(CODE_ROOT):\n",
        "  !git clone https://lore-lml:29f601e814e0446c5b17a9f6c3684d1cbd316bcf@github.com/lore-lml/machine-learning2020-incremental_learning.git\n",
        "  !mv 'machine-learning2020-incremental_learning/libs' '.'\n",
        "  !rm -rf 'machine-learning2020-incremental_learning'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Subset\n",
        "from torch.backends import cudnn\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import libs.utils as utils\n",
        "from libs.utils import get_one_hot\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-24 16:47:50--  https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169001437 (161M) [application/x-gzip]\n",
            "Saving to: ‘cifar-100-python.tar.gz’\n",
            "\n",
            "cifar-100-python.ta 100%[===================>] 161.17M  31.4MB/s    in 5.7s    \n",
            "\n",
            "2020-06-24 16:47:56 (28.2 MB/s) - ‘cifar-100-python.tar.gz’ saved [169001437/169001437]\n",
            "\n",
            "Cloning into 'machine-learning2020-incremental_learning'...\n",
            "remote: Enumerating objects: 355, done.\u001b[K\n",
            "remote: Counting objects: 100% (355/355), done.\u001b[K\n",
            "remote: Compressing objects: 100% (254/254), done.\u001b[K\n",
            "remote: Total 355 (delta 133), reused 306 (delta 84), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (355/355), 5.31 MiB | 8.62 MiB/s, done.\n",
            "Resolving deltas: 100% (133/133), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7W9y67yoipNk",
        "colab_type": "text"
      },
      "source": [
        "**SET ARGUMENTS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "r0hjWAP3ipNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "arguments = utils.get_arguments()\n",
        "\n",
        "DEVICE = arguments['DEVICE']\n",
        "NUM_CLASSES = arguments[\"NUM_CLASSES\"] \n",
        "\n",
        "BATCH_SIZE = arguments[\"BATCH_SIZE\"]        # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                                            # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = arguments[\"LR\"]                        # The initial Learning Rate\n",
        "MOMENTUM = arguments[\"MOMENTUM\"]            # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = arguments[\"WEIGHT_DECAY\"]    # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = arguments[\"NUM_EPOCHS\"]        # Total number of training epochs (iterations over dataset)\n",
        "GAMMA = arguments[\"GAMMA\"]                  # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = arguments[\"LOG_FREQUENCY\"]\n",
        "MILESTONES = arguments[\"MILESTONES\"]\n",
        "SEED = 653 #arguments[\"SEED\"]\n",
        "\n",
        "LOSS_TYPE = 'bce'\n",
        "\n",
        "#TRAINING_TYPE = 'FT'\n",
        "TRAINING_TYPE = 'JT'\n",
        "OUTPUT_PATH = f\"RUN1_{TRAINING_TYPE}_seed{SEED}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "SaT8eFDNipNm",
        "colab_type": "text"
      },
      "source": [
        "**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "m-ydAGw4ipNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transforms, eval_transforms = utils.get_train_eval_transforms()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "X7Naz_DdipNp",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "G-Xct5sNipNp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1b6f6bc1-1b1c-4206-c3b4-1c51b7d017e0"
      },
      "source": [
        "train_val_dataset = utils.get_cifar_with_seed(DATASET_ROOT, train_transforms, src='train', seed=SEED)\n",
        "test_dataset = utils.get_cifar_with_seed(DATASET_ROOT, eval_transforms, src='test', seed=SEED)\n",
        "\n",
        "print(f\"Size Training Set: {len(train_val_dataset)}\")\n",
        "print(f\"Size Test Set: {len(test_dataset)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size Training Set: 50000\n",
            "Size Test Set: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xZDP5yXBipNt",
        "colab_type": "text"
      },
      "source": [
        "**Train, Test, Validation functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "secPALBtipNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_batch(net, train_loader, criterion, optimizer, current_step, device=DEVICE):\n",
        "    net.train()\n",
        "    cumulative_loss =.0\n",
        "    running_corrects = 0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        if LOSS_TYPE == 'bce':\n",
        "            labels_enc = get_one_hot(labels, NUM_CLASSES, DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(images)\n",
        "        \n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        \n",
        "        loss = criterion(outputs, labels_enc) if LOSS_TYPE == 'bce'\\\n",
        "                                              else criterion(outputs, labels)\n",
        "        cumulative_loss += loss.item()\n",
        "        \n",
        "        if current_step != 0 and current_step % LOG_FREQUENCY == 0:\n",
        "                print('\\t\\tTrain step - Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_step += 1\n",
        "\n",
        "    return cumulative_loss / len(train_loader), running_corrects, current_step\n",
        "\n",
        "def validate(net, val_loader, criterion, optimizer, device=DEVICE):\n",
        "    net.eval()\n",
        "    cumulative_loss =.0\n",
        "    running_corrects = 0\n",
        "    for images, labels in val_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        if LOSS_TYPE == 'bce':\n",
        "            labels_enc = get_one_hot(labels, NUM_CLASSES, DEVICE)\n",
        "        \n",
        "\n",
        "        outputs = net(images)\n",
        "        \n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        \n",
        "        loss = criterion(outputs, labels_enc) if LOSS_TYPE == 'bce'\\\n",
        "                                              else criterion(outputs, labels)\n",
        "        cumulative_loss += loss.item()\n",
        "\n",
        "\n",
        "    return cumulative_loss / len(val_loader), running_corrects\n",
        "\n",
        "def test(net, test_loader, device=DEVICE):\n",
        "    \n",
        "    # confusion matrix\n",
        "    y_true = []\n",
        "    y_preds = []\n",
        "\n",
        "    running_corrects = 0\n",
        "    for images, labels in tqdm(test_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        net.eval()\n",
        "        outputs = net(images)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "        # confusion matrix\n",
        "        y_true.extend(labels.data.tolist())\n",
        "        y_preds.extend(preds.tolist())\n",
        "\n",
        "   \n",
        "    return running_corrects, y_true, y_preds\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "s5SroLpaipNw",
        "colab_type": "text"
      },
      "source": [
        "**FINE TUNING FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "clnGi_eLipNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fine_tuning(train_val_dataset, test_dataset, max_epoch=NUM_EPOCHS, file_path=OUTPUT_PATH, device=DEVICE):\n",
        "    import math, time\n",
        "    incremental_test = []\n",
        "    train_mean_stage_accuracies = []\n",
        "    val_mean_stage_accuracies = []\n",
        "    test_stage_accuracies = []\n",
        "    cudnn.benchmark\n",
        "    net = utils.get_resnet(32).to(device)\n",
        "    criterion = utils.get_criterion(LOSS_TYPE)\n",
        "    start_time = time.time()\n",
        "    for stage in range(10):\n",
        "        optimizer, scheduler = utils.get_otpmizer_scheduler(net.parameters(), LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA)\n",
        "        print(f\"STARTING FINE TUNING STAGE {stage+1}...\")\n",
        "        # Get indices\n",
        "        # 4000 training, 1000 validation\n",
        "        train_idx, val_idx, test_idx = utils.get_kth_batch(train_val_dataset, test_dataset, stage,\n",
        "                                                                 seed=SEED, train_size=.9, get='indices')\n",
        "        \n",
        "        # Make test set incremental\n",
        "        incremental_test.extend(test_idx)\n",
        "        train_set, val_set, test_set = Subset(train_val_dataset, train_idx),\\\n",
        "                                       Subset(train_val_dataset, val_idx),\\\n",
        "                                       Subset(test_dataset, incremental_test)\n",
        "\n",
        "        # Build data loaders\n",
        "        curr_train_loader = utils.get_train_loader(train_set,batch_size=BATCH_SIZE)\n",
        "        curr_val_loader = utils.get_eval_loader(val_set, batch_size=BATCH_SIZE)\n",
        "        curr_test_loader = utils.get_eval_loader(test_set, batch_size=BATCH_SIZE)\n",
        "\n",
        "        # Init results\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        train_accuracies = []\n",
        "        val_accuracies = []\n",
        "        min_val_loss = -1\n",
        "        current_step = 0\n",
        "        tolerance = 10\n",
        "        for epoch in range(max_epoch):\n",
        "            print(f\"\\tSTARTING EPOCH {epoch+1} - LR={scheduler.get_last_lr()}...\")\n",
        "            curr_result = train_batch(net, curr_train_loader, criterion, optimizer, current_step, device)\n",
        "            curr_train_loss = curr_result[0]\n",
        "            curr_train_accuracy = curr_result[1] / float(BATCH_SIZE * len(curr_train_loader))\n",
        "            current_step = curr_result[2]\n",
        "            \n",
        "            train_losses.append(curr_train_loss)\n",
        "            train_accuracies.append(curr_train_accuracy)\n",
        "            scheduler.step()\n",
        "            \n",
        "            curr_val_loss, val_corrects = validate(net, curr_val_loader, criterion, optimizer, device)\n",
        "            val_losses.append(curr_val_loss)\n",
        "            curr_val_accuracy = val_corrects / float(len(val_set))\n",
        "            val_accuracies.append(curr_val_accuracy)\n",
        "            \n",
        "            print(f\"\\t\\tRESULT EPOCH {epoch+1}:\")\n",
        "            print(f\"\\t\\t\\tTrain Loss: {curr_train_loss} - Train Accuracy: {curr_train_accuracy}\")\n",
        "            print(f\"\\t\\t\\tVal Loss: {curr_val_loss} - Val Accuracy: {curr_val_accuracy}\\n\")\n",
        "            \n",
        "            if math.isnan(curr_val_loss):\n",
        "                tolerance -= 1\n",
        "            else:\n",
        "                tolerance = 10\n",
        "            \n",
        "            if tolerance == 0:\n",
        "                print(f\"STAGE {stage+1} -> EARLY STOPPING\\n\")\n",
        "                break\n",
        "            \n",
        "            if min_val_loss == -1 or min_val_loss > curr_val_loss:\n",
        "                min_val_loss = curr_val_loss\n",
        "                torch.save(net, f\"{file_path}_best_model_finetuning.pth\")\n",
        "        \n",
        "        net = torch.load(f\"{file_path}_best_model_finetuning.pth\").to(device)\n",
        "        corrects, y_true, y_preds = test(net, curr_test_loader, device)\n",
        "        epoch_test_accuracy = corrects / float(len(test_set))\n",
        "        test_stage_accuracies.append(epoch_test_accuracy)\n",
        "        train_mean_stage_accuracies.append(np.mean(train_accuracies))\n",
        "        val_mean_stage_accuracies.append(np.mean(val_accuracies))\n",
        "        \n",
        "        print(f\"\\n\\tResults STAGE {stage+1}:\")\n",
        "        print(f\"\\t\\tTrain Mean Accuracy: {train_mean_stage_accuracies[stage]}\")\n",
        "        print(f\"\\t\\tVal Mean Accuracy: {val_mean_stage_accuracies[stage]}\")\n",
        "        print(f\"\\t\\tTest Accuracy: {test_stage_accuracies[stage]}\\n\")\n",
        "\n",
        "\n",
        "    total_time = int(time.time() - start_time)\n",
        "    min = int(total_time / 60)\n",
        "    sec = total_time % 60\n",
        "    print(f\"\\nTotal time: {min} min {sec} sec\\n\")\n",
        "        \n",
        "    return train_mean_stage_accuracies,\\\n",
        "           val_mean_stage_accuracies,\\\n",
        "           test_stage_accuracies,\\\n",
        "           y_true, y_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sLnI2Dqx6I-",
        "colab_type": "text"
      },
      "source": [
        "**JOINT TRAINING FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44iaChR_yM34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def joint_training(train_val_dataset, test_dataset, max_epoch=NUM_EPOCHS, file_path=OUTPUT_PATH, device=DEVICE):\n",
        "    import math, time\n",
        "    incremental_train = []\n",
        "    incremental_val = []\n",
        "    incremental_test = []\n",
        "    train_mean_stage_accuracies = []\n",
        "    val_mean_stage_accuracies = []\n",
        "    test_stage_accuracies = []\n",
        "    cudnn.benchmark\n",
        "    net = utils.get_resnet(32).to(device)\n",
        "    criterion = utils.get_criterion(LOSS_TYPE)\n",
        "    start_time = time.time()\n",
        "    for stage in range(10):\n",
        "        optimizer, scheduler = utils.get_otpmizer_scheduler(net.parameters(), LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA)\n",
        "        print(f\"STARTING JOINT TRAINING STAGE {stage+1}...\")\n",
        "        # Get indices\n",
        "        # 4000 training, 1000 validation\n",
        "        train_idx, val_idx, test_idx = utils.get_kth_batch(train_val_dataset, test_dataset, stage,\n",
        "                                                                 seed=SEED, train_size=.9, get='indices')\n",
        "        \n",
        "        # Make test set incremental\n",
        "        incremental_train.extend(train_idx)\n",
        "        incremental_val.extend(val_idx)\n",
        "        incremental_test.extend(test_idx)\n",
        "        train_set, val_set, test_set = Subset(train_val_dataset, incremental_train),\\\n",
        "                                       Subset(train_val_dataset, incremental_val),\\\n",
        "                                       Subset(test_dataset, incremental_test)\n",
        "\n",
        "\n",
        "        # Build data loaders\n",
        "        curr_train_loader = utils.get_train_loader(train_set,batch_size=BATCH_SIZE)\n",
        "        curr_val_loader = utils.get_eval_loader(val_set, batch_size=BATCH_SIZE)\n",
        "        curr_test_loader = utils.get_eval_loader(test_set, batch_size=BATCH_SIZE)\n",
        "\n",
        "        # Init results\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        train_accuracies = []\n",
        "        val_accuracies = []\n",
        "        min_val_loss = -1\n",
        "        current_step = 0\n",
        "        tolerance = 10\n",
        "        for epoch in range(max_epoch):\n",
        "            print(f\"\\tSTARTING EPOCH {epoch+1} - LR={scheduler.get_last_lr()}...\")\n",
        "            curr_result = train_batch(net, curr_train_loader, criterion, optimizer, current_step, device)\n",
        "            curr_train_loss = curr_result[0]\n",
        "            curr_train_accuracy = curr_result[1] / float(BATCH_SIZE * len(curr_train_loader))\n",
        "            current_step = curr_result[2]\n",
        "            \n",
        "            train_losses.append(curr_train_loss)\n",
        "            train_accuracies.append(curr_train_accuracy)\n",
        "            scheduler.step()\n",
        "            \n",
        "            curr_val_loss, val_corrects = validate(net, curr_val_loader, criterion, optimizer, device)\n",
        "            val_losses.append(curr_val_loss)\n",
        "            curr_val_accuracy = val_corrects / float(len(val_set))\n",
        "            val_accuracies.append(curr_val_accuracy)\n",
        "            \n",
        "            print(f\"\\t\\tRESULT EPOCH {epoch+1}:\")\n",
        "            print(f\"\\t\\t\\tTrain Loss: {curr_train_loss} - Train Accuracy: {curr_train_accuracy}\")\n",
        "            print(f\"\\t\\t\\tVal Loss: {curr_val_loss} - Val Accuracy: {curr_val_accuracy}\\n\")\n",
        "            \n",
        "            if math.isnan(curr_val_loss):\n",
        "                tolerance -= 1\n",
        "            else:\n",
        "                tolerance = 10\n",
        "            \n",
        "            if tolerance == 0:\n",
        "                print(f\"STAGE {stage+1} -> EARLY STOPPING\\n\")\n",
        "                break\n",
        "            \n",
        "            if min_val_loss == -1 or min_val_loss > curr_val_loss:\n",
        "                min_val_loss = curr_val_loss\n",
        "                torch.save(net, f\"{file_path}_best_model_finetuning.pth\")\n",
        "        \n",
        "        net = torch.load(f\"{file_path}_best_model_finetuning.pth\").to(device)\n",
        "        corrects, y_true, y_preds = test(net, curr_test_loader, device)\n",
        "        epoch_test_accuracy = corrects / float(len(test_set))\n",
        "        test_stage_accuracies.append(epoch_test_accuracy)\n",
        "        train_mean_stage_accuracies.append(np.mean(train_accuracies))\n",
        "        val_mean_stage_accuracies.append(np.mean(val_accuracies))\n",
        "        \n",
        "        print(f\"\\n\\tResults STAGE {stage+1}:\")\n",
        "        print(f\"\\t\\tTrain Mean Accuracy: {train_mean_stage_accuracies[stage]}\")\n",
        "        print(f\"\\t\\tVal Mean Accuracy: {val_mean_stage_accuracies[stage]}\")\n",
        "        print(f\"\\t\\tTest Accuracy: {test_stage_accuracies[stage]}\\n\")\n",
        "\n",
        "\n",
        "    total_time = int(time.time() - start_time)\n",
        "    min = int(total_time / 60)\n",
        "    sec = total_time % 60\n",
        "    print(f\"\\nJOINT TRAININGTotal time: {min} min {sec} sec\\n\")\n",
        "        \n",
        "    return train_mean_stage_accuracies,\\\n",
        "           val_mean_stage_accuracies,\\\n",
        "           test_stage_accuracies,\\\n",
        "           y_true, y_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "bvaYg8SiipNy",
        "colab_type": "text"
      },
      "source": [
        "**FINE TUNING / JOINT TRAINING START**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "i_ejvvl4ipNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "350b5205-fe0a-464e-cac2-b17ff5a00640"
      },
      "source": [
        "train_accuracies,\\\n",
        "val_accuracies,\\\n",
        "test_accuracies,\\\n",
        "y_true, y_preds = fine_tuning(train_val_dataset, test_dataset, NUM_EPOCHS) if TRAINING_TYPE == 'FT' else joint_training(train_val_dataset, test_dataset, NUM_EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "STARTING JOINT TRAINING STAGE 1...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n",
            "\t\tTrain step - Step 30, Loss 0.030520353466272354\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.0669885418776955 - Train Accuracy: 0.165625\n",
            "\t\t\tVal Loss: 0.03065500082448125 - Val Accuracy: 0.3\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.024435386061668396\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.025707097724080086 - Train Accuracy: 0.3964285714285714\n",
            "\t\t\tVal Loss: 0.026496050413697958 - Val Accuracy: 0.374\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.02285441756248474\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.022323554009199144 - Train Accuracy: 0.4928571428571429\n",
            "\t\t\tVal Loss: 0.02199142356403172 - Val Accuracy: 0.534\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.020594138652086258\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.02030337740268026 - Train Accuracy: 0.5542410714285714\n",
            "\t\t\tVal Loss: 0.020742008462548256 - Val Accuracy: 0.558\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 150, Loss 0.018839355558156967\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.018541125687105316 - Train Accuracy: 0.5901785714285714\n",
            "\t\t\tVal Loss: 0.021708876360207796 - Val Accuracy: 0.542\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.017305420711636543\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.017616450733372143 - Train Accuracy: 0.6227678571428571\n",
            "\t\t\tVal Loss: 0.01889376458711922 - Val Accuracy: 0.62\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.01407728623598814\n",
            "\t\tTrain step - Step 240, Loss 0.016939794644713402\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.016689503246120046 - Train Accuracy: 0.6419642857142858\n",
            "\t\t\tVal Loss: 0.01665314892306924 - Val Accuracy: 0.648\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 270, Loss 0.015466495417058468\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.01577236152120999 - Train Accuracy: 0.6636160714285714\n",
            "\t\t\tVal Loss: 0.0164592491928488 - Val Accuracy: 0.65\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.013284444808959961\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.014876333783779826 - Train Accuracy: 0.6926339285714286\n",
            "\t\t\tVal Loss: 0.017227521864697337 - Val Accuracy: 0.654\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.014937996864318848\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.014627394718783243 - Train Accuracy: 0.6964285714285714\n",
            "\t\t\tVal Loss: 0.018131910357624292 - Val Accuracy: 0.628\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.01318421307951212\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.013758052273520402 - Train Accuracy: 0.7147321428571428\n",
            "\t\t\tVal Loss: 0.017048933310434222 - Val Accuracy: 0.682\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.014716872945427895\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.013314009723918779 - Train Accuracy: 0.7274553571428571\n",
            "\t\t\tVal Loss: 0.0176530119497329 - Val Accuracy: 0.644\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 420, Loss 0.013050198554992676\n",
            "\t\tTrain step - Step 450, Loss 0.015769315883517265\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.013057700438158853 - Train Accuracy: 0.725\n",
            "\t\t\tVal Loss: 0.01566172274760902 - Val Accuracy: 0.698\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.012138468213379383\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.012522968410381249 - Train Accuracy: 0.7444196428571429\n",
            "\t\t\tVal Loss: 0.015077165327966213 - Val Accuracy: 0.684\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.01358996145427227\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.01209512148052454 - Train Accuracy: 0.7513392857142858\n",
            "\t\t\tVal Loss: 0.013330295565538108 - Val Accuracy: 0.726\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 540, Loss 0.011275083757936954\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.011234975898904459 - Train Accuracy: 0.7774553571428572\n",
            "\t\t\tVal Loss: 0.013954604975879192 - Val Accuracy: 0.72\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.011282849125564098\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.01129830064518111 - Train Accuracy: 0.7799107142857142\n",
            "\t\t\tVal Loss: 0.013126221718266606 - Val Accuracy: 0.74\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.015078405849635601\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.010669423932475703 - Train Accuracy: 0.7912946428571429\n",
            "\t\t\tVal Loss: 0.014308149111457169 - Val Accuracy: 0.72\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.009085716679692268\n",
            "\t\tTrain step - Step 660, Loss 0.01026215311139822\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.010653479982699667 - Train Accuracy: 0.7912946428571429\n",
            "\t\t\tVal Loss: 0.015836918260902166 - Val Accuracy: 0.692\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.013172502629458904\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.010520213256989206 - Train Accuracy: 0.7921875\n",
            "\t\t\tVal Loss: 0.013753557344898582 - Val Accuracy: 0.728\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.010804862715303898\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.010063827170857362 - Train Accuracy: 0.7991071428571429\n",
            "\t\t\tVal Loss: 0.01594860083423555 - Val Accuracy: 0.682\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.006728967186063528\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.00954821773671678 - Train Accuracy: 0.8116071428571429\n",
            "\t\t\tVal Loss: 0.0132878003641963 - Val Accuracy: 0.728\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.008857437409460545\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.009217668071921382 - Train Accuracy: 0.8243303571428572\n",
            "\t\t\tVal Loss: 0.01445979904383421 - Val Accuracy: 0.714\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 810, Loss 0.010981165803968906\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.009316644551498549 - Train Accuracy: 0.8180803571428571\n",
            "\t\t\tVal Loss: 0.01570825546514243 - Val Accuracy: 0.7\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.009197918698191643\n",
            "\t\tTrain step - Step 870, Loss 0.00834500789642334\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.008599672373384238 - Train Accuracy: 0.8354910714285714\n",
            "\t\t\tVal Loss: 0.01546157943084836 - Val Accuracy: 0.71\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.008672494441270828\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.008460696613682168 - Train Accuracy: 0.8428571428571429\n",
            "\t\t\tVal Loss: 0.012424631509929895 - Val Accuracy: 0.756\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 930, Loss 0.009215051308274269\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.008443322591483593 - Train Accuracy: 0.8350446428571429\n",
            "\t\t\tVal Loss: 0.014039793517440557 - Val Accuracy: 0.746\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.0072270785458385944\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.007988056899713618 - Train Accuracy: 0.8504464285714286\n",
            "\t\t\tVal Loss: 0.013520466396585107 - Val Accuracy: 0.76\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.007962347008287907\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.007687495409377984 - Train Accuracy: 0.8508928571428571\n",
            "\t\t\tVal Loss: 0.012511910405009985 - Val Accuracy: 0.766\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.00842488743364811\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.0074770367438239714 - Train Accuracy: 0.8591517857142857\n",
            "\t\t\tVal Loss: 0.01677286601625383 - Val Accuracy: 0.72\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1050, Loss 0.007368987426161766\n",
            "\t\tTrain step - Step 1080, Loss 0.008390464819967747\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.007690278799938304 - Train Accuracy: 0.85625\n",
            "\t\t\tVal Loss: 0.01326518936548382 - Val Accuracy: 0.76\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.010543789714574814\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.007231019370790038 - Train Accuracy: 0.8678571428571429\n",
            "\t\t\tVal Loss: 0.01266825245693326 - Val Accuracy: 0.756\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.007239113096147776\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.006848301525626863 - Train Accuracy: 0.8727678571428571\n",
            "\t\t\tVal Loss: 0.011955965892411768 - Val Accuracy: 0.78\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.008582047186791897\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.006920153315046004 - Train Accuracy: 0.8691964285714285\n",
            "\t\t\tVal Loss: 0.011332229827530682 - Val Accuracy: 0.79\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1200, Loss 0.00601597037166357\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.0069735272920557435 - Train Accuracy: 0.8649553571428571\n",
            "\t\t\tVal Loss: 0.013409169390797615 - Val Accuracy: 0.75\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.007529232185333967\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.006775611798678125 - Train Accuracy: 0.8736607142857142\n",
            "\t\t\tVal Loss: 0.014834061963483691 - Val Accuracy: 0.744\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.006523395422846079\n",
            "\t\tTrain step - Step 1290, Loss 0.008175129070878029\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.006651271081396511 - Train Accuracy: 0.8767857142857143\n",
            "\t\t\tVal Loss: 0.01983741344884038 - Val Accuracy: 0.702\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1320, Loss 0.0038349914830178022\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.006529243882479412 - Train Accuracy: 0.8776785714285714\n",
            "\t\t\tVal Loss: 0.01053241896443069 - Val Accuracy: 0.812\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.006062883418053389\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.0058258199266025 - Train Accuracy: 0.8944196428571428\n",
            "\t\t\tVal Loss: 0.01409004197921604 - Val Accuracy: 0.75\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.008439342491328716\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.005769241348441158 - Train Accuracy: 0.8912946428571429\n",
            "\t\t\tVal Loss: 0.012029281235300004 - Val Accuracy: 0.778\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.00439006183296442\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.005680007115006447 - Train Accuracy: 0.8997767857142858\n",
            "\t\t\tVal Loss: 0.011329613160341978 - Val Accuracy: 0.796\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1440, Loss 0.005337804555892944\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.005478820457522358 - Train Accuracy: 0.9006696428571429\n",
            "\t\t\tVal Loss: 0.015148123493418097 - Val Accuracy: 0.748\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.006144457962363958\n",
            "\t\tTrain step - Step 1500, Loss 0.006604271940886974\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.0056592513008841445 - Train Accuracy: 0.8930803571428572\n",
            "\t\t\tVal Loss: 0.010053327539935708 - Val Accuracy: 0.822\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.005780050531029701\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.005156621563115291 - Train Accuracy: 0.9006696428571429\n",
            "\t\t\tVal Loss: 0.020013666013255715 - Val Accuracy: 0.718\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.0048219324089586735\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.005171182858092444 - Train Accuracy: 0.9069196428571429\n",
            "\t\t\tVal Loss: 0.011924159480258822 - Val Accuracy: 0.776\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1590, Loss 0.005991782993078232\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.004896256959597979 - Train Accuracy: 0.9102678571428572\n",
            "\t\t\tVal Loss: 0.013296222081407905 - Val Accuracy: 0.772\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.004734905436635017\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.004974540589111192 - Train Accuracy: 0.9120535714285715\n",
            "\t\t\tVal Loss: 0.013787788804620504 - Val Accuracy: 0.77\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.006506860256195068\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.0046987361873367 - Train Accuracy: 0.9147321428571429\n",
            "\t\t\tVal Loss: 0.011909134569577873 - Val Accuracy: 0.788\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.004408462438732386\n",
            "\t\tTrain step - Step 1710, Loss 0.0065023950301110744\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.005112102128831403 - Train Accuracy: 0.9064732142857143\n",
            "\t\t\tVal Loss: 0.013035531155765057 - Val Accuracy: 0.776\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1740, Loss 0.002738269744440913\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.0034940450585314205 - Train Accuracy: 0.9433035714285715\n",
            "\t\t\tVal Loss: 0.00797955843154341 - Val Accuracy: 0.856\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1770, Loss 0.001849625026807189\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.0026147998736373015 - Train Accuracy: 0.9611607142857143\n",
            "\t\t\tVal Loss: 0.009212857927195728 - Val Accuracy: 0.838\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1800, Loss 0.001512529794126749\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.0023966519394889472 - Train Accuracy: 0.9658482142857143\n",
            "\t\t\tVal Loss: 0.008268524892628193 - Val Accuracy: 0.858\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1830, Loss 0.00170004868414253\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.0020976547484419174 - Train Accuracy: 0.971875\n",
            "\t\t\tVal Loss: 0.008316709194332361 - Val Accuracy: 0.86\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1860, Loss 0.0012885758187621832\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.0020088153325819543 - Train Accuracy: 0.9738839285714286\n",
            "\t\t\tVal Loss: 0.008701098500750959 - Val Accuracy: 0.848\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1890, Loss 0.0012671285076066852\n",
            "\t\tTrain step - Step 1920, Loss 0.0018779189558699727\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.0018727969145402312 - Train Accuracy: 0.9732142857142857\n",
            "\t\t\tVal Loss: 0.00902589235920459 - Val Accuracy: 0.866\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.0014007050776854157\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.0017094798968173563 - Train Accuracy: 0.9772321428571429\n",
            "\t\t\tVal Loss: 0.008266281336545944 - Val Accuracy: 0.86\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1980, Loss 0.0017522946000099182\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.0017811140328246567 - Train Accuracy: 0.9743303571428571\n",
            "\t\t\tVal Loss: 0.007760440348647535 - Val Accuracy: 0.874\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.0022760480642318726\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.001632239604701421 - Train Accuracy: 0.9785714285714285\n",
            "\t\t\tVal Loss: 0.009381652111187577 - Val Accuracy: 0.864\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.0017549680778756738\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.0015606587935638216 - Train Accuracy: 0.9810267857142857\n",
            "\t\t\tVal Loss: 0.009335640235804021 - Val Accuracy: 0.844\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.0013573613250628114\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.0015463046446841742 - Train Accuracy: 0.9794642857142857\n",
            "\t\t\tVal Loss: 0.009853217052295804 - Val Accuracy: 0.848\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2100, Loss 0.001722634071484208\n",
            "\t\tTrain step - Step 2130, Loss 0.0015654884045943618\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.0013980057423136063 - Train Accuracy: 0.9816964285714286\n",
            "\t\t\tVal Loss: 0.00869079411495477 - Val Accuracy: 0.85\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.0020532074850052595\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.0014597437444276043 - Train Accuracy: 0.9808035714285714\n",
            "\t\t\tVal Loss: 0.00956909661181271 - Val Accuracy: 0.848\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.0017436797497794032\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.0014297473560353476 - Train Accuracy: 0.9828125\n",
            "\t\t\tVal Loss: 0.008863399969413877 - Val Accuracy: 0.846\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2220, Loss 0.0013434675056487322\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.001272026833612472 - Train Accuracy: 0.9863839285714285\n",
            "\t\t\tVal Loss: 0.008850139565765858 - Val Accuracy: 0.854\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2250, Loss 0.0010779479052871466\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.001219992309675685 - Train Accuracy: 0.9866071428571429\n",
            "\t\t\tVal Loss: 0.008623299654573202 - Val Accuracy: 0.858\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2280, Loss 0.0011476132785901427\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.0012147626556855227 - Train Accuracy: 0.9868303571428572\n",
            "\t\t\tVal Loss: 0.00928490306250751 - Val Accuracy: 0.842\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2310, Loss 0.0011900418903678656\n",
            "\t\tTrain step - Step 2340, Loss 0.0013988682767376304\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.0011424604104831814 - Train Accuracy: 0.9877232142857143\n",
            "\t\t\tVal Loss: 0.00813861284404993 - Val Accuracy: 0.866\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2370, Loss 0.001447133137844503\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.0012281969023336258 - Train Accuracy: 0.984375\n",
            "\t\t\tVal Loss: 0.008318793028593063 - Val Accuracy: 0.868\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2400, Loss 0.0011615309631451964\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.0010765212737689062 - Train Accuracy: 0.9888392857142857\n",
            "\t\t\tVal Loss: 0.008742136182263494 - Val Accuracy: 0.864\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2430, Loss 0.002008588518947363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.0011598161504870015 - Train Accuracy: 0.9872767857142857\n",
            "\t\t\tVal Loss: 0.008333964855410159 - Val Accuracy: 0.854\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 19.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 1:\n",
            "\t\tTrain Mean Accuracy: 0.8408801020408164\n",
            "\t\tVal Mean Accuracy: 0.7482571428571427\n",
            "\t\tTest Accuracy: 0.841\n",
            "\n",
            "STARTING JOINT TRAINING STAGE 2...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.026192069053649902\n",
            "\t\tTrain step - Step 60, Loss 0.024832362309098244\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.03081110210290977 - Train Accuracy: 0.47689732142857144\n",
            "\t\t\tVal Loss: 0.025924334302544594 - Val Accuracy: 0.453\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.02039356157183647\n",
            "\t\tTrain step - Step 120, Loss 0.01808496005833149\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.020181332688246456 - Train Accuracy: 0.5751116071428571\n",
            "\t\t\tVal Loss: 0.021951856673695147 - Val Accuracy: 0.551\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 150, Loss 0.017021963372826576\n",
            "\t\tTrain step - Step 180, Loss 0.018921829760074615\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.01831534652571593 - Train Accuracy: 0.6232142857142857\n",
            "\t\t\tVal Loss: 0.023241121787577868 - Val Accuracy: 0.553\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.017768843099474907\n",
            "\t\tTrain step - Step 240, Loss 0.018298493698239326\n",
            "\t\tTrain step - Step 270, Loss 0.015936443582177162\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.017050409024315222 - Train Accuracy: 0.6520089285714286\n",
            "\t\t\tVal Loss: 0.019987864885479212 - Val Accuracy: 0.593\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.015382553450763226\n",
            "\t\tTrain step - Step 330, Loss 0.016264533624053\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.016303325750465905 - Train Accuracy: 0.6719866071428572\n",
            "\t\t\tVal Loss: 0.01891613588668406 - Val Accuracy: 0.635\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.017797019332647324\n",
            "\t\tTrain step - Step 390, Loss 0.017699269577860832\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.015658911557069846 - Train Accuracy: 0.6858258928571429\n",
            "\t\t\tVal Loss: 0.019523546914570034 - Val Accuracy: 0.609\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 420, Loss 0.013636414892971516\n",
            "\t\tTrain step - Step 450, Loss 0.01434028334915638\n",
            "\t\tTrain step - Step 480, Loss 0.012883184477686882\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.014545349630394153 - Train Accuracy: 0.71328125\n",
            "\t\t\tVal Loss: 0.01860109146218747 - Val Accuracy: 0.658\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.012386192567646503\n",
            "\t\tTrain step - Step 540, Loss 0.013904542662203312\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.014170975650527648 - Train Accuracy: 0.7215401785714286\n",
            "\t\t\tVal Loss: 0.020169052062556148 - Val Accuracy: 0.598\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.012637709267437458\n",
            "\t\tTrain step - Step 600, Loss 0.017114195972681046\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.01359891996585897 - Train Accuracy: 0.7383928571428572\n",
            "\t\t\tVal Loss: 0.017983951256610453 - Val Accuracy: 0.644\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.010677105747163296\n",
            "\t\tTrain step - Step 660, Loss 0.01240294799208641\n",
            "\t\tTrain step - Step 690, Loss 0.014326109550893307\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.012878641845392329 - Train Accuracy: 0.7482142857142857\n",
            "\t\t\tVal Loss: 0.018475466640666127 - Val Accuracy: 0.628\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.014469325542449951\n",
            "\t\tTrain step - Step 750, Loss 0.012060018256306648\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.012776930470551763 - Train Accuracy: 0.7555803571428571\n",
            "\t\t\tVal Loss: 0.01670054765418172 - Val Accuracy: 0.679\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.012928223237395287\n",
            "\t\tTrain step - Step 810, Loss 0.013649705797433853\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.012389903688537223 - Train Accuracy: 0.7595982142857143\n",
            "\t\t\tVal Loss: 0.01886366563849151 - Val Accuracy: 0.63\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.01212702039629221\n",
            "\t\tTrain step - Step 870, Loss 0.01137536857277155\n",
            "\t\tTrain step - Step 900, Loss 0.013480224646627903\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.011998408074889864 - Train Accuracy: 0.7643973214285714\n",
            "\t\t\tVal Loss: 0.017218458699062467 - Val Accuracy: 0.664\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 930, Loss 0.013574602082371712\n",
            "\t\tTrain step - Step 960, Loss 0.010237503796815872\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.011454306157039745 - Train Accuracy: 0.78203125\n",
            "\t\t\tVal Loss: 0.017983565339818597 - Val Accuracy: 0.666\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.01191444881260395\n",
            "\t\tTrain step - Step 1020, Loss 0.011850008741021156\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.011222092009016445 - Train Accuracy: 0.7818080357142857\n",
            "\t\t\tVal Loss: 0.01903171418234706 - Val Accuracy: 0.657\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 1050, Loss 0.012729045934975147\n",
            "\t\tTrain step - Step 1080, Loss 0.01093585230410099\n",
            "\t\tTrain step - Step 1110, Loss 0.011560327373445034\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.01100180774394955 - Train Accuracy: 0.7872767857142857\n",
            "\t\t\tVal Loss: 0.02020162926055491 - Val Accuracy: 0.624\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.00901817437261343\n",
            "\t\tTrain step - Step 1170, Loss 0.010973001830279827\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.010725872218608856 - Train Accuracy: 0.7943080357142858\n",
            "\t\t\tVal Loss: 0.017013655975461006 - Val Accuracy: 0.679\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 1200, Loss 0.009104167111217976\n",
            "\t\tTrain step - Step 1230, Loss 0.010484782978892326\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.010401185947869505 - Train Accuracy: 0.8018973214285714\n",
            "\t\t\tVal Loss: 0.016655768267810345 - Val Accuracy: 0.667\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.010547897778451443\n",
            "\t\tTrain step - Step 1290, Loss 0.011679076589643955\n",
            "\t\tTrain step - Step 1320, Loss 0.013778082095086575\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.010195313593638795 - Train Accuracy: 0.8030133928571429\n",
            "\t\t\tVal Loss: 0.01687687251251191 - Val Accuracy: 0.666\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.008912343531847\n",
            "\t\tTrain step - Step 1380, Loss 0.00983052235096693\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.01006390037946403 - Train Accuracy: 0.8082589285714286\n",
            "\t\t\tVal Loss: 0.017982460441999137 - Val Accuracy: 0.675\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.010544492863118649\n",
            "\t\tTrain step - Step 1440, Loss 0.009962976910173893\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.009576703667906777 - Train Accuracy: 0.8121651785714286\n",
            "\t\t\tVal Loss: 0.016675262013450265 - Val Accuracy: 0.675\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.00903350580483675\n",
            "\t\tTrain step - Step 1500, Loss 0.012491507455706596\n",
            "\t\tTrain step - Step 1530, Loss 0.012308950535953045\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.009569816564076713 - Train Accuracy: 0.8159598214285714\n",
            "\t\t\tVal Loss: 0.015393642242997885 - Val Accuracy: 0.706\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.008408940397202969\n",
            "\t\tTrain step - Step 1590, Loss 0.008878931403160095\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.009326666640117765 - Train Accuracy: 0.8261160714285715\n",
            "\t\t\tVal Loss: 0.01716262981062755 - Val Accuracy: 0.673\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.00851704366505146\n",
            "\t\tTrain step - Step 1650, Loss 0.008756387047469616\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.00911008073017001 - Train Accuracy: 0.8303571428571429\n",
            "\t\t\tVal Loss: 0.018633038853295147 - Val Accuracy: 0.667\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.007184030953794718\n",
            "\t\tTrain step - Step 1710, Loss 0.007861386984586716\n",
            "\t\tTrain step - Step 1740, Loss 0.008371356874704361\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.008613912248983979 - Train Accuracy: 0.8389508928571429\n",
            "\t\t\tVal Loss: 0.018221779726445675 - Val Accuracy: 0.657\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 1770, Loss 0.007488918025046587\n",
            "\t\tTrain step - Step 1800, Loss 0.009021095000207424\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.008824721344613604 - Train Accuracy: 0.8360491071428572\n",
            "\t\t\tVal Loss: 0.018270315369591117 - Val Accuracy: 0.676\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 1830, Loss 0.0072363149374723434\n",
            "\t\tTrain step - Step 1860, Loss 0.009154519997537136\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.008737227200929608 - Train Accuracy: 0.8349330357142857\n",
            "\t\t\tVal Loss: 0.016506039537489414 - Val Accuracy: 0.681\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 1890, Loss 0.006814960855990648\n",
            "\t\tTrain step - Step 1920, Loss 0.009370553307235241\n",
            "\t\tTrain step - Step 1950, Loss 0.007802912499755621\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.008310537998165403 - Train Accuracy: 0.8449776785714286\n",
            "\t\t\tVal Loss: 0.018094793776981533 - Val Accuracy: 0.686\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 1980, Loss 0.0053472500294446945\n",
            "\t\tTrain step - Step 2010, Loss 0.007892405614256859\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.008100009563245943 - Train Accuracy: 0.8477678571428572\n",
            "\t\t\tVal Loss: 0.01832701440434903 - Val Accuracy: 0.665\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 2040, Loss 0.006450836546719074\n",
            "\t\tTrain step - Step 2070, Loss 0.008987275883555412\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.008590279599385603 - Train Accuracy: 0.8389508928571429\n",
            "\t\t\tVal Loss: 0.016424626810476184 - Val Accuracy: 0.721\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 2100, Loss 0.007713558617979288\n",
            "\t\tTrain step - Step 2130, Loss 0.008374049328267574\n",
            "\t\tTrain step - Step 2160, Loss 0.009490913711488247\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.007924153875293476 - Train Accuracy: 0.8544642857142857\n",
            "\t\t\tVal Loss: 0.0158162898151204 - Val Accuracy: 0.715\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 2190, Loss 0.006606270093470812\n",
            "\t\tTrain step - Step 2220, Loss 0.007499693427234888\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.007977056044286916 - Train Accuracy: 0.8478794642857143\n",
            "\t\t\tVal Loss: 0.016075009829364717 - Val Accuracy: 0.699\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 2250, Loss 0.006678995210677385\n",
            "\t\tTrain step - Step 2280, Loss 0.007674709428101778\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.007697869424841234 - Train Accuracy: 0.8616071428571429\n",
            "\t\t\tVal Loss: 0.0169030602555722 - Val Accuracy: 0.693\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 2310, Loss 0.006167395040392876\n",
            "\t\tTrain step - Step 2340, Loss 0.007636067923158407\n",
            "\t\tTrain step - Step 2370, Loss 0.00871426984667778\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.007295730410675917 - Train Accuracy: 0.8655133928571429\n",
            "\t\t\tVal Loss: 0.019836099934764206 - Val Accuracy: 0.659\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 2400, Loss 0.006790407933294773\n",
            "\t\tTrain step - Step 2430, Loss 0.007559666410088539\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.007826276043696062 - Train Accuracy: 0.8514508928571428\n",
            "\t\t\tVal Loss: 0.016507893276866525 - Val Accuracy: 0.696\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 2460, Loss 0.0059639704413712025\n",
            "\t\tTrain step - Step 2490, Loss 0.008300556801259518\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.007081664939011846 - Train Accuracy: 0.8670758928571428\n",
            "\t\t\tVal Loss: 0.01623068784829229 - Val Accuracy: 0.716\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 2520, Loss 0.0070150732062757015\n",
            "\t\tTrain step - Step 2550, Loss 0.0056667146272957325\n",
            "\t\tTrain step - Step 2580, Loss 0.007607671432197094\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.007202909268172724 - Train Accuracy: 0.8646205357142858\n",
            "\t\t\tVal Loss: 0.019497979315929115 - Val Accuracy: 0.689\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 2610, Loss 0.007600673474371433\n",
            "\t\tTrain step - Step 2640, Loss 0.00782690942287445\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.007469008982713733 - Train Accuracy: 0.8641741071428571\n",
            "\t\t\tVal Loss: 0.016727823996916413 - Val Accuracy: 0.704\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 2670, Loss 0.006951858755201101\n",
            "\t\tTrain step - Step 2700, Loss 0.0077682738192379475\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.007374119226421629 - Train Accuracy: 0.8631696428571428\n",
            "\t\t\tVal Loss: 0.017302919761277735 - Val Accuracy: 0.684\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 2730, Loss 0.0059248171746730804\n",
            "\t\tTrain step - Step 2760, Loss 0.006501504220068455\n",
            "\t\tTrain step - Step 2790, Loss 0.005905375350266695\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.007145692980183023 - Train Accuracy: 0.8686383928571428\n",
            "\t\t\tVal Loss: 0.016755254240706563 - Val Accuracy: 0.7\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 2820, Loss 0.00605536624789238\n",
            "\t\tTrain step - Step 2850, Loss 0.007164544425904751\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.006809188265885626 - Train Accuracy: 0.8743303571428571\n",
            "\t\t\tVal Loss: 0.017016703845001757 - Val Accuracy: 0.703\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 2880, Loss 0.007235788740217686\n",
            "\t\tTrain step - Step 2910, Loss 0.006673567928373814\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.006623536182035293 - Train Accuracy: 0.878125\n",
            "\t\t\tVal Loss: 0.015258202678523958 - Val Accuracy: 0.739\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 2940, Loss 0.00482154218479991\n",
            "\t\tTrain step - Step 2970, Loss 0.008922483772039413\n",
            "\t\tTrain step - Step 3000, Loss 0.0067968652583658695\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.006451819883659482 - Train Accuracy: 0.8818080357142857\n",
            "\t\t\tVal Loss: 0.017262153094634414 - Val Accuracy: 0.704\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 3030, Loss 0.006769502069801092\n",
            "\t\tTrain step - Step 3060, Loss 0.005430195014923811\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.00622491161338985 - Train Accuracy: 0.88671875\n",
            "\t\t\tVal Loss: 0.015850785945076495 - Val Accuracy: 0.735\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 3090, Loss 0.0041639055125415325\n",
            "\t\tTrain step - Step 3120, Loss 0.007871723733842373\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.006634939402075751 - Train Accuracy: 0.8755580357142857\n",
            "\t\t\tVal Loss: 0.016729803988710046 - Val Accuracy: 0.698\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 3150, Loss 0.007189295254647732\n",
            "\t\tTrain step - Step 3180, Loss 0.006186225451529026\n",
            "\t\tTrain step - Step 3210, Loss 0.008267712779343128\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.006478448864072561 - Train Accuracy: 0.8810267857142857\n",
            "\t\t\tVal Loss: 0.01717586605809629 - Val Accuracy: 0.699\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 3240, Loss 0.0054317014291882515\n",
            "\t\tTrain step - Step 3270, Loss 0.0065314327366650105\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.006283206133438008 - Train Accuracy: 0.8837053571428571\n",
            "\t\t\tVal Loss: 0.018661978014279157 - Val Accuracy: 0.679\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 3300, Loss 0.006460437551140785\n",
            "\t\tTrain step - Step 3330, Loss 0.005376117303967476\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.006666024069168738 - Train Accuracy: 0.8748883928571428\n",
            "\t\t\tVal Loss: 0.016689275624230504 - Val Accuracy: 0.713\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 3360, Loss 0.007842655293643475\n",
            "\t\tTrain step - Step 3390, Loss 0.007799116428941488\n",
            "\t\tTrain step - Step 3420, Loss 0.00669082859531045\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.006215156262208308 - Train Accuracy: 0.8872767857142857\n",
            "\t\t\tVal Loss: 0.016711436212062836 - Val Accuracy: 0.72\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 3450, Loss 0.00513825099915266\n",
            "\t\tTrain step - Step 3480, Loss 0.003484269604086876\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.004132917855999299 - Train Accuracy: 0.9314732142857143\n",
            "\t\t\tVal Loss: 0.012029238685499877 - Val Accuracy: 0.793\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 3510, Loss 0.003020641626790166\n",
            "\t\tTrain step - Step 3540, Loss 0.0029391413554549217\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.003045029499168907 - Train Accuracy: 0.9529017857142857\n",
            "\t\t\tVal Loss: 0.011562220053747296 - Val Accuracy: 0.784\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 3570, Loss 0.0020897090435028076\n",
            "\t\tTrain step - Step 3600, Loss 0.0029768587555736303\n",
            "\t\tTrain step - Step 3630, Loss 0.002157674403861165\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.002720854020610984 - Train Accuracy: 0.9594866071428572\n",
            "\t\t\tVal Loss: 0.012319752655457705 - Val Accuracy: 0.799\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 3660, Loss 0.0028076099697500467\n",
            "\t\tTrain step - Step 3690, Loss 0.001830410910770297\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.0025154912012762256 - Train Accuracy: 0.9650669642857143\n",
            "\t\t\tVal Loss: 0.012026178475935012 - Val Accuracy: 0.786\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 3720, Loss 0.0026332566048949957\n",
            "\t\tTrain step - Step 3750, Loss 0.0024432141799479723\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.002270701599107789 - Train Accuracy: 0.9697544642857143\n",
            "\t\t\tVal Loss: 0.011697512294631451 - Val Accuracy: 0.8\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 3780, Loss 0.002257648855447769\n",
            "\t\tTrain step - Step 3810, Loss 0.0013971527805551887\n",
            "\t\tTrain step - Step 3840, Loss 0.0027999691665172577\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.002092762106829988 - Train Accuracy: 0.9728794642857143\n",
            "\t\t\tVal Loss: 0.011714852706063539 - Val Accuracy: 0.795\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 3870, Loss 0.001745310379192233\n",
            "\t\tTrain step - Step 3900, Loss 0.001903374446555972\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.0020225973284271146 - Train Accuracy: 0.9734375\n",
            "\t\t\tVal Loss: 0.01159130601445213 - Val Accuracy: 0.808\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 3930, Loss 0.0023833459708839655\n",
            "\t\tTrain step - Step 3960, Loss 0.002280443673953414\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.0019050276089858796 - Train Accuracy: 0.9758928571428571\n",
            "\t\t\tVal Loss: 0.012856948771513999 - Val Accuracy: 0.79\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 3990, Loss 0.0015439031412824988\n",
            "\t\tTrain step - Step 4020, Loss 0.0016110300784930587\n",
            "\t\tTrain step - Step 4050, Loss 0.002034860895946622\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.0018842328065407595 - Train Accuracy: 0.9761160714285714\n",
            "\t\t\tVal Loss: 0.011765963397920132 - Val Accuracy: 0.801\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 4080, Loss 0.002348966896533966\n",
            "\t\tTrain step - Step 4110, Loss 0.0018940245499834418\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.0018158949712025268 - Train Accuracy: 0.9746651785714285\n",
            "\t\t\tVal Loss: 0.011781892855651677 - Val Accuracy: 0.8\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 4140, Loss 0.001297969021834433\n",
            "\t\tTrain step - Step 4170, Loss 0.0031070904806256294\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.0016330711859544472 - Train Accuracy: 0.9792410714285714\n",
            "\t\t\tVal Loss: 0.012292192433960736 - Val Accuracy: 0.803\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 4200, Loss 0.0016152196330949664\n",
            "\t\tTrain step - Step 4230, Loss 0.0040049683302640915\n",
            "\t\tTrain step - Step 4260, Loss 0.001641201670281589\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.0017280738310156657 - Train Accuracy: 0.9782366071428571\n",
            "\t\t\tVal Loss: 0.012500807759352028 - Val Accuracy: 0.797\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 4290, Loss 0.0010772792156785727\n",
            "\t\tTrain step - Step 4320, Loss 0.0017842764500528574\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.0016154804774227418 - Train Accuracy: 0.9785714285714285\n",
            "\t\t\tVal Loss: 0.01212287088856101 - Val Accuracy: 0.805\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 4350, Loss 0.0015214760787785053\n",
            "\t\tTrain step - Step 4380, Loss 0.0017617144621908665\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.0014948952901509723 - Train Accuracy: 0.9809151785714286\n",
            "\t\t\tVal Loss: 0.01275730796623975 - Val Accuracy: 0.799\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 4410, Loss 0.001351511338725686\n",
            "\t\tTrain step - Step 4440, Loss 0.0013948564883321524\n",
            "\t\tTrain step - Step 4470, Loss 0.0015710721490904689\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.0012830653893096107 - Train Accuracy: 0.98671875\n",
            "\t\t\tVal Loss: 0.012307994242291898 - Val Accuracy: 0.787\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 4500, Loss 0.0013912570429965854\n",
            "\t\tTrain step - Step 4530, Loss 0.0018216475145891309\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.001269713553899367 - Train Accuracy: 0.9878348214285714\n",
            "\t\t\tVal Loss: 0.012600658985320479 - Val Accuracy: 0.8\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 4560, Loss 0.0015214585000649095\n",
            "\t\tTrain step - Step 4590, Loss 0.001174852717667818\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.0012434101239445485 - Train Accuracy: 0.9879464285714286\n",
            "\t\t\tVal Loss: 0.012495196890085936 - Val Accuracy: 0.804\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 4620, Loss 0.0011523693101480603\n",
            "\t\tTrain step - Step 4650, Loss 0.0008348026894964278\n",
            "\t\tTrain step - Step 4680, Loss 0.0008668813388794661\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.001146331793695156 - Train Accuracy: 0.9887276785714286\n",
            "\t\t\tVal Loss: 0.011661779833957553 - Val Accuracy: 0.811\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 4710, Loss 0.0011631881352514029\n",
            "\t\tTrain step - Step 4740, Loss 0.001542388810776174\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.0012641942128539085 - Train Accuracy: 0.9869419642857142\n",
            "\t\t\tVal Loss: 0.01286860735854134 - Val Accuracy: 0.793\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 4770, Loss 0.0011391168227419257\n",
            "\t\tTrain step - Step 4800, Loss 0.0005233985721133649\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.0011496461936206157 - Train Accuracy: 0.9873883928571429\n",
            "\t\t\tVal Loss: 0.01224318437743932 - Val Accuracy: 0.804\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 4830, Loss 0.000929923786316067\n",
            "\t\tTrain step - Step 4860, Loss 0.0011739758774638176\n",
            "\t\tTrain step - Step 4890, Loss 0.0013787997886538506\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/16 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.0011428199217854334 - Train Accuracy: 0.98828125\n",
            "\t\t\tVal Loss: 0.01212414843030274 - Val Accuracy: 0.8\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:00<00:00, 22.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 2:\n",
            "\t\tTrain Mean Accuracy: 0.8540768494897959\n",
            "\t\tVal Mean Accuracy: 0.7062857142857143\n",
            "\t\tTest Accuracy: 0.802\n",
            "\n",
            "STARTING JOINT TRAINING STAGE 3...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.02023758925497532\n",
            "\t\tTrain step - Step 60, Loss 0.015200590714812279\n",
            "\t\tTrain step - Step 90, Loss 0.016374394297599792\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.020470966975248996 - Train Accuracy: 0.6316964285714286\n",
            "\t\t\tVal Loss: 0.021952816595633824 - Val Accuracy: 0.5613333333333334\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.014488770626485348\n",
            "\t\tTrain step - Step 150, Loss 0.013784665614366531\n",
            "\t\tTrain step - Step 180, Loss 0.015933504328131676\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.015673858769947573 - Train Accuracy: 0.6906994047619047\n",
            "\t\t\tVal Loss: 0.020755771547555923 - Val Accuracy: 0.5993333333333334\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.015084716491401196\n",
            "\t\tTrain step - Step 240, Loss 0.01203987654298544\n",
            "\t\tTrain step - Step 270, Loss 0.01477949321269989\n",
            "\t\tTrain step - Step 300, Loss 0.013509031385183334\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.014633728945184322 - Train Accuracy: 0.7079613095238095\n",
            "\t\t\tVal Loss: 0.019633154928063352 - Val Accuracy: 0.6153333333333333\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.012804205529391766\n",
            "\t\tTrain step - Step 360, Loss 0.012138325721025467\n",
            "\t\tTrain step - Step 390, Loss 0.013845834881067276\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.013800348847040109 - Train Accuracy: 0.7286458333333333\n",
            "\t\t\tVal Loss: 0.019547439413145185 - Val Accuracy: 0.632\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 420, Loss 0.013670799322426319\n",
            "\t\tTrain step - Step 450, Loss 0.011941501870751381\n",
            "\t\tTrain step - Step 480, Loss 0.014062704518437386\n",
            "\t\tTrain step - Step 510, Loss 0.014983641915023327\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.013313895419594787 - Train Accuracy: 0.7392113095238095\n",
            "\t\t\tVal Loss: 0.022249922233944137 - Val Accuracy: 0.5873333333333334\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 540, Loss 0.010941263288259506\n",
            "\t\tTrain step - Step 570, Loss 0.017087608575820923\n",
            "\t\tTrain step - Step 600, Loss 0.01575809344649315\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.012994674788344474 - Train Accuracy: 0.7441220238095239\n",
            "\t\t\tVal Loss: 0.02038856114571293 - Val Accuracy: 0.6106666666666667\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.011902925558388233\n",
            "\t\tTrain step - Step 660, Loss 0.013431785628199577\n",
            "\t\tTrain step - Step 690, Loss 0.013013629242777824\n",
            "\t\tTrain step - Step 720, Loss 0.011871320195496082\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.012509833187574431 - Train Accuracy: 0.758110119047619\n",
            "\t\t\tVal Loss: 0.018738432011256616 - Val Accuracy: 0.6406666666666667\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.013845411129295826\n",
            "\t\tTrain step - Step 780, Loss 0.010793672874569893\n",
            "\t\tTrain step - Step 810, Loss 0.015170427039265633\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.012370681017637252 - Train Accuracy: 0.758110119047619\n",
            "\t\t\tVal Loss: 0.020461564883589745 - Val Accuracy: 0.6286666666666667\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.011934251524508\n",
            "\t\tTrain step - Step 870, Loss 0.01183974277228117\n",
            "\t\tTrain step - Step 900, Loss 0.010878789238631725\n",
            "\t\tTrain step - Step 930, Loss 0.014061461202800274\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.012060882621223018 - Train Accuracy: 0.7659970238095238\n",
            "\t\t\tVal Loss: 0.019330359374483425 - Val Accuracy: 0.6233333333333333\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.011763770133256912\n",
            "\t\tTrain step - Step 990, Loss 0.011580603197216988\n",
            "\t\tTrain step - Step 1020, Loss 0.010362827219069004\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.011950427896919705 - Train Accuracy: 0.7662946428571429\n",
            "\t\t\tVal Loss: 0.01821220697214206 - Val Accuracy: 0.6566666666666666\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 1050, Loss 0.010806477628648281\n",
            "\t\tTrain step - Step 1080, Loss 0.011333108879625797\n",
            "\t\tTrain step - Step 1110, Loss 0.013511366210877895\n",
            "\t\tTrain step - Step 1140, Loss 0.011111749336123466\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.01184550750823248 - Train Accuracy: 0.7707589285714286\n",
            "\t\t\tVal Loss: 0.019024512769343953 - Val Accuracy: 0.6413333333333333\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.011195787228643894\n",
            "\t\tTrain step - Step 1200, Loss 0.010973681695759296\n",
            "\t\tTrain step - Step 1230, Loss 0.012505453079938889\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.011534117330752668 - Train Accuracy: 0.7790178571428571\n",
            "\t\t\tVal Loss: 0.019686288200318813 - Val Accuracy: 0.6326666666666667\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.012073230929672718\n",
            "\t\tTrain step - Step 1290, Loss 0.009938014671206474\n",
            "\t\tTrain step - Step 1320, Loss 0.010758724063634872\n",
            "\t\tTrain step - Step 1350, Loss 0.008655104786157608\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.011267355603298971 - Train Accuracy: 0.7854166666666667\n",
            "\t\t\tVal Loss: 0.021734942294036348 - Val Accuracy: 0.5933333333333334\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.006765084341168404\n",
            "\t\tTrain step - Step 1410, Loss 0.01053108461201191\n",
            "\t\tTrain step - Step 1440, Loss 0.01208545733243227\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.011089795850039948 - Train Accuracy: 0.7877232142857142\n",
            "\t\t\tVal Loss: 0.01801019402531286 - Val Accuracy: 0.6613333333333333\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.009923269972205162\n",
            "\t\tTrain step - Step 1500, Loss 0.011901860125362873\n",
            "\t\tTrain step - Step 1530, Loss 0.0111180879175663\n",
            "\t\tTrain step - Step 1560, Loss 0.011072130873799324\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.010904778646571295 - Train Accuracy: 0.7909970238095239\n",
            "\t\t\tVal Loss: 0.021510928714027006 - Val Accuracy: 0.612\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 1590, Loss 0.009474516846239567\n",
            "\t\tTrain step - Step 1620, Loss 0.009980976581573486\n",
            "\t\tTrain step - Step 1650, Loss 0.012927822768688202\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.010646937898404542 - Train Accuracy: 0.8001488095238095\n",
            "\t\t\tVal Loss: 0.02001473625811438 - Val Accuracy: 0.6393333333333333\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.008840218186378479\n",
            "\t\tTrain step - Step 1710, Loss 0.012058541178703308\n",
            "\t\tTrain step - Step 1740, Loss 0.009781851433217525\n",
            "\t\tTrain step - Step 1770, Loss 0.013691997155547142\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.010709948332182 - Train Accuracy: 0.7938988095238095\n",
            "\t\t\tVal Loss: 0.02074086289697637 - Val Accuracy: 0.6286666666666667\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 1800, Loss 0.009998379275202751\n",
            "\t\tTrain step - Step 1830, Loss 0.008206309750676155\n",
            "\t\tTrain step - Step 1860, Loss 0.011541671119630337\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.010605358971016748 - Train Accuracy: 0.7999255952380953\n",
            "\t\t\tVal Loss: 0.020494246816573043 - Val Accuracy: 0.626\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 1890, Loss 0.011045554652810097\n",
            "\t\tTrain step - Step 1920, Loss 0.01038732286542654\n",
            "\t\tTrain step - Step 1950, Loss 0.012415251694619656\n",
            "\t\tTrain step - Step 1980, Loss 0.00870460830628872\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.010250718470308043 - Train Accuracy: 0.8070684523809524\n",
            "\t\t\tVal Loss: 0.02036721957847476 - Val Accuracy: 0.622\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 2010, Loss 0.010855100117623806\n",
            "\t\tTrain step - Step 2040, Loss 0.008101152256131172\n",
            "\t\tTrain step - Step 2070, Loss 0.01330103725194931\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.01050213629912053 - Train Accuracy: 0.8040178571428571\n",
            "\t\t\tVal Loss: 0.02051646790156762 - Val Accuracy: 0.6306666666666667\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 2100, Loss 0.009444470517337322\n",
            "\t\tTrain step - Step 2130, Loss 0.011620976962149143\n",
            "\t\tTrain step - Step 2160, Loss 0.010576531291007996\n",
            "\t\tTrain step - Step 2190, Loss 0.01168314553797245\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.010234929616784766 - Train Accuracy: 0.807217261904762\n",
            "\t\t\tVal Loss: 0.02115092403255403 - Val Accuracy: 0.626\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 2220, Loss 0.01035244669765234\n",
            "\t\tTrain step - Step 2250, Loss 0.013042864389717579\n",
            "\t\tTrain step - Step 2280, Loss 0.01099351979792118\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.009751682662005936 - Train Accuracy: 0.8180803571428571\n",
            "\t\t\tVal Loss: 0.020643665688112378 - Val Accuracy: 0.626\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 2310, Loss 0.008711873553693295\n",
            "\t\tTrain step - Step 2340, Loss 0.008099406026303768\n",
            "\t\tTrain step - Step 2370, Loss 0.011418023146688938\n",
            "\t\tTrain step - Step 2400, Loss 0.0076646143570542336\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.009996648868989377 - Train Accuracy: 0.8066220238095239\n",
            "\t\t\tVal Loss: 0.02059861117353042 - Val Accuracy: 0.6126666666666667\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 2430, Loss 0.007659423630684614\n",
            "\t\tTrain step - Step 2460, Loss 0.009793932549655437\n",
            "\t\tTrain step - Step 2490, Loss 0.009191228076815605\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.00956421759689138 - Train Accuracy: 0.8191964285714286\n",
            "\t\t\tVal Loss: 0.0215510461324205 - Val Accuracy: 0.6013333333333334\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 2520, Loss 0.008691459894180298\n",
            "\t\tTrain step - Step 2550, Loss 0.008122998289763927\n",
            "\t\tTrain step - Step 2580, Loss 0.013320944271981716\n",
            "\t\tTrain step - Step 2610, Loss 0.011427745223045349\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.009701203785481907 - Train Accuracy: 0.8147321428571429\n",
            "\t\t\tVal Loss: 0.0184933942121764 - Val Accuracy: 0.6713333333333333\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 2640, Loss 0.007061890326440334\n",
            "\t\tTrain step - Step 2670, Loss 0.00976953562349081\n",
            "\t\tTrain step - Step 2700, Loss 0.008230661042034626\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.009601838669429224 - Train Accuracy: 0.8223214285714285\n",
            "\t\t\tVal Loss: 0.018397317578395207 - Val Accuracy: 0.6533333333333333\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 2730, Loss 0.00779841048642993\n",
            "\t\tTrain step - Step 2760, Loss 0.011028866283595562\n",
            "\t\tTrain step - Step 2790, Loss 0.008843572810292244\n",
            "\t\tTrain step - Step 2820, Loss 0.01115416269749403\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.009524426121442092 - Train Accuracy: 0.8210565476190477\n",
            "\t\t\tVal Loss: 0.018274502828717232 - Val Accuracy: 0.6686666666666666\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 2850, Loss 0.00984981469810009\n",
            "\t\tTrain step - Step 2880, Loss 0.008420850150287151\n",
            "\t\tTrain step - Step 2910, Loss 0.011797334998846054\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.009347127976694278 - Train Accuracy: 0.8250744047619047\n",
            "\t\t\tVal Loss: 0.019538613424325984 - Val Accuracy: 0.6453333333333333\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 2940, Loss 0.007867480628192425\n",
            "\t\tTrain step - Step 2970, Loss 0.011070185340940952\n",
            "\t\tTrain step - Step 3000, Loss 0.009457912296056747\n",
            "\t\tTrain step - Step 3030, Loss 0.009112232364714146\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.009247715083793516 - Train Accuracy: 0.8274553571428571\n",
            "\t\t\tVal Loss: 0.02444929792545736 - Val Accuracy: 0.5986666666666667\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 3060, Loss 0.010372352786362171\n",
            "\t\tTrain step - Step 3090, Loss 0.008492935448884964\n",
            "\t\tTrain step - Step 3120, Loss 0.006140934303402901\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.00890498955157541 - Train Accuracy: 0.8321428571428572\n",
            "\t\t\tVal Loss: 0.020460316445678473 - Val Accuracy: 0.626\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 3150, Loss 0.007753638084977865\n",
            "\t\tTrain step - Step 3180, Loss 0.005614148918539286\n",
            "\t\tTrain step - Step 3210, Loss 0.010255055502057076\n",
            "\t\tTrain step - Step 3240, Loss 0.011469251476228237\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.009263309357421739 - Train Accuracy: 0.8258928571428571\n",
            "\t\t\tVal Loss: 0.02497667757173379 - Val Accuracy: 0.5606666666666666\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 3270, Loss 0.007064808625727892\n",
            "\t\tTrain step - Step 3300, Loss 0.009658358059823513\n",
            "\t\tTrain step - Step 3330, Loss 0.008442049846053123\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.009226912960764907 - Train Accuracy: 0.8298363095238095\n",
            "\t\t\tVal Loss: 0.01724518827783565 - Val Accuracy: 0.6926666666666667\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 3360, Loss 0.00829519983381033\n",
            "\t\tTrain step - Step 3390, Loss 0.008301139809191227\n",
            "\t\tTrain step - Step 3420, Loss 0.008395119570195675\n",
            "\t\tTrain step - Step 3450, Loss 0.00945934746414423\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.008586950147790567 - Train Accuracy: 0.842485119047619\n",
            "\t\t\tVal Loss: 0.02003271656576544 - Val Accuracy: 0.65\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 3480, Loss 0.007983519695699215\n",
            "\t\tTrain step - Step 3510, Loss 0.009776903316378593\n",
            "\t\tTrain step - Step 3540, Loss 0.009394620545208454\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.008618816826492548 - Train Accuracy: 0.8388392857142857\n",
            "\t\t\tVal Loss: 0.019657342073818047 - Val Accuracy: 0.6493333333333333\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 3570, Loss 0.00785023346543312\n",
            "\t\tTrain step - Step 3600, Loss 0.008621514774858952\n",
            "\t\tTrain step - Step 3630, Loss 0.006966006476432085\n",
            "\t\tTrain step - Step 3660, Loss 0.01017758809030056\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.00891441349383621 - Train Accuracy: 0.8330357142857143\n",
            "\t\t\tVal Loss: 0.019960300531238317 - Val Accuracy: 0.654\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 3690, Loss 0.006879323627799749\n",
            "\t\tTrain step - Step 3720, Loss 0.008470415137708187\n",
            "\t\tTrain step - Step 3750, Loss 0.007743902038782835\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.00852803440675849 - Train Accuracy: 0.8438988095238096\n",
            "\t\t\tVal Loss: 0.022036949483056862 - Val Accuracy: 0.6193333333333333\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 3780, Loss 0.008138513192534447\n",
            "\t\tTrain step - Step 3810, Loss 0.01041378267109394\n",
            "\t\tTrain step - Step 3840, Loss 0.007437230087816715\n",
            "\t\tTrain step - Step 3870, Loss 0.009187018498778343\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.00860855428590661 - Train Accuracy: 0.8405505952380953\n",
            "\t\t\tVal Loss: 0.019690791610628366 - Val Accuracy: 0.656\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 3900, Loss 0.008285638876259327\n",
            "\t\tTrain step - Step 3930, Loss 0.010076710022985935\n",
            "\t\tTrain step - Step 3960, Loss 0.008431664668023586\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.008480440528087673 - Train Accuracy: 0.8408482142857143\n",
            "\t\t\tVal Loss: 0.01866220178393026 - Val Accuracy: 0.6653333333333333\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 3990, Loss 0.00747681362554431\n",
            "\t\tTrain step - Step 4020, Loss 0.009814674034714699\n",
            "\t\tTrain step - Step 4050, Loss 0.008144195191562176\n",
            "\t\tTrain step - Step 4080, Loss 0.00900510884821415\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.008406092381725709 - Train Accuracy: 0.8457589285714285\n",
            "\t\t\tVal Loss: 0.021003258725007374 - Val Accuracy: 0.6346666666666667\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 4110, Loss 0.010371667332947254\n",
            "\t\tTrain step - Step 4140, Loss 0.009001134894788265\n",
            "\t\tTrain step - Step 4170, Loss 0.008821886964142323\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.008480921170363824 - Train Accuracy: 0.843452380952381\n",
            "\t\t\tVal Loss: 0.018602772615849972 - Val Accuracy: 0.6473333333333333\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 4200, Loss 0.006293189246207476\n",
            "\t\tTrain step - Step 4230, Loss 0.0072792950086295605\n",
            "\t\tTrain step - Step 4260, Loss 0.00844820961356163\n",
            "\t\tTrain step - Step 4290, Loss 0.009637044742703438\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.008089491339134319 - Train Accuracy: 0.8479910714285714\n",
            "\t\t\tVal Loss: 0.020640043541789055 - Val Accuracy: 0.642\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 4320, Loss 0.01037554256618023\n",
            "\t\tTrain step - Step 4350, Loss 0.007363070268183947\n",
            "\t\tTrain step - Step 4380, Loss 0.0067077865824103355\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.008147436123163928 - Train Accuracy: 0.8498511904761905\n",
            "\t\t\tVal Loss: 0.021870270371437073 - Val Accuracy: 0.6273333333333333\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 4410, Loss 0.009628177620470524\n",
            "\t\tTrain step - Step 4440, Loss 0.007464033085852861\n",
            "\t\tTrain step - Step 4470, Loss 0.008326281793415546\n",
            "\t\tTrain step - Step 4500, Loss 0.008458963595330715\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.008074934377024572 - Train Accuracy: 0.8511160714285714\n",
            "\t\t\tVal Loss: 0.02336836272540192 - Val Accuracy: 0.6113333333333333\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 4530, Loss 0.008167383261024952\n",
            "\t\tTrain step - Step 4560, Loss 0.0073911938816308975\n",
            "\t\tTrain step - Step 4590, Loss 0.008063367567956448\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.008088526879215524 - Train Accuracy: 0.8482142857142857\n",
            "\t\t\tVal Loss: 0.01925926236435771 - Val Accuracy: 0.6726666666666666\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 4620, Loss 0.007257347926497459\n",
            "\t\tTrain step - Step 4650, Loss 0.00834711641073227\n",
            "\t\tTrain step - Step 4680, Loss 0.009518212638795376\n",
            "\t\tTrain step - Step 4710, Loss 0.009156102314591408\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.008223675173662957 - Train Accuracy: 0.8459077380952381\n",
            "\t\t\tVal Loss: 0.021496948630859453 - Val Accuracy: 0.6293333333333333\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 4740, Loss 0.0064928727224469185\n",
            "\t\tTrain step - Step 4770, Loss 0.009835469536483288\n",
            "\t\tTrain step - Step 4800, Loss 0.007321739103645086\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.008076506183438357 - Train Accuracy: 0.8500744047619048\n",
            "\t\t\tVal Loss: 0.02214460540562868 - Val Accuracy: 0.626\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 4830, Loss 0.00915960967540741\n",
            "\t\tTrain step - Step 4860, Loss 0.009030943736433983\n",
            "\t\tTrain step - Step 4890, Loss 0.006076738238334656\n",
            "\t\tTrain step - Step 4920, Loss 0.006336858496069908\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.007993909623473882 - Train Accuracy: 0.8519345238095238\n",
            "\t\t\tVal Loss: 0.02030662912875414 - Val Accuracy: 0.65\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 4950, Loss 0.006206097546964884\n",
            "\t\tTrain step - Step 4980, Loss 0.00672442652285099\n",
            "\t\tTrain step - Step 5010, Loss 0.007009518798440695\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.007947550926889693 - Train Accuracy: 0.8543154761904762\n",
            "\t\t\tVal Loss: 0.0197085861582309 - Val Accuracy: 0.6686666666666666\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 5040, Loss 0.0076828207820653915\n",
            "\t\tTrain step - Step 5070, Loss 0.007430691737681627\n",
            "\t\tTrain step - Step 5100, Loss 0.006489450577646494\n",
            "\t\tTrain step - Step 5130, Loss 0.009206762537360191\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.007791361982180249 - Train Accuracy: 0.8559523809523809\n",
            "\t\t\tVal Loss: 0.018289096420630813 - Val Accuracy: 0.6766666666666666\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 5160, Loss 0.005514266435056925\n",
            "\t\tTrain step - Step 5190, Loss 0.004503539297729731\n",
            "\t\tTrain step - Step 5220, Loss 0.0029233854729682207\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.005169488897635823 - Train Accuracy: 0.9122767857142857\n",
            "\t\t\tVal Loss: 0.012993947369977832 - Val Accuracy: 0.75\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 5250, Loss 0.003272696165367961\n",
            "\t\tTrain step - Step 5280, Loss 0.004158610478043556\n",
            "\t\tTrain step - Step 5310, Loss 0.003253899049013853\n",
            "\t\tTrain step - Step 5340, Loss 0.0033111614175140858\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.0038992947410969505 - Train Accuracy: 0.9389880952380952\n",
            "\t\t\tVal Loss: 0.01362641113034139 - Val Accuracy: 0.7513333333333333\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 5370, Loss 0.0037144715897738934\n",
            "\t\tTrain step - Step 5400, Loss 0.005508556962013245\n",
            "\t\tTrain step - Step 5430, Loss 0.00423752935603261\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.003440814261280355 - Train Accuracy: 0.9487351190476191\n",
            "\t\t\tVal Loss: 0.013942028124195835 - Val Accuracy: 0.7526666666666667\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 5460, Loss 0.003081071423366666\n",
            "\t\tTrain step - Step 5490, Loss 0.0034809126518666744\n",
            "\t\tTrain step - Step 5520, Loss 0.00357740162871778\n",
            "\t\tTrain step - Step 5550, Loss 0.003990985453128815\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.0032819400851925216 - Train Accuracy: 0.9520833333333333\n",
            "\t\t\tVal Loss: 0.013665095476123193 - Val Accuracy: 0.7613333333333333\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 5580, Loss 0.003737366758286953\n",
            "\t\tTrain step - Step 5610, Loss 0.0022888057865202427\n",
            "\t\tTrain step - Step 5640, Loss 0.002550057601183653\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.0030548964627087117 - Train Accuracy: 0.9582589285714286\n",
            "\t\t\tVal Loss: 0.013652269029989839 - Val Accuracy: 0.7633333333333333\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 5670, Loss 0.0038072930183261633\n",
            "\t\tTrain step - Step 5700, Loss 0.0019111394649371505\n",
            "\t\tTrain step - Step 5730, Loss 0.0038934366311877966\n",
            "\t\tTrain step - Step 5760, Loss 0.0024261297658085823\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.0028820226711797573 - Train Accuracy: 0.9590029761904761\n",
            "\t\t\tVal Loss: 0.013862598842630783 - Val Accuracy: 0.7533333333333333\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 5790, Loss 0.0024137673899531364\n",
            "\t\tTrain step - Step 5820, Loss 0.0036705257371068\n",
            "\t\tTrain step - Step 5850, Loss 0.0017593845259398222\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.002726740509803806 - Train Accuracy: 0.9614583333333333\n",
            "\t\t\tVal Loss: 0.01385249849408865 - Val Accuracy: 0.7666666666666667\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 5880, Loss 0.0027453883085399866\n",
            "\t\tTrain step - Step 5910, Loss 0.0026597720570862293\n",
            "\t\tTrain step - Step 5940, Loss 0.0027619218453764915\n",
            "\t\tTrain step - Step 5970, Loss 0.0018280628137290478\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.002611764276488906 - Train Accuracy: 0.9651041666666667\n",
            "\t\t\tVal Loss: 0.01332759220773975 - Val Accuracy: 0.7673333333333333\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 6000, Loss 0.0026970189064741135\n",
            "\t\tTrain step - Step 6030, Loss 0.0026116466615349054\n",
            "\t\tTrain step - Step 6060, Loss 0.003034743946045637\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.002467023909446739 - Train Accuracy: 0.9668154761904761\n",
            "\t\t\tVal Loss: 0.014182319437774519 - Val Accuracy: 0.7653333333333333\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 6090, Loss 0.0025924842339009047\n",
            "\t\tTrain step - Step 6120, Loss 0.002228714292868972\n",
            "\t\tTrain step - Step 6150, Loss 0.002614871133118868\n",
            "\t\tTrain step - Step 6180, Loss 0.0033189766108989716\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.002296957270508366 - Train Accuracy: 0.9694940476190477\n",
            "\t\t\tVal Loss: 0.014269448583945632 - Val Accuracy: 0.7613333333333333\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 6210, Loss 0.0020132530480623245\n",
            "\t\tTrain step - Step 6240, Loss 0.002085020998492837\n",
            "\t\tTrain step - Step 6270, Loss 0.0024978541769087315\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.0022542829569872644 - Train Accuracy: 0.971577380952381\n",
            "\t\t\tVal Loss: 0.014623834596325954 - Val Accuracy: 0.7573333333333333\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 6300, Loss 0.00235453387722373\n",
            "\t\tTrain step - Step 6330, Loss 0.0016811846289783716\n",
            "\t\tTrain step - Step 6360, Loss 0.002255433239042759\n",
            "\t\tTrain step - Step 6390, Loss 0.0013089528074488044\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.0021027407187613704 - Train Accuracy: 0.9742559523809524\n",
            "\t\t\tVal Loss: 0.014355546057534715 - Val Accuracy: 0.7653333333333333\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 6420, Loss 0.003051737556234002\n",
            "\t\tTrain step - Step 6450, Loss 0.0017354594310745597\n",
            "\t\tTrain step - Step 6480, Loss 0.0027645134832710028\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.0020262247694301464 - Train Accuracy: 0.9735119047619047\n",
            "\t\t\tVal Loss: 0.014398257519739369 - Val Accuracy: 0.7646666666666667\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 6510, Loss 0.0015780217945575714\n",
            "\t\tTrain step - Step 6540, Loss 0.0018803681014105678\n",
            "\t\tTrain step - Step 6570, Loss 0.0016865520738065243\n",
            "\t\tTrain step - Step 6600, Loss 0.002692208159714937\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.002090701578362357 - Train Accuracy: 0.9721726190476191\n",
            "\t\t\tVal Loss: 0.015629996623223025 - Val Accuracy: 0.7566666666666667\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 6630, Loss 0.0018608003156259656\n",
            "\t\tTrain step - Step 6660, Loss 0.0013479688204824924\n",
            "\t\tTrain step - Step 6690, Loss 0.001029841136187315\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.001752436819619366 - Train Accuracy: 0.9791666666666666\n",
            "\t\t\tVal Loss: 0.01402835784635196 - Val Accuracy: 0.7726666666666666\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 6720, Loss 0.0014574630185961723\n",
            "\t\tTrain step - Step 6750, Loss 0.002194575034081936\n",
            "\t\tTrain step - Step 6780, Loss 0.002467251615598798\n",
            "\t\tTrain step - Step 6810, Loss 0.0011931740446016192\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.0016789249538089193 - Train Accuracy: 0.9806547619047619\n",
            "\t\t\tVal Loss: 0.013447953077654043 - Val Accuracy: 0.7706666666666667\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 6840, Loss 0.0020852810703217983\n",
            "\t\tTrain step - Step 6870, Loss 0.0011731829727068543\n",
            "\t\tTrain step - Step 6900, Loss 0.0010917856125161052\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.0015977652028336057 - Train Accuracy: 0.9824404761904761\n",
            "\t\t\tVal Loss: 0.013763978184821704 - Val Accuracy: 0.7766666666666666\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 6930, Loss 0.001073174411430955\n",
            "\t\tTrain step - Step 6960, Loss 0.0014850827865302563\n",
            "\t\tTrain step - Step 6990, Loss 0.0013243553694337606\n",
            "\t\tTrain step - Step 7020, Loss 0.0008306211093440652\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.0015421117788978985 - Train Accuracy: 0.9836309523809523\n",
            "\t\t\tVal Loss: 0.014288011433867117 - Val Accuracy: 0.7626666666666667\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 7050, Loss 0.001212370116263628\n",
            "\t\tTrain step - Step 7080, Loss 0.001091329613700509\n",
            "\t\tTrain step - Step 7110, Loss 0.000993465888313949\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.0014953254184330857 - Train Accuracy: 0.9836309523809523\n",
            "\t\t\tVal Loss: 0.014116256847046316 - Val Accuracy: 0.7766666666666666\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 7140, Loss 0.0019073870498687029\n",
            "\t\tTrain step - Step 7170, Loss 0.0009813992073759437\n",
            "\t\tTrain step - Step 7200, Loss 0.0018118360312655568\n",
            "\t\tTrain step - Step 7230, Loss 0.0020455808844417334\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.0015003558203932786 - Train Accuracy: 0.9829613095238096\n",
            "\t\t\tVal Loss: 0.014449704438447952 - Val Accuracy: 0.7706666666666667\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 7260, Loss 0.001533246017061174\n",
            "\t\tTrain step - Step 7290, Loss 0.0012294522020965815\n",
            "\t\tTrain step - Step 7320, Loss 0.0010674946242943406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/24 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.0014353462151207384 - Train Accuracy: 0.9861607142857143\n",
            "\t\t\tVal Loss: 0.014452594798058271 - Val Accuracy: 0.7666666666666667\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [00:00<00:00, 24.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 3:\n",
            "\t\tTrain Mean Accuracy: 0.8535150935374147\n",
            "\t\tVal Mean Accuracy: 0.6719809523809522\n",
            "\t\tTest Accuracy: 0.766\n",
            "\n",
            "STARTING JOINT TRAINING STAGE 4...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.020010419189929962\n",
            "\t\tTrain step - Step 60, Loss 0.0158910620957613\n",
            "\t\tTrain step - Step 90, Loss 0.016582585871219635\n",
            "\t\tTrain step - Step 120, Loss 0.015636146068572998\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.018456076245222774 - Train Accuracy: 0.6650111607142857\n",
            "\t\t\tVal Loss: 0.025257432251237333 - Val Accuracy: 0.547\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 150, Loss 0.014847974292933941\n",
            "\t\tTrain step - Step 180, Loss 0.016109852120280266\n",
            "\t\tTrain step - Step 210, Loss 0.016204003244638443\n",
            "\t\tTrain step - Step 240, Loss 0.014261576347053051\n",
            "\t\tTrain step - Step 270, Loss 0.014042534865438938\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.01533882573380002 - Train Accuracy: 0.7071428571428572\n",
            "\t\t\tVal Loss: 0.02399202180095017 - Val Accuracy: 0.57\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.012768699787557125\n",
            "\t\tTrain step - Step 330, Loss 0.016386736184358597\n",
            "\t\tTrain step - Step 360, Loss 0.01563938893377781\n",
            "\t\tTrain step - Step 390, Loss 0.011638352647423744\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.014698600043941822 - Train Accuracy: 0.7200334821428571\n",
            "\t\t\tVal Loss: 0.02147751726442948 - Val Accuracy: 0.598\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 420, Loss 0.01380064245313406\n",
            "\t\tTrain step - Step 450, Loss 0.01320362277328968\n",
            "\t\tTrain step - Step 480, Loss 0.017303192988038063\n",
            "\t\tTrain step - Step 510, Loss 0.0154831288382411\n",
            "\t\tTrain step - Step 540, Loss 0.01344255916774273\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.014242552639916538 - Train Accuracy: 0.7280133928571428\n",
            "\t\t\tVal Loss: 0.024421691603492945 - Val Accuracy: 0.5535\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.011196608655154705\n",
            "\t\tTrain step - Step 600, Loss 0.015096258372068405\n",
            "\t\tTrain step - Step 630, Loss 0.013445400632917881\n",
            "\t\tTrain step - Step 660, Loss 0.01467086747288704\n",
            "\t\tTrain step - Step 690, Loss 0.014853181317448616\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.013970009603404573 - Train Accuracy: 0.73359375\n",
            "\t\t\tVal Loss: 0.021392682392615825 - Val Accuracy: 0.607\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.01580865867435932\n",
            "\t\tTrain step - Step 750, Loss 0.01443724799901247\n",
            "\t\tTrain step - Step 780, Loss 0.015657849609851837\n",
            "\t\tTrain step - Step 810, Loss 0.016589483246207237\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.013236141577363015 - Train Accuracy: 0.7510602678571429\n",
            "\t\t\tVal Loss: 0.02122047229204327 - Val Accuracy: 0.6025\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.013015433214604855\n",
            "\t\tTrain step - Step 870, Loss 0.010637177154421806\n",
            "\t\tTrain step - Step 900, Loss 0.014579388312995434\n",
            "\t\tTrain step - Step 930, Loss 0.015209467150270939\n",
            "\t\tTrain step - Step 960, Loss 0.01243869960308075\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.013118928744058523 - Train Accuracy: 0.7513950892857143\n",
            "\t\t\tVal Loss: 0.02083102607866749 - Val Accuracy: 0.617\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.013793968595564365\n",
            "\t\tTrain step - Step 1020, Loss 0.012638784013688564\n",
            "\t\tTrain step - Step 1050, Loss 0.01115306094288826\n",
            "\t\tTrain step - Step 1080, Loss 0.014347909018397331\n",
            "\t\tTrain step - Step 1110, Loss 0.013838597573339939\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.01286510138639382 - Train Accuracy: 0.7588727678571429\n",
            "\t\t\tVal Loss: 0.021554604114498943 - Val Accuracy: 0.6045\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.013759516179561615\n",
            "\t\tTrain step - Step 1170, Loss 0.014434585347771645\n",
            "\t\tTrain step - Step 1200, Loss 0.01655418984591961\n",
            "\t\tTrain step - Step 1230, Loss 0.012642974965274334\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.012727346823417715 - Train Accuracy: 0.7623325892857142\n",
            "\t\t\tVal Loss: 0.019676072261063382 - Val Accuracy: 0.6425\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.010803396813571453\n",
            "\t\tTrain step - Step 1290, Loss 0.011179015040397644\n",
            "\t\tTrain step - Step 1320, Loss 0.010488218627870083\n",
            "\t\tTrain step - Step 1350, Loss 0.012199537828564644\n",
            "\t\tTrain step - Step 1380, Loss 0.010369024239480495\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.012435908409367714 - Train Accuracy: 0.7676339285714285\n",
            "\t\t\tVal Loss: 0.021466480626259 - Val Accuracy: 0.604\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.00989297404885292\n",
            "\t\tTrain step - Step 1440, Loss 0.012036890722811222\n",
            "\t\tTrain step - Step 1470, Loss 0.012203201651573181\n",
            "\t\tTrain step - Step 1500, Loss 0.013055653311312199\n",
            "\t\tTrain step - Step 1530, Loss 0.011158948764204979\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.012358271503554924 - Train Accuracy: 0.7681361607142857\n",
            "\t\t\tVal Loss: 0.02146739378804341 - Val Accuracy: 0.6005\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.010722659528255463\n",
            "\t\tTrain step - Step 1590, Loss 0.011971533298492432\n",
            "\t\tTrain step - Step 1620, Loss 0.010680262930691242\n",
            "\t\tTrain step - Step 1650, Loss 0.013737878762185574\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.012342105486563273 - Train Accuracy: 0.7680803571428572\n",
            "\t\t\tVal Loss: 0.020701681001810357 - Val Accuracy: 0.613\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.008897462859749794\n",
            "\t\tTrain step - Step 1710, Loss 0.01215963065624237\n",
            "\t\tTrain step - Step 1740, Loss 0.01356379222124815\n",
            "\t\tTrain step - Step 1770, Loss 0.010745439678430557\n",
            "\t\tTrain step - Step 1800, Loss 0.012608184479176998\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.012140932965225407 - Train Accuracy: 0.7737165178571429\n",
            "\t\t\tVal Loss: 0.020754705677973107 - Val Accuracy: 0.62\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 1830, Loss 0.01054391823709011\n",
            "\t\tTrain step - Step 1860, Loss 0.010393109172582626\n",
            "\t\tTrain step - Step 1890, Loss 0.01146995835006237\n",
            "\t\tTrain step - Step 1920, Loss 0.012843064963817596\n",
            "\t\tTrain step - Step 1950, Loss 0.012317436747252941\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.011918238856430565 - Train Accuracy: 0.7790736607142857\n",
            "\t\t\tVal Loss: 0.019572468823753297 - Val Accuracy: 0.6355\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 1980, Loss 0.012080426327884197\n",
            "\t\tTrain step - Step 2010, Loss 0.012866220436990261\n",
            "\t\tTrain step - Step 2040, Loss 0.011488092131912708\n",
            "\t\tTrain step - Step 2070, Loss 0.014437145553529263\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.011852430538939578 - Train Accuracy: 0.7774553571428572\n",
            "\t\t\tVal Loss: 0.022767443617340177 - Val Accuracy: 0.5845\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 2100, Loss 0.01196447852998972\n",
            "\t\tTrain step - Step 2130, Loss 0.012813248671591282\n",
            "\t\tTrain step - Step 2160, Loss 0.011844737455248833\n",
            "\t\tTrain step - Step 2190, Loss 0.009941570460796356\n",
            "\t\tTrain step - Step 2220, Loss 0.00966416671872139\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.011604825952755554 - Train Accuracy: 0.7829241071428571\n",
            "\t\t\tVal Loss: 0.024567139451391995 - Val Accuracy: 0.578\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 2250, Loss 0.010785127989947796\n",
            "\t\tTrain step - Step 2280, Loss 0.011643526144325733\n",
            "\t\tTrain step - Step 2310, Loss 0.010266944766044617\n",
            "\t\tTrain step - Step 2340, Loss 0.008949045091867447\n",
            "\t\tTrain step - Step 2370, Loss 0.00957357045263052\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.01129706480340766 - Train Accuracy: 0.7914620535714286\n",
            "\t\t\tVal Loss: 0.019995890266727656 - Val Accuracy: 0.6285\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 2400, Loss 0.010322473011910915\n",
            "\t\tTrain step - Step 2430, Loss 0.011048560030758381\n",
            "\t\tTrain step - Step 2460, Loss 0.009434235282242298\n",
            "\t\tTrain step - Step 2490, Loss 0.011042118072509766\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.011429483835984553 - Train Accuracy: 0.7866629464285714\n",
            "\t\t\tVal Loss: 0.021576694562099874 - Val Accuracy: 0.6175\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 2520, Loss 0.00912510696798563\n",
            "\t\tTrain step - Step 2550, Loss 0.010424184612929821\n",
            "\t\tTrain step - Step 2580, Loss 0.01315272506326437\n",
            "\t\tTrain step - Step 2610, Loss 0.01129242591559887\n",
            "\t\tTrain step - Step 2640, Loss 0.010399559512734413\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.011416065257175692 - Train Accuracy: 0.7863839285714286\n",
            "\t\t\tVal Loss: 0.020728784147650003 - Val Accuracy: 0.622\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 2670, Loss 0.014768899418413639\n",
            "\t\tTrain step - Step 2700, Loss 0.0118953175842762\n",
            "\t\tTrain step - Step 2730, Loss 0.010208136402070522\n",
            "\t\tTrain step - Step 2760, Loss 0.012308089062571526\n",
            "\t\tTrain step - Step 2790, Loss 0.013987602666020393\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.01110870999816273 - Train Accuracy: 0.7929129464285715\n",
            "\t\t\tVal Loss: 0.019244128663558513 - Val Accuracy: 0.6385\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 2820, Loss 0.009742679074406624\n",
            "\t\tTrain step - Step 2850, Loss 0.009628145024180412\n",
            "\t\tTrain step - Step 2880, Loss 0.011078369803726673\n",
            "\t\tTrain step - Step 2910, Loss 0.010504800826311111\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.01099735226349107 - Train Accuracy: 0.7986607142857143\n",
            "\t\t\tVal Loss: 0.023752619163133204 - Val Accuracy: 0.59\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 2940, Loss 0.011966164223849773\n",
            "\t\tTrain step - Step 2970, Loss 0.009114994667470455\n",
            "\t\tTrain step - Step 3000, Loss 0.012533132918179035\n",
            "\t\tTrain step - Step 3030, Loss 0.01295347511768341\n",
            "\t\tTrain step - Step 3060, Loss 0.010325422510504723\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.011151627664055143 - Train Accuracy: 0.7952566964285714\n",
            "\t\t\tVal Loss: 0.021038360486272722 - Val Accuracy: 0.634\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 3090, Loss 0.009098518639802933\n",
            "\t\tTrain step - Step 3120, Loss 0.013341781683266163\n",
            "\t\tTrain step - Step 3150, Loss 0.009084532968699932\n",
            "\t\tTrain step - Step 3180, Loss 0.010331626050174236\n",
            "\t\tTrain step - Step 3210, Loss 0.01327571365982294\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.010869183178458895 - Train Accuracy: 0.7975446428571429\n",
            "\t\t\tVal Loss: 0.021411206107586622 - Val Accuracy: 0.6125\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 3240, Loss 0.011332588270306587\n",
            "\t\tTrain step - Step 3270, Loss 0.01212263759225607\n",
            "\t\tTrain step - Step 3300, Loss 0.01008521392941475\n",
            "\t\tTrain step - Step 3330, Loss 0.01216199155896902\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.010899322629640145 - Train Accuracy: 0.7997767857142857\n",
            "\t\t\tVal Loss: 0.02216763954493217 - Val Accuracy: 0.6065\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 3360, Loss 0.009954828768968582\n",
            "\t\tTrain step - Step 3390, Loss 0.010069196112453938\n",
            "\t\tTrain step - Step 3420, Loss 0.010099763981997967\n",
            "\t\tTrain step - Step 3450, Loss 0.011338982731103897\n",
            "\t\tTrain step - Step 3480, Loss 0.010925030335783958\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.01072405412061406 - Train Accuracy: 0.80234375\n",
            "\t\t\tVal Loss: 0.021377260505687445 - Val Accuracy: 0.6285\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 3510, Loss 0.009320382960140705\n",
            "\t\tTrain step - Step 3540, Loss 0.011604023166000843\n",
            "\t\tTrain step - Step 3570, Loss 0.010907499119639397\n",
            "\t\tTrain step - Step 3600, Loss 0.011557528749108315\n",
            "\t\tTrain step - Step 3630, Loss 0.012630997225642204\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.010668652863906962 - Train Accuracy: 0.8030691964285714\n",
            "\t\t\tVal Loss: 0.020860906457528472 - Val Accuracy: 0.6215\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 3660, Loss 0.009857560507953167\n",
            "\t\tTrain step - Step 3690, Loss 0.010425028391182423\n",
            "\t\tTrain step - Step 3720, Loss 0.01067139022052288\n",
            "\t\tTrain step - Step 3750, Loss 0.01052348967641592\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.010548252000340394 - Train Accuracy: 0.8078683035714286\n",
            "\t\t\tVal Loss: 0.020312749460572377 - Val Accuracy: 0.6455\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 3780, Loss 0.009225058369338512\n",
            "\t\tTrain step - Step 3810, Loss 0.00860526505857706\n",
            "\t\tTrain step - Step 3840, Loss 0.008005422540009022\n",
            "\t\tTrain step - Step 3870, Loss 0.011221230030059814\n",
            "\t\tTrain step - Step 3900, Loss 0.012998566031455994\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.010510601495791758 - Train Accuracy: 0.8075334821428571\n",
            "\t\t\tVal Loss: 0.021244010189548135 - Val Accuracy: 0.636\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 3930, Loss 0.007927454076707363\n",
            "\t\tTrain step - Step 3960, Loss 0.010482732206583023\n",
            "\t\tTrain step - Step 3990, Loss 0.012086995877325535\n",
            "\t\tTrain step - Step 4020, Loss 0.008125841617584229\n",
            "\t\tTrain step - Step 4050, Loss 0.015496685169637203\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.010807759075292519 - Train Accuracy: 0.8017857142857143\n",
            "\t\t\tVal Loss: 0.02486263564787805 - Val Accuracy: 0.5715\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 4080, Loss 0.012028217315673828\n",
            "\t\tTrain step - Step 4110, Loss 0.010716748423874378\n",
            "\t\tTrain step - Step 4140, Loss 0.01102131325751543\n",
            "\t\tTrain step - Step 4170, Loss 0.010362501256167889\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.010411627111690386 - Train Accuracy: 0.8084821428571428\n",
            "\t\t\tVal Loss: 0.021938163263257593 - Val Accuracy: 0.616\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 4200, Loss 0.010762832127511501\n",
            "\t\tTrain step - Step 4230, Loss 0.009043987840414047\n",
            "\t\tTrain step - Step 4260, Loss 0.0121057303622365\n",
            "\t\tTrain step - Step 4290, Loss 0.010656199418008327\n",
            "\t\tTrain step - Step 4320, Loss 0.012648181989789009\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.010499206092208623 - Train Accuracy: 0.8046316964285715\n",
            "\t\t\tVal Loss: 0.0217171247350052 - Val Accuracy: 0.615\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 4350, Loss 0.00845950748771429\n",
            "\t\tTrain step - Step 4380, Loss 0.008523190394043922\n",
            "\t\tTrain step - Step 4410, Loss 0.008352572098374367\n",
            "\t\tTrain step - Step 4440, Loss 0.010943950153887272\n",
            "\t\tTrain step - Step 4470, Loss 0.011145937256515026\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.010154879442416132 - Train Accuracy: 0.81484375\n",
            "\t\t\tVal Loss: 0.02037168137030676 - Val Accuracy: 0.637\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 4500, Loss 0.010195481590926647\n",
            "\t\tTrain step - Step 4530, Loss 0.009463983587920666\n",
            "\t\tTrain step - Step 4560, Loss 0.009049688465893269\n",
            "\t\tTrain step - Step 4590, Loss 0.0077573941089212894\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.010348168723950429 - Train Accuracy: 0.8087611607142857\n",
            "\t\t\tVal Loss: 0.022936367779038846 - Val Accuracy: 0.601\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 4620, Loss 0.009576171636581421\n",
            "\t\tTrain step - Step 4650, Loss 0.009651606902480125\n",
            "\t\tTrain step - Step 4680, Loss 0.013394082896411419\n",
            "\t\tTrain step - Step 4710, Loss 0.009323357604444027\n",
            "\t\tTrain step - Step 4740, Loss 0.009156650863587856\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.00998806025101138 - Train Accuracy: 0.8175223214285714\n",
            "\t\t\tVal Loss: 0.021394577925093472 - Val Accuracy: 0.6275\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 4770, Loss 0.007237964775413275\n",
            "\t\tTrain step - Step 4800, Loss 0.008403394371271133\n",
            "\t\tTrain step - Step 4830, Loss 0.008649175055325031\n",
            "\t\tTrain step - Step 4860, Loss 0.011184845119714737\n",
            "\t\tTrain step - Step 4890, Loss 0.009748205542564392\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.010196590583239283 - Train Accuracy: 0.8164620535714285\n",
            "\t\t\tVal Loss: 0.02041599655058235 - Val Accuracy: 0.638\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 4920, Loss 0.007713810075074434\n",
            "\t\tTrain step - Step 4950, Loss 0.010827171616256237\n",
            "\t\tTrain step - Step 4980, Loss 0.010685479268431664\n",
            "\t\tTrain step - Step 5010, Loss 0.011295601725578308\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.010072711293053415 - Train Accuracy: 0.815625\n",
            "\t\t\tVal Loss: 0.021216952241957188 - Val Accuracy: 0.6295\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 5040, Loss 0.008389108814299107\n",
            "\t\tTrain step - Step 5070, Loss 0.008565298281610012\n",
            "\t\tTrain step - Step 5100, Loss 0.011405243538320065\n",
            "\t\tTrain step - Step 5130, Loss 0.009913569316267967\n",
            "\t\tTrain step - Step 5160, Loss 0.010526883415877819\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.009937975040104772 - Train Accuracy: 0.8172991071428571\n",
            "\t\t\tVal Loss: 0.020117355044931173 - Val Accuracy: 0.64\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 5190, Loss 0.008649542927742004\n",
            "\t\tTrain step - Step 5220, Loss 0.00913424976170063\n",
            "\t\tTrain step - Step 5250, Loss 0.010673662647604942\n",
            "\t\tTrain step - Step 5280, Loss 0.011267540976405144\n",
            "\t\tTrain step - Step 5310, Loss 0.009416444227099419\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.009857183748057911 - Train Accuracy: 0.819921875\n",
            "\t\t\tVal Loss: 0.022071032144594938 - Val Accuracy: 0.6135\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 5340, Loss 0.009726385585963726\n",
            "\t\tTrain step - Step 5370, Loss 0.009322915226221085\n",
            "\t\tTrain step - Step 5400, Loss 0.009023956023156643\n",
            "\t\tTrain step - Step 5430, Loss 0.008887297473847866\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.010007335009452488 - Train Accuracy: 0.8194754464285714\n",
            "\t\t\tVal Loss: 0.02080537547590211 - Val Accuracy: 0.634\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 5460, Loss 0.006487944163382053\n",
            "\t\tTrain step - Step 5490, Loss 0.008767005056142807\n",
            "\t\tTrain step - Step 5520, Loss 0.00895765796303749\n",
            "\t\tTrain step - Step 5550, Loss 0.011894133873283863\n",
            "\t\tTrain step - Step 5580, Loss 0.009882235899567604\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.009676586952991784 - Train Accuracy: 0.8247209821428572\n",
            "\t\t\tVal Loss: 0.01979396922979504 - Val Accuracy: 0.643\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 5610, Loss 0.010470283217728138\n",
            "\t\tTrain step - Step 5640, Loss 0.010354672558605671\n",
            "\t\tTrain step - Step 5670, Loss 0.010519890114665031\n",
            "\t\tTrain step - Step 5700, Loss 0.010262889787554741\n",
            "\t\tTrain step - Step 5730, Loss 0.009966924786567688\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.010001622243518277 - Train Accuracy: 0.8181361607142857\n",
            "\t\t\tVal Loss: 0.02019723365083337 - Val Accuracy: 0.6295\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 5760, Loss 0.009688363410532475\n",
            "\t\tTrain step - Step 5790, Loss 0.008484291844069958\n",
            "\t\tTrain step - Step 5820, Loss 0.008484660647809505\n",
            "\t\tTrain step - Step 5850, Loss 0.01242932677268982\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.0094228048509519 - Train Accuracy: 0.8289620535714286\n",
            "\t\t\tVal Loss: 0.0230831426451914 - Val Accuracy: 0.61\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 5880, Loss 0.009230272844433784\n",
            "\t\tTrain step - Step 5910, Loss 0.008337707258760929\n",
            "\t\tTrain step - Step 5940, Loss 0.010185791179537773\n",
            "\t\tTrain step - Step 5970, Loss 0.009783515706658363\n",
            "\t\tTrain step - Step 6000, Loss 0.012792038731276989\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.009353585038999362 - Train Accuracy: 0.8315290178571428\n",
            "\t\t\tVal Loss: 0.02075974951731041 - Val Accuracy: 0.625\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 6030, Loss 0.008940138854086399\n",
            "\t\tTrain step - Step 6060, Loss 0.01090991497039795\n",
            "\t\tTrain step - Step 6090, Loss 0.01265041995793581\n",
            "\t\tTrain step - Step 6120, Loss 0.010931024327874184\n",
            "\t\tTrain step - Step 6150, Loss 0.012506842613220215\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.009762861682767314 - Train Accuracy: 0.8249441964285714\n",
            "\t\t\tVal Loss: 0.020550317218294367 - Val Accuracy: 0.6455\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 6180, Loss 0.009623144753277302\n",
            "\t\tTrain step - Step 6210, Loss 0.008967522531747818\n",
            "\t\tTrain step - Step 6240, Loss 0.008811555802822113\n",
            "\t\tTrain step - Step 6270, Loss 0.010970880277454853\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.009671764142279113 - Train Accuracy: 0.8261160714285715\n",
            "\t\t\tVal Loss: 0.020498229045188054 - Val Accuracy: 0.6295\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 6300, Loss 0.008079439401626587\n",
            "\t\tTrain step - Step 6330, Loss 0.008113812655210495\n",
            "\t\tTrain step - Step 6360, Loss 0.012475075200200081\n",
            "\t\tTrain step - Step 6390, Loss 0.006680574268102646\n",
            "\t\tTrain step - Step 6420, Loss 0.009075548499822617\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.009402341871256275 - Train Accuracy: 0.8311383928571429\n",
            "\t\t\tVal Loss: 0.01901215559337288 - Val Accuracy: 0.6615\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 6450, Loss 0.008333797566592693\n",
            "\t\tTrain step - Step 6480, Loss 0.009370585903525352\n",
            "\t\tTrain step - Step 6510, Loss 0.010135841555893421\n",
            "\t\tTrain step - Step 6540, Loss 0.011247570626437664\n",
            "\t\tTrain step - Step 6570, Loss 0.010750578716397285\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.009862031884092305 - Train Accuracy: 0.8177455357142858\n",
            "\t\t\tVal Loss: 0.021036048885434866 - Val Accuracy: 0.622\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 6600, Loss 0.008342799730598927\n",
            "\t\tTrain step - Step 6630, Loss 0.010255703702569008\n",
            "\t\tTrain step - Step 6660, Loss 0.008943459950387478\n",
            "\t\tTrain step - Step 6690, Loss 0.011655868962407112\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.009494000021368265 - Train Accuracy: 0.826953125\n",
            "\t\t\tVal Loss: 0.020888593106064945 - Val Accuracy: 0.6365\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 6720, Loss 0.009579498320817947\n",
            "\t\tTrain step - Step 6750, Loss 0.009004328399896622\n",
            "\t\tTrain step - Step 6780, Loss 0.007871674373745918\n",
            "\t\tTrain step - Step 6810, Loss 0.008825683034956455\n",
            "\t\tTrain step - Step 6840, Loss 0.00998400617390871\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.009353636361525527 - Train Accuracy: 0.8290178571428571\n",
            "\t\t\tVal Loss: 0.021927849389612675 - Val Accuracy: 0.6125\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 6870, Loss 0.006212243344634771\n",
            "\t\tTrain step - Step 6900, Loss 0.006456580013036728\n",
            "\t\tTrain step - Step 6930, Loss 0.004940531216561794\n",
            "\t\tTrain step - Step 6960, Loss 0.005918084178119898\n",
            "\t\tTrain step - Step 6990, Loss 0.006104110274463892\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.006214673055468925 - Train Accuracy: 0.8964285714285715\n",
            "\t\t\tVal Loss: 0.014254384994274005 - Val Accuracy: 0.7445\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 7020, Loss 0.004749947693198919\n",
            "\t\tTrain step - Step 7050, Loss 0.0044044977985322475\n",
            "\t\tTrain step - Step 7080, Loss 0.0035688679199665785\n",
            "\t\tTrain step - Step 7110, Loss 0.005213284865021706\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.00490692067292652 - Train Accuracy: 0.9251116071428571\n",
            "\t\t\tVal Loss: 0.014792859554290771 - Val Accuracy: 0.7415\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 7140, Loss 0.004447913728654385\n",
            "\t\tTrain step - Step 7170, Loss 0.004411632195115089\n",
            "\t\tTrain step - Step 7200, Loss 0.0032899316865950823\n",
            "\t\tTrain step - Step 7230, Loss 0.0050401221960783005\n",
            "\t\tTrain step - Step 7260, Loss 0.004749064799398184\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.004463637415652297 - Train Accuracy: 0.9334263392857143\n",
            "\t\t\tVal Loss: 0.01413321340805851 - Val Accuracy: 0.7495\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 7290, Loss 0.0033338922075927258\n",
            "\t\tTrain step - Step 7320, Loss 0.0039510964415967464\n",
            "\t\tTrain step - Step 7350, Loss 0.005275132600218058\n",
            "\t\tTrain step - Step 7380, Loss 0.003640115261077881\n",
            "\t\tTrain step - Step 7410, Loss 0.004733091685920954\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.004177309393084475 - Train Accuracy: 0.9358258928571429\n",
            "\t\t\tVal Loss: 0.014446052082348615 - Val Accuracy: 0.749\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 7440, Loss 0.003347610356286168\n",
            "\t\tTrain step - Step 7470, Loss 0.003598457435145974\n",
            "\t\tTrain step - Step 7500, Loss 0.004324158653616905\n",
            "\t\tTrain step - Step 7530, Loss 0.0034227806609123945\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.0038210722202035997 - Train Accuracy: 0.9430245535714286\n",
            "\t\t\tVal Loss: 0.014911538368323818 - Val Accuracy: 0.7505\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 7560, Loss 0.003495499724522233\n",
            "\t\tTrain step - Step 7590, Loss 0.004373547155410051\n",
            "\t\tTrain step - Step 7620, Loss 0.003316384507343173\n",
            "\t\tTrain step - Step 7650, Loss 0.0035859846975654364\n",
            "\t\tTrain step - Step 7680, Loss 0.0023957802914083004\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.0036525240650267473 - Train Accuracy: 0.9478236607142857\n",
            "\t\t\tVal Loss: 0.014849797647912055 - Val Accuracy: 0.7465\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 7710, Loss 0.0026008086279034615\n",
            "\t\tTrain step - Step 7740, Loss 0.003309910884127021\n",
            "\t\tTrain step - Step 7770, Loss 0.003574649803340435\n",
            "\t\tTrain step - Step 7800, Loss 0.0040714917704463005\n",
            "\t\tTrain step - Step 7830, Loss 0.0033331280574202538\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.0035759846862804677 - Train Accuracy: 0.9475446428571429\n",
            "\t\t\tVal Loss: 0.014821343356743455 - Val Accuracy: 0.7485\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 7860, Loss 0.004265325143933296\n",
            "\t\tTrain step - Step 7890, Loss 0.0032070528250187635\n",
            "\t\tTrain step - Step 7920, Loss 0.002741656731814146\n",
            "\t\tTrain step - Step 7950, Loss 0.00497740413993597\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.003394869280912514 - Train Accuracy: 0.951953125\n",
            "\t\t\tVal Loss: 0.014797826326685026 - Val Accuracy: 0.7475\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 7980, Loss 0.004222695715725422\n",
            "\t\tTrain step - Step 8010, Loss 0.0027908985503017902\n",
            "\t\tTrain step - Step 8040, Loss 0.0029653257224708796\n",
            "\t\tTrain step - Step 8070, Loss 0.0024896126706153154\n",
            "\t\tTrain step - Step 8100, Loss 0.0038152222987264395\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.003277365068372871 - Train Accuracy: 0.9532366071428572\n",
            "\t\t\tVal Loss: 0.01563153395545669 - Val Accuracy: 0.7365\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 8130, Loss 0.002528546378016472\n",
            "\t\tTrain step - Step 8160, Loss 0.002974266419187188\n",
            "\t\tTrain step - Step 8190, Loss 0.0030129163060337305\n",
            "\t\tTrain step - Step 8220, Loss 0.003503073938190937\n",
            "\t\tTrain step - Step 8250, Loss 0.0038626601453870535\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.003068495262414217 - Train Accuracy: 0.9568638392857143\n",
            "\t\t\tVal Loss: 0.015829550859052688 - Val Accuracy: 0.734\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 8280, Loss 0.002089964458718896\n",
            "\t\tTrain step - Step 8310, Loss 0.0025237153749912977\n",
            "\t\tTrain step - Step 8340, Loss 0.0030516188126057386\n",
            "\t\tTrain step - Step 8370, Loss 0.003645437303930521\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.003007208931791995 - Train Accuracy: 0.9582589285714286\n",
            "\t\t\tVal Loss: 0.015545863163424656 - Val Accuracy: 0.7465\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 8400, Loss 0.0027453110087662935\n",
            "\t\tTrain step - Step 8430, Loss 0.0031324666924774647\n",
            "\t\tTrain step - Step 8460, Loss 0.002238598419353366\n",
            "\t\tTrain step - Step 8490, Loss 0.0028364157769829035\n",
            "\t\tTrain step - Step 8520, Loss 0.002511823084205389\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.0029358687852176703 - Train Accuracy: 0.9587053571428571\n",
            "\t\t\tVal Loss: 0.015624232008121908 - Val Accuracy: 0.744\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 8550, Loss 0.002715931972488761\n",
            "\t\tTrain step - Step 8580, Loss 0.003436827566474676\n",
            "\t\tTrain step - Step 8610, Loss 0.003144371323287487\n",
            "\t\tTrain step - Step 8640, Loss 0.0034586244728416204\n",
            "\t\tTrain step - Step 8670, Loss 0.004852907732129097\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.0028692655772569456 - Train Accuracy: 0.9598772321428571\n",
            "\t\t\tVal Loss: 0.015671694214688614 - Val Accuracy: 0.749\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 8700, Loss 0.0031379866413772106\n",
            "\t\tTrain step - Step 8730, Loss 0.003289078362286091\n",
            "\t\tTrain step - Step 8760, Loss 0.0022242360282689333\n",
            "\t\tTrain step - Step 8790, Loss 0.0020351202692836523\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.0027166239659501506 - Train Accuracy: 0.9643415178571428\n",
            "\t\t\tVal Loss: 0.016126441478263587 - Val Accuracy: 0.747\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 8820, Loss 0.003493395633995533\n",
            "\t\tTrain step - Step 8850, Loss 0.002146865241229534\n",
            "\t\tTrain step - Step 8880, Loss 0.001710053300485015\n",
            "\t\tTrain step - Step 8910, Loss 0.002513191429898143\n",
            "\t\tTrain step - Step 8940, Loss 0.0016738660633563995\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.002336130742748667 - Train Accuracy: 0.9709821428571429\n",
            "\t\t\tVal Loss: 0.015895851771347225 - Val Accuracy: 0.746\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 8970, Loss 0.0016559150535613298\n",
            "\t\tTrain step - Step 9000, Loss 0.0018691623117774725\n",
            "\t\tTrain step - Step 9030, Loss 0.001853741123341024\n",
            "\t\tTrain step - Step 9060, Loss 0.0024110653903335333\n",
            "\t\tTrain step - Step 9090, Loss 0.0019631620962172747\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.002188645737312202 - Train Accuracy: 0.9732700892857142\n",
            "\t\t\tVal Loss: 0.014891243074089289 - Val Accuracy: 0.756\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 9120, Loss 0.0014413255266845226\n",
            "\t\tTrain step - Step 9150, Loss 0.001941857859492302\n",
            "\t\tTrain step - Step 9180, Loss 0.001261868397705257\n",
            "\t\tTrain step - Step 9210, Loss 0.0018631552811712027\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.0021177819298048104 - Train Accuracy: 0.9751116071428572\n",
            "\t\t\tVal Loss: 0.015883938584011048 - Val Accuracy: 0.7445\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 9240, Loss 0.002346100052818656\n",
            "\t\tTrain step - Step 9270, Loss 0.002094981959089637\n",
            "\t\tTrain step - Step 9300, Loss 0.002507030963897705\n",
            "\t\tTrain step - Step 9330, Loss 0.0024292091839015484\n",
            "\t\tTrain step - Step 9360, Loss 0.002526711206883192\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.002116076831173684 - Train Accuracy: 0.9752232142857142\n",
            "\t\t\tVal Loss: 0.015106312173884362 - Val Accuracy: 0.7545\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 9390, Loss 0.001551105291582644\n",
            "\t\tTrain step - Step 9420, Loss 0.0017574900994077325\n",
            "\t\tTrain step - Step 9450, Loss 0.003161750268191099\n",
            "\t\tTrain step - Step 9480, Loss 0.0018117317231371999\n",
            "\t\tTrain step - Step 9510, Loss 0.002733164932578802\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.002044903627497011 - Train Accuracy: 0.9765625\n",
            "\t\t\tVal Loss: 0.015139603841817006 - Val Accuracy: 0.7525\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 9540, Loss 0.0020544303115457296\n",
            "\t\tTrain step - Step 9570, Loss 0.0023218318819999695\n",
            "\t\tTrain step - Step 9600, Loss 0.0017400922952219844\n",
            "\t\tTrain step - Step 9630, Loss 0.002393175382167101\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.00200145037711731 - Train Accuracy: 0.9774553571428571\n",
            "\t\t\tVal Loss: 0.015890170878265053 - Val Accuracy: 0.75\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 9660, Loss 0.0025371061637997627\n",
            "\t\tTrain step - Step 9690, Loss 0.0012188112596049905\n",
            "\t\tTrain step - Step 9720, Loss 0.0019768865313380957\n",
            "\t\tTrain step - Step 9750, Loss 0.0012157597811892629\n",
            "\t\tTrain step - Step 9780, Loss 0.002374164294451475\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/32 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.001979321938623408 - Train Accuracy: 0.9780133928571428\n",
            "\t\t\tVal Loss: 0.015544379042694345 - Val Accuracy: 0.756\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 22.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 4:\n",
            "\t\tTrain Mean Accuracy: 0.8403866390306123\n",
            "\t\tVal Mean Accuracy: 0.6555785714285713\n",
            "\t\tTest Accuracy: 0.75825\n",
            "\n",
            "STARTING JOINT TRAINING STAGE 5...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.01918521523475647\n",
            "\t\tTrain step - Step 60, Loss 0.014674187637865543\n",
            "\t\tTrain step - Step 90, Loss 0.014279620721936226\n",
            "\t\tTrain step - Step 120, Loss 0.017734307795763016\n",
            "\t\tTrain step - Step 150, Loss 0.01577826961874962\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.016693064687507492 - Train Accuracy: 0.7014285714285714\n",
            "\t\t\tVal Loss: 0.02293566884472966 - Val Accuracy: 0.5916\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.014391304925084114\n",
            "\t\tTrain step - Step 210, Loss 0.01637030951678753\n",
            "\t\tTrain step - Step 240, Loss 0.012815632857382298\n",
            "\t\tTrain step - Step 270, Loss 0.011390838772058487\n",
            "\t\tTrain step - Step 300, Loss 0.014026409015059471\n",
            "\t\tTrain step - Step 330, Loss 0.012105283327400684\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.014190244892878191 - Train Accuracy: 0.7380803571428571\n",
            "\t\t\tVal Loss: 0.02485385756008327 - Val Accuracy: 0.5644\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.012952754274010658\n",
            "\t\tTrain step - Step 390, Loss 0.014556906186044216\n",
            "\t\tTrain step - Step 420, Loss 0.01267552375793457\n",
            "\t\tTrain step - Step 450, Loss 0.01443462073802948\n",
            "\t\tTrain step - Step 480, Loss 0.01200910285115242\n",
            "\t\tTrain step - Step 510, Loss 0.013332763686776161\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.013475441746413708 - Train Accuracy: 0.7510714285714286\n",
            "\t\t\tVal Loss: 0.024842517962679268 - Val Accuracy: 0.5776\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 540, Loss 0.011986873112618923\n",
            "\t\tTrain step - Step 570, Loss 0.013566391542553902\n",
            "\t\tTrain step - Step 600, Loss 0.013123828917741776\n",
            "\t\tTrain step - Step 630, Loss 0.014888589270412922\n",
            "\t\tTrain step - Step 660, Loss 0.012791936285793781\n",
            "\t\tTrain step - Step 690, Loss 0.014034844003617764\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.013313766393278326 - Train Accuracy: 0.7558482142857142\n",
            "\t\t\tVal Loss: 0.026072705257683994 - Val Accuracy: 0.5376\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.013104095123708248\n",
            "\t\tTrain step - Step 750, Loss 0.013110442087054253\n",
            "\t\tTrain step - Step 780, Loss 0.013602538034319878\n",
            "\t\tTrain step - Step 810, Loss 0.011456495150923729\n",
            "\t\tTrain step - Step 840, Loss 0.015506697818636894\n",
            "\t\tTrain step - Step 870, Loss 0.013011201284825802\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.012980186891342912 - Train Accuracy: 0.7615625\n",
            "\t\t\tVal Loss: 0.02045382894575596 - Val Accuracy: 0.6232\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.012493586167693138\n",
            "\t\tTrain step - Step 930, Loss 0.013906142674386501\n",
            "\t\tTrain step - Step 960, Loss 0.012639828957617283\n",
            "\t\tTrain step - Step 990, Loss 0.01332132052630186\n",
            "\t\tTrain step - Step 1020, Loss 0.011612079106271267\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.012813085062163217 - Train Accuracy: 0.7642410714285715\n",
            "\t\t\tVal Loss: 0.02096023955382407 - Val Accuracy: 0.6172\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 1050, Loss 0.011078419163823128\n",
            "\t\tTrain step - Step 1080, Loss 0.011271366849541664\n",
            "\t\tTrain step - Step 1110, Loss 0.009492126293480396\n",
            "\t\tTrain step - Step 1140, Loss 0.014327573589980602\n",
            "\t\tTrain step - Step 1170, Loss 0.014136898331344128\n",
            "\t\tTrain step - Step 1200, Loss 0.013656148687005043\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.012597518068339144 - Train Accuracy: 0.766875\n",
            "\t\t\tVal Loss: 0.021253841230645776 - Val Accuracy: 0.6064\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.01256563887000084\n",
            "\t\tTrain step - Step 1260, Loss 0.014994332566857338\n",
            "\t\tTrain step - Step 1290, Loss 0.011455348692834377\n",
            "\t\tTrain step - Step 1320, Loss 0.012274457141757011\n",
            "\t\tTrain step - Step 1350, Loss 0.015462247654795647\n",
            "\t\tTrain step - Step 1380, Loss 0.012980163097381592\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.01260507523481335 - Train Accuracy: 0.7652678571428572\n",
            "\t\t\tVal Loss: 0.021004053857177497 - Val Accuracy: 0.6128\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.012401338666677475\n",
            "\t\tTrain step - Step 1440, Loss 0.01210307702422142\n",
            "\t\tTrain step - Step 1470, Loss 0.015091253444552422\n",
            "\t\tTrain step - Step 1500, Loss 0.015290500596165657\n",
            "\t\tTrain step - Step 1530, Loss 0.01193730067461729\n",
            "\t\tTrain step - Step 1560, Loss 0.013253319077193737\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.012494515803243433 - Train Accuracy: 0.7710714285714285\n",
            "\t\t\tVal Loss: 0.02193123116157949 - Val Accuracy: 0.622\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 1590, Loss 0.014284050092101097\n",
            "\t\tTrain step - Step 1620, Loss 0.011540485545992851\n",
            "\t\tTrain step - Step 1650, Loss 0.011203629896044731\n",
            "\t\tTrain step - Step 1680, Loss 0.012603147886693478\n",
            "\t\tTrain step - Step 1710, Loss 0.011328316293656826\n",
            "\t\tTrain step - Step 1740, Loss 0.013734311796724796\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.012367841691843101 - Train Accuracy: 0.7716964285714286\n",
            "\t\t\tVal Loss: 0.02321771429851651 - Val Accuracy: 0.5948\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 1770, Loss 0.011224200017750263\n",
            "\t\tTrain step - Step 1800, Loss 0.01165099162608385\n",
            "\t\tTrain step - Step 1830, Loss 0.013545991852879524\n",
            "\t\tTrain step - Step 1860, Loss 0.011414563283324242\n",
            "\t\tTrain step - Step 1890, Loss 0.012601575814187527\n",
            "\t\tTrain step - Step 1920, Loss 0.012996410951018333\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.012204470964414732 - Train Accuracy: 0.7785267857142857\n",
            "\t\t\tVal Loss: 0.022169026196934283 - Val Accuracy: 0.6\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 1950, Loss 0.014214739203453064\n",
            "\t\tTrain step - Step 1980, Loss 0.010986510664224625\n",
            "\t\tTrain step - Step 2010, Loss 0.011417686939239502\n",
            "\t\tTrain step - Step 2040, Loss 0.01391260139644146\n",
            "\t\tTrain step - Step 2070, Loss 0.012287978082895279\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.01202965421868222 - Train Accuracy: 0.78\n",
            "\t\t\tVal Loss: 0.023036450939252974 - Val Accuracy: 0.6128\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 2100, Loss 0.01127468328922987\n",
            "\t\tTrain step - Step 2130, Loss 0.011493762023746967\n",
            "\t\tTrain step - Step 2160, Loss 0.011672134511172771\n",
            "\t\tTrain step - Step 2190, Loss 0.01114149671047926\n",
            "\t\tTrain step - Step 2220, Loss 0.012483721598982811\n",
            "\t\tTrain step - Step 2250, Loss 0.015158730559051037\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.0122445073351264 - Train Accuracy: 0.7765178571428571\n",
            "\t\t\tVal Loss: 0.025103546562604606 - Val Accuracy: 0.562\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 2280, Loss 0.014146588742733002\n",
            "\t\tTrain step - Step 2310, Loss 0.011113166809082031\n",
            "\t\tTrain step - Step 2340, Loss 0.00955058354884386\n",
            "\t\tTrain step - Step 2370, Loss 0.012252697721123695\n",
            "\t\tTrain step - Step 2400, Loss 0.012167923152446747\n",
            "\t\tTrain step - Step 2430, Loss 0.011666965670883656\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.011864072318587984 - Train Accuracy: 0.7812053571428571\n",
            "\t\t\tVal Loss: 0.025573452515527607 - Val Accuracy: 0.5716\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 2460, Loss 0.009708340279757977\n",
            "\t\tTrain step - Step 2490, Loss 0.011128139682114124\n",
            "\t\tTrain step - Step 2520, Loss 0.012332526966929436\n",
            "\t\tTrain step - Step 2550, Loss 0.012090640142560005\n",
            "\t\tTrain step - Step 2580, Loss 0.013201720081269741\n",
            "\t\tTrain step - Step 2610, Loss 0.012392963282763958\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.01194586253059762 - Train Accuracy: 0.7817857142857143\n",
            "\t\t\tVal Loss: 0.019963588938117026 - Val Accuracy: 0.638\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 2640, Loss 0.011914268136024475\n",
            "\t\tTrain step - Step 2670, Loss 0.012483613565564156\n",
            "\t\tTrain step - Step 2700, Loss 0.010478677228093147\n",
            "\t\tTrain step - Step 2730, Loss 0.011683912947773933\n",
            "\t\tTrain step - Step 2760, Loss 0.010946627706289291\n",
            "\t\tTrain step - Step 2790, Loss 0.012711104936897755\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.01168070617531027 - Train Accuracy: 0.7884821428571429\n",
            "\t\t\tVal Loss: 0.021222289511933924 - Val Accuracy: 0.6192\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 2820, Loss 0.012099304236471653\n",
            "\t\tTrain step - Step 2850, Loss 0.010273301042616367\n",
            "\t\tTrain step - Step 2880, Loss 0.013159980066120625\n",
            "\t\tTrain step - Step 2910, Loss 0.013620755635201931\n",
            "\t\tTrain step - Step 2940, Loss 0.012793157249689102\n",
            "\t\tTrain step - Step 2970, Loss 0.012808420695364475\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.011872817634471825 - Train Accuracy: 0.7844196428571428\n",
            "\t\t\tVal Loss: 0.020741746481508016 - Val Accuracy: 0.6228\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 3000, Loss 0.010301923379302025\n",
            "\t\tTrain step - Step 3030, Loss 0.010261119343340397\n",
            "\t\tTrain step - Step 3060, Loss 0.012120372615754604\n",
            "\t\tTrain step - Step 3090, Loss 0.011678628623485565\n",
            "\t\tTrain step - Step 3120, Loss 0.012341503985226154\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.011590557204825538 - Train Accuracy: 0.7867410714285714\n",
            "\t\t\tVal Loss: 0.022219859529286623 - Val Accuracy: 0.6092\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 3150, Loss 0.0103131840005517\n",
            "\t\tTrain step - Step 3180, Loss 0.009181050583720207\n",
            "\t\tTrain step - Step 3210, Loss 0.010009064339101315\n",
            "\t\tTrain step - Step 3240, Loss 0.011184687726199627\n",
            "\t\tTrain step - Step 3270, Loss 0.01252727396786213\n",
            "\t\tTrain step - Step 3300, Loss 0.011835641227662563\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.0114020254170256 - Train Accuracy: 0.7898660714285715\n",
            "\t\t\tVal Loss: 0.020977622456848623 - Val Accuracy: 0.6384\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 3330, Loss 0.010046937502920628\n",
            "\t\tTrain step - Step 3360, Loss 0.012289664708077908\n",
            "\t\tTrain step - Step 3390, Loss 0.009074327535927296\n",
            "\t\tTrain step - Step 3420, Loss 0.012947749346494675\n",
            "\t\tTrain step - Step 3450, Loss 0.011815284378826618\n",
            "\t\tTrain step - Step 3480, Loss 0.013071119785308838\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.011787819681423051 - Train Accuracy: 0.7845089285714286\n",
            "\t\t\tVal Loss: 0.02116714066360146 - Val Accuracy: 0.6296\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 3510, Loss 0.00904069934040308\n",
            "\t\tTrain step - Step 3540, Loss 0.008933437056839466\n",
            "\t\tTrain step - Step 3570, Loss 0.012595792300999165\n",
            "\t\tTrain step - Step 3600, Loss 0.014606365002691746\n",
            "\t\tTrain step - Step 3630, Loss 0.013187252916395664\n",
            "\t\tTrain step - Step 3660, Loss 0.013052526861429214\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.011599487236567906 - Train Accuracy: 0.7877232142857142\n",
            "\t\t\tVal Loss: 0.019983929954469203 - Val Accuracy: 0.6356\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 3690, Loss 0.014745539985597134\n",
            "\t\tTrain step - Step 3720, Loss 0.009359734132885933\n",
            "\t\tTrain step - Step 3750, Loss 0.013832511380314827\n",
            "\t\tTrain step - Step 3780, Loss 0.011005429551005363\n",
            "\t\tTrain step - Step 3810, Loss 0.014633756130933762\n",
            "\t\tTrain step - Step 3840, Loss 0.009071841835975647\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.011411389580794743 - Train Accuracy: 0.7923660714285714\n",
            "\t\t\tVal Loss: 0.022966207331046463 - Val Accuracy: 0.6008\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 3870, Loss 0.008887344039976597\n",
            "\t\tTrain step - Step 3900, Loss 0.012319603003561497\n",
            "\t\tTrain step - Step 3930, Loss 0.012608513236045837\n",
            "\t\tTrain step - Step 3960, Loss 0.00985241960734129\n",
            "\t\tTrain step - Step 3990, Loss 0.012079138308763504\n",
            "\t\tTrain step - Step 4020, Loss 0.010147458873689175\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.011420205618653978 - Train Accuracy: 0.7915178571428572\n",
            "\t\t\tVal Loss: 0.021233679517172276 - Val Accuracy: 0.6216\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 4050, Loss 0.010973346419632435\n",
            "\t\tTrain step - Step 4080, Loss 0.010678274556994438\n",
            "\t\tTrain step - Step 4110, Loss 0.010215403512120247\n",
            "\t\tTrain step - Step 4140, Loss 0.011943311430513859\n",
            "\t\tTrain step - Step 4170, Loss 0.011744603514671326\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.01122131187202675 - Train Accuracy: 0.7966517857142857\n",
            "\t\t\tVal Loss: 0.021777900401502848 - Val Accuracy: 0.622\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 4200, Loss 0.00888333935290575\n",
            "\t\tTrain step - Step 4230, Loss 0.010227086022496223\n",
            "\t\tTrain step - Step 4260, Loss 0.013643618673086166\n",
            "\t\tTrain step - Step 4290, Loss 0.013637732714414597\n",
            "\t\tTrain step - Step 4320, Loss 0.011294771917164326\n",
            "\t\tTrain step - Step 4350, Loss 0.01384668331593275\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.011480286536472184 - Train Accuracy: 0.7912946428571429\n",
            "\t\t\tVal Loss: 0.02285141418687999 - Val Accuracy: 0.6028\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 4380, Loss 0.011841113679111004\n",
            "\t\tTrain step - Step 4410, Loss 0.012857887893915176\n",
            "\t\tTrain step - Step 4440, Loss 0.011163637042045593\n",
            "\t\tTrain step - Step 4470, Loss 0.009181836619973183\n",
            "\t\tTrain step - Step 4500, Loss 0.014049123972654343\n",
            "\t\tTrain step - Step 4530, Loss 0.013264112174510956\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.011305100284516811 - Train Accuracy: 0.7927232142857142\n",
            "\t\t\tVal Loss: 0.02053644130937755 - Val Accuracy: 0.626\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 4560, Loss 0.01142884697765112\n",
            "\t\tTrain step - Step 4590, Loss 0.009815588593482971\n",
            "\t\tTrain step - Step 4620, Loss 0.009733215905725956\n",
            "\t\tTrain step - Step 4650, Loss 0.011637894436717033\n",
            "\t\tTrain step - Step 4680, Loss 0.009928550571203232\n",
            "\t\tTrain step - Step 4710, Loss 0.012385961599647999\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.01111639638032232 - Train Accuracy: 0.7975\n",
            "\t\t\tVal Loss: 0.022398166172206403 - Val Accuracy: 0.6072\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 4740, Loss 0.00958195049315691\n",
            "\t\tTrain step - Step 4770, Loss 0.010236000642180443\n",
            "\t\tTrain step - Step 4800, Loss 0.0086475545540452\n",
            "\t\tTrain step - Step 4830, Loss 0.011110114865005016\n",
            "\t\tTrain step - Step 4860, Loss 0.009613375179469585\n",
            "\t\tTrain step - Step 4890, Loss 0.012762036174535751\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.011189184931239911 - Train Accuracy: 0.79375\n",
            "\t\t\tVal Loss: 0.021745497803203763 - Val Accuracy: 0.6208\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 4920, Loss 0.009422555565834045\n",
            "\t\tTrain step - Step 4950, Loss 0.012520451098680496\n",
            "\t\tTrain step - Step 4980, Loss 0.009913327172398567\n",
            "\t\tTrain step - Step 5010, Loss 0.012002845294773579\n",
            "\t\tTrain step - Step 5040, Loss 0.012426457367837429\n",
            "\t\tTrain step - Step 5070, Loss 0.014756714925169945\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.011088304767119033 - Train Accuracy: 0.7986607142857143\n",
            "\t\t\tVal Loss: 0.020783609384670852 - Val Accuracy: 0.6244\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 5100, Loss 0.011278332211077213\n",
            "\t\tTrain step - Step 5130, Loss 0.010351710021495819\n",
            "\t\tTrain step - Step 5160, Loss 0.008329218253493309\n",
            "\t\tTrain step - Step 5190, Loss 0.011853138916194439\n",
            "\t\tTrain step - Step 5220, Loss 0.012405021116137505\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.011120209446442979 - Train Accuracy: 0.7976339285714286\n",
            "\t\t\tVal Loss: 0.020104827638715506 - Val Accuracy: 0.6456\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 5250, Loss 0.0071985917165875435\n",
            "\t\tTrain step - Step 5280, Loss 0.012158927507698536\n",
            "\t\tTrain step - Step 5310, Loss 0.009910340420901775\n",
            "\t\tTrain step - Step 5340, Loss 0.010835574939846992\n",
            "\t\tTrain step - Step 5370, Loss 0.012444177642464638\n",
            "\t\tTrain step - Step 5400, Loss 0.010879111476242542\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.011034384715769972 - Train Accuracy: 0.7986607142857143\n",
            "\t\t\tVal Loss: 0.01988901635631919 - Val Accuracy: 0.6412\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 5430, Loss 0.00966638047248125\n",
            "\t\tTrain step - Step 5460, Loss 0.011615423485636711\n",
            "\t\tTrain step - Step 5490, Loss 0.009616113267838955\n",
            "\t\tTrain step - Step 5520, Loss 0.013116402551531792\n",
            "\t\tTrain step - Step 5550, Loss 0.010424381121993065\n",
            "\t\tTrain step - Step 5580, Loss 0.011460446752607822\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.011009366783712591 - Train Accuracy: 0.7997767857142857\n",
            "\t\t\tVal Loss: 0.020860148314386606 - Val Accuracy: 0.6236\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 5610, Loss 0.011324786581099033\n",
            "\t\tTrain step - Step 5640, Loss 0.012106982991099358\n",
            "\t\tTrain step - Step 5670, Loss 0.008661523461341858\n",
            "\t\tTrain step - Step 5700, Loss 0.00966251827776432\n",
            "\t\tTrain step - Step 5730, Loss 0.01215561106801033\n",
            "\t\tTrain step - Step 5760, Loss 0.014452867209911346\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.011023887496973786 - Train Accuracy: 0.8001339285714286\n",
            "\t\t\tVal Loss: 0.02048246874473989 - Val Accuracy: 0.6348\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 5790, Loss 0.009984922595322132\n",
            "\t\tTrain step - Step 5820, Loss 0.010987009853124619\n",
            "\t\tTrain step - Step 5850, Loss 0.009345263242721558\n",
            "\t\tTrain step - Step 5880, Loss 0.01280508004128933\n",
            "\t\tTrain step - Step 5910, Loss 0.00981493666768074\n",
            "\t\tTrain step - Step 5940, Loss 0.012294415384531021\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.011041535064578056 - Train Accuracy: 0.7977678571428571\n",
            "\t\t\tVal Loss: 0.020656622387468813 - Val Accuracy: 0.6224\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 5970, Loss 0.010686223395168781\n",
            "\t\tTrain step - Step 6000, Loss 0.010556276887655258\n",
            "\t\tTrain step - Step 6030, Loss 0.011248328723013401\n",
            "\t\tTrain step - Step 6060, Loss 0.011979908682405949\n",
            "\t\tTrain step - Step 6090, Loss 0.010895686224102974\n",
            "\t\tTrain step - Step 6120, Loss 0.010269653983414173\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.011034262494317123 - Train Accuracy: 0.7986160714285714\n",
            "\t\t\tVal Loss: 0.020744974818080665 - Val Accuracy: 0.6348\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 6150, Loss 0.008410674519836903\n",
            "\t\tTrain step - Step 6180, Loss 0.010714436881244183\n",
            "\t\tTrain step - Step 6210, Loss 0.010491392575204372\n",
            "\t\tTrain step - Step 6240, Loss 0.01027163490653038\n",
            "\t\tTrain step - Step 6270, Loss 0.01236140076071024\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.01100694245791861 - Train Accuracy: 0.8012946428571428\n",
            "\t\t\tVal Loss: 0.02113353698514402 - Val Accuracy: 0.6308\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 6300, Loss 0.01010388694703579\n",
            "\t\tTrain step - Step 6330, Loss 0.011539976112544537\n",
            "\t\tTrain step - Step 6360, Loss 0.008960369974374771\n",
            "\t\tTrain step - Step 6390, Loss 0.013211497105658054\n",
            "\t\tTrain step - Step 6420, Loss 0.015217217616736889\n",
            "\t\tTrain step - Step 6450, Loss 0.013471991755068302\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.010915732269308396 - Train Accuracy: 0.8027232142857142\n",
            "\t\t\tVal Loss: 0.019948349753394722 - Val Accuracy: 0.632\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 6480, Loss 0.011185672134160995\n",
            "\t\tTrain step - Step 6510, Loss 0.012423581443727016\n",
            "\t\tTrain step - Step 6540, Loss 0.01232348382472992\n",
            "\t\tTrain step - Step 6570, Loss 0.011221302673220634\n",
            "\t\tTrain step - Step 6600, Loss 0.01047658734023571\n",
            "\t\tTrain step - Step 6630, Loss 0.013105363585054874\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.010822003691324166 - Train Accuracy: 0.8033035714285715\n",
            "\t\t\tVal Loss: 0.020145268039777876 - Val Accuracy: 0.638\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 6660, Loss 0.010997827164828777\n",
            "\t\tTrain step - Step 6690, Loss 0.008925794623792171\n",
            "\t\tTrain step - Step 6720, Loss 0.00864285696297884\n",
            "\t\tTrain step - Step 6750, Loss 0.01150734443217516\n",
            "\t\tTrain step - Step 6780, Loss 0.01061735488474369\n",
            "\t\tTrain step - Step 6810, Loss 0.012648246251046658\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.010775077555860792 - Train Accuracy: 0.805625\n",
            "\t\t\tVal Loss: 0.02287899786606431 - Val Accuracy: 0.6108\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 6840, Loss 0.009933319874107838\n",
            "\t\tTrain step - Step 6870, Loss 0.010361067950725555\n",
            "\t\tTrain step - Step 6900, Loss 0.009486570954322815\n",
            "\t\tTrain step - Step 6930, Loss 0.008182900957763195\n",
            "\t\tTrain step - Step 6960, Loss 0.009241067804396152\n",
            "\t\tTrain step - Step 6990, Loss 0.01397485937923193\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.010724606825304883 - Train Accuracy: 0.8064732142857143\n",
            "\t\t\tVal Loss: 0.021195195149630308 - Val Accuracy: 0.6204\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 7020, Loss 0.009847363457083702\n",
            "\t\tTrain step - Step 7050, Loss 0.008839142508804798\n",
            "\t\tTrain step - Step 7080, Loss 0.008439606055617332\n",
            "\t\tTrain step - Step 7110, Loss 0.008896227926015854\n",
            "\t\tTrain step - Step 7140, Loss 0.011329231783747673\n",
            "\t\tTrain step - Step 7170, Loss 0.009749580174684525\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.010800089628568717 - Train Accuracy: 0.8053571428571429\n",
            "\t\t\tVal Loss: 0.02472079957369715 - Val Accuracy: 0.5812\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 7200, Loss 0.01057501882314682\n",
            "\t\tTrain step - Step 7230, Loss 0.010732357390224934\n",
            "\t\tTrain step - Step 7260, Loss 0.010670032352209091\n",
            "\t\tTrain step - Step 7290, Loss 0.013750663958489895\n",
            "\t\tTrain step - Step 7320, Loss 0.015105513855814934\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.010888108411537749 - Train Accuracy: 0.8040625\n",
            "\t\t\tVal Loss: 0.019060651515610517 - Val Accuracy: 0.6584\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 7350, Loss 0.009018653072416782\n",
            "\t\tTrain step - Step 7380, Loss 0.012409372255206108\n",
            "\t\tTrain step - Step 7410, Loss 0.011667453683912754\n",
            "\t\tTrain step - Step 7440, Loss 0.011365680024027824\n",
            "\t\tTrain step - Step 7470, Loss 0.011790648102760315\n",
            "\t\tTrain step - Step 7500, Loss 0.010129068978130817\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.010586880767451866 - Train Accuracy: 0.8078571428571428\n",
            "\t\t\tVal Loss: 0.022213156381621958 - Val Accuracy: 0.6152\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 7530, Loss 0.008083618246018887\n",
            "\t\tTrain step - Step 7560, Loss 0.009278240613639355\n",
            "\t\tTrain step - Step 7590, Loss 0.01328445877879858\n",
            "\t\tTrain step - Step 7620, Loss 0.011188916862010956\n",
            "\t\tTrain step - Step 7650, Loss 0.01150639820843935\n",
            "\t\tTrain step - Step 7680, Loss 0.013232390396296978\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.010678452593939645 - Train Accuracy: 0.8091071428571428\n",
            "\t\t\tVal Loss: 0.018964622309431432 - Val Accuracy: 0.6476\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 7710, Loss 0.007947280071675777\n",
            "\t\tTrain step - Step 7740, Loss 0.01179610937833786\n",
            "\t\tTrain step - Step 7770, Loss 0.010882331989705563\n",
            "\t\tTrain step - Step 7800, Loss 0.01101341936737299\n",
            "\t\tTrain step - Step 7830, Loss 0.012438858859241009\n",
            "\t\tTrain step - Step 7860, Loss 0.010948197916150093\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.010366016738116742 - Train Accuracy: 0.8123660714285714\n",
            "\t\t\tVal Loss: 0.021152112213894726 - Val Accuracy: 0.63\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 7890, Loss 0.009848523885011673\n",
            "\t\tTrain step - Step 7920, Loss 0.007166005205363035\n",
            "\t\tTrain step - Step 7950, Loss 0.009158014319837093\n",
            "\t\tTrain step - Step 7980, Loss 0.01003655418753624\n",
            "\t\tTrain step - Step 8010, Loss 0.013477594591677189\n",
            "\t\tTrain step - Step 8040, Loss 0.009497388266026974\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.010468585797186408 - Train Accuracy: 0.81375\n",
            "\t\t\tVal Loss: 0.019868280738592148 - Val Accuracy: 0.65\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 8070, Loss 0.010661741718649864\n",
            "\t\tTrain step - Step 8100, Loss 0.009998654946684837\n",
            "\t\tTrain step - Step 8130, Loss 0.01041814498603344\n",
            "\t\tTrain step - Step 8160, Loss 0.010655896738171577\n",
            "\t\tTrain step - Step 8190, Loss 0.012037402018904686\n",
            "\t\tTrain step - Step 8220, Loss 0.01014392264187336\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.010626655817031861 - Train Accuracy: 0.8066071428571429\n",
            "\t\t\tVal Loss: 0.020550101529806852 - Val Accuracy: 0.644\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 8250, Loss 0.010939841158688068\n",
            "\t\tTrain step - Step 8280, Loss 0.010142291896045208\n",
            "\t\tTrain step - Step 8310, Loss 0.009797366335988045\n",
            "\t\tTrain step - Step 8340, Loss 0.00949943158775568\n",
            "\t\tTrain step - Step 8370, Loss 0.011118877679109573\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.01045984452058162 - Train Accuracy: 0.8129017857142857\n",
            "\t\t\tVal Loss: 0.019601001776754855 - Val Accuracy: 0.654\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 8400, Loss 0.009303104132413864\n",
            "\t\tTrain step - Step 8430, Loss 0.011454801075160503\n",
            "\t\tTrain step - Step 8460, Loss 0.008319079875946045\n",
            "\t\tTrain step - Step 8490, Loss 0.01276456844061613\n",
            "\t\tTrain step - Step 8520, Loss 0.013772922568023205\n",
            "\t\tTrain step - Step 8550, Loss 0.011255604214966297\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.010503291405205216 - Train Accuracy: 0.8118303571428571\n",
            "\t\t\tVal Loss: 0.021276005497202276 - Val Accuracy: 0.6244\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 8580, Loss 0.010559466667473316\n",
            "\t\tTrain step - Step 8610, Loss 0.008435830473899841\n",
            "\t\tTrain step - Step 8640, Loss 0.005768312606960535\n",
            "\t\tTrain step - Step 8670, Loss 0.006603095214813948\n",
            "\t\tTrain step - Step 8700, Loss 0.005840753670781851\n",
            "\t\tTrain step - Step 8730, Loss 0.005301775876432657\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.007038039240453924 - Train Accuracy: 0.8848214285714285\n",
            "\t\t\tVal Loss: 0.014903880702331663 - Val Accuracy: 0.7348\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 8760, Loss 0.00520816445350647\n",
            "\t\tTrain step - Step 8790, Loss 0.006364703178405762\n",
            "\t\tTrain step - Step 8820, Loss 0.0048837545327842236\n",
            "\t\tTrain step - Step 8850, Loss 0.0047791218385100365\n",
            "\t\tTrain step - Step 8880, Loss 0.006873341742902994\n",
            "\t\tTrain step - Step 8910, Loss 0.004667758010327816\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.005604933263467891 - Train Accuracy: 0.9119196428571429\n",
            "\t\t\tVal Loss: 0.014428366837091745 - Val Accuracy: 0.7376\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 8940, Loss 0.004392147529870272\n",
            "\t\tTrain step - Step 8970, Loss 0.005333291366696358\n",
            "\t\tTrain step - Step 9000, Loss 0.004538374487310648\n",
            "\t\tTrain step - Step 9030, Loss 0.0046510035172104836\n",
            "\t\tTrain step - Step 9060, Loss 0.004776229616254568\n",
            "\t\tTrain step - Step 9090, Loss 0.00466932775452733\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.005172553034499288 - Train Accuracy: 0.9202232142857143\n",
            "\t\t\tVal Loss: 0.015175228449515998 - Val Accuracy: 0.7412\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 9120, Loss 0.00567665696144104\n",
            "\t\tTrain step - Step 9150, Loss 0.004817331209778786\n",
            "\t\tTrain step - Step 9180, Loss 0.005582112353295088\n",
            "\t\tTrain step - Step 9210, Loss 0.007102860137820244\n",
            "\t\tTrain step - Step 9240, Loss 0.004686526954174042\n",
            "\t\tTrain step - Step 9270, Loss 0.005425355397164822\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.004938136182193245 - Train Accuracy: 0.9259375\n",
            "\t\t\tVal Loss: 0.015028344397433103 - Val Accuracy: 0.734\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 9300, Loss 0.004037120379507542\n",
            "\t\tTrain step - Step 9330, Loss 0.004279155749827623\n",
            "\t\tTrain step - Step 9360, Loss 0.004107646644115448\n",
            "\t\tTrain step - Step 9390, Loss 0.006741730496287346\n",
            "\t\tTrain step - Step 9420, Loss 0.0044601378031075\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.004579789685085416 - Train Accuracy: 0.9309821428571429\n",
            "\t\t\tVal Loss: 0.014586544153280557 - Val Accuracy: 0.7512\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 9450, Loss 0.003956648521125317\n",
            "\t\tTrain step - Step 9480, Loss 0.005171949975192547\n",
            "\t\tTrain step - Step 9510, Loss 0.004953020252287388\n",
            "\t\tTrain step - Step 9540, Loss 0.005360704381018877\n",
            "\t\tTrain step - Step 9570, Loss 0.00537146208807826\n",
            "\t\tTrain step - Step 9600, Loss 0.0032995673827826977\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.004401886790458645 - Train Accuracy: 0.9331696428571429\n",
            "\t\t\tVal Loss: 0.015233532106503845 - Val Accuracy: 0.7328\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 9630, Loss 0.0034704911522567272\n",
            "\t\tTrain step - Step 9660, Loss 0.0036698358599096537\n",
            "\t\tTrain step - Step 9690, Loss 0.004209861624985933\n",
            "\t\tTrain step - Step 9720, Loss 0.0037678247317671776\n",
            "\t\tTrain step - Step 9750, Loss 0.0037471407558768988\n",
            "\t\tTrain step - Step 9780, Loss 0.005428110249340534\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.0042218154801854065 - Train Accuracy: 0.9377678571428572\n",
            "\t\t\tVal Loss: 0.015375951700843871 - Val Accuracy: 0.736\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 9810, Loss 0.003333375323563814\n",
            "\t\tTrain step - Step 9840, Loss 0.003847411833703518\n",
            "\t\tTrain step - Step 9870, Loss 0.005192230921238661\n",
            "\t\tTrain step - Step 9900, Loss 0.002795920241624117\n",
            "\t\tTrain step - Step 9930, Loss 0.0037658452056348324\n",
            "\t\tTrain step - Step 9960, Loss 0.003916206303983927\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.004011944661449109 - Train Accuracy: 0.9410714285714286\n",
            "\t\t\tVal Loss: 0.01567120661493391 - Val Accuracy: 0.7396\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 9990, Loss 0.003613904817029834\n",
            "\t\tTrain step - Step 10020, Loss 0.003826134605333209\n",
            "\t\tTrain step - Step 10050, Loss 0.004077559802681208\n",
            "\t\tTrain step - Step 10080, Loss 0.003509914269670844\n",
            "\t\tTrain step - Step 10110, Loss 0.002924192463979125\n",
            "\t\tTrain step - Step 10140, Loss 0.0048264688812196255\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.004024808312367116 - Train Accuracy: 0.9402232142857143\n",
            "\t\t\tVal Loss: 0.01586048996541649 - Val Accuracy: 0.7276\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 10170, Loss 0.0033813011832535267\n",
            "\t\tTrain step - Step 10200, Loss 0.0035383652430027723\n",
            "\t\tTrain step - Step 10230, Loss 0.0039846403524279594\n",
            "\t\tTrain step - Step 10260, Loss 0.0038275038823485374\n",
            "\t\tTrain step - Step 10290, Loss 0.003432496218010783\n",
            "\t\tTrain step - Step 10320, Loss 0.0039355154149234295\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.003767107353279633 - Train Accuracy: 0.9461607142857142\n",
            "\t\t\tVal Loss: 0.015637888316996397 - Val Accuracy: 0.7424\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 10350, Loss 0.0031275611836463213\n",
            "\t\tTrain step - Step 10380, Loss 0.003029878716915846\n",
            "\t\tTrain step - Step 10410, Loss 0.0031803457532078028\n",
            "\t\tTrain step - Step 10440, Loss 0.0037254381459206343\n",
            "\t\tTrain step - Step 10470, Loss 0.003249023575335741\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.003677379941966917 - Train Accuracy: 0.9481696428571429\n",
            "\t\t\tVal Loss: 0.01583235473372042 - Val Accuracy: 0.7324\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 10500, Loss 0.0038339076563715935\n",
            "\t\tTrain step - Step 10530, Loss 0.004069143906235695\n",
            "\t\tTrain step - Step 10560, Loss 0.003118511289358139\n",
            "\t\tTrain step - Step 10590, Loss 0.0035354469437152147\n",
            "\t\tTrain step - Step 10620, Loss 0.005680930335074663\n",
            "\t\tTrain step - Step 10650, Loss 0.0034581574145704508\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.0035696488339453936 - Train Accuracy: 0.9485267857142857\n",
            "\t\t\tVal Loss: 0.016523237386718393 - Val Accuracy: 0.726\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 10680, Loss 0.0034142695367336273\n",
            "\t\tTrain step - Step 10710, Loss 0.0035721457097679377\n",
            "\t\tTrain step - Step 10740, Loss 0.0031983202788978815\n",
            "\t\tTrain step - Step 10770, Loss 0.003145748982205987\n",
            "\t\tTrain step - Step 10800, Loss 0.004705361090600491\n",
            "\t\tTrain step - Step 10830, Loss 0.0062887114472687244\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.0035600298144189374 - Train Accuracy: 0.9491071428571428\n",
            "\t\t\tVal Loss: 0.01584563332144171 - Val Accuracy: 0.7344\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 10860, Loss 0.003456905484199524\n",
            "\t\tTrain step - Step 10890, Loss 0.0029058700893074274\n",
            "\t\tTrain step - Step 10920, Loss 0.0026366901583969593\n",
            "\t\tTrain step - Step 10950, Loss 0.0033572425600141287\n",
            "\t\tTrain step - Step 10980, Loss 0.002095572417601943\n",
            "\t\tTrain step - Step 11010, Loss 0.003121771849691868\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.0035278681732181993 - Train Accuracy: 0.9483928571428571\n",
            "\t\t\tVal Loss: 0.01634394919965416 - Val Accuracy: 0.7348\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 11040, Loss 0.003800843609496951\n",
            "\t\tTrain step - Step 11070, Loss 0.0027791170869022608\n",
            "\t\tTrain step - Step 11100, Loss 0.0036967371124774218\n",
            "\t\tTrain step - Step 11130, Loss 0.004078054800629616\n",
            "\t\tTrain step - Step 11160, Loss 0.0030927585903555155\n",
            "\t\tTrain step - Step 11190, Loss 0.002599393716081977\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.002957819247219179 - Train Accuracy: 0.9603125\n",
            "\t\t\tVal Loss: 0.015769787691533567 - Val Accuracy: 0.7392\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 11220, Loss 0.0023478774819523096\n",
            "\t\tTrain step - Step 11250, Loss 0.0019543771632015705\n",
            "\t\tTrain step - Step 11280, Loss 0.0025178270880132914\n",
            "\t\tTrain step - Step 11310, Loss 0.003914316650480032\n",
            "\t\tTrain step - Step 11340, Loss 0.0026196155231446028\n",
            "\t\tTrain step - Step 11370, Loss 0.0016818498261272907\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.00268561964788075 - Train Accuracy: 0.9674553571428571\n",
            "\t\t\tVal Loss: 0.01508350467775017 - Val Accuracy: 0.7456\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 11400, Loss 0.003313639434054494\n",
            "\t\tTrain step - Step 11430, Loss 0.0021911554504185915\n",
            "\t\tTrain step - Step 11460, Loss 0.0036399380769580603\n",
            "\t\tTrain step - Step 11490, Loss 0.0020513173658400774\n",
            "\t\tTrain step - Step 11520, Loss 0.002555576618760824\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.0026017594756558536 - Train Accuracy: 0.9679464285714285\n",
            "\t\t\tVal Loss: 0.015462637390010059 - Val Accuracy: 0.7416\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 11550, Loss 0.002359881531447172\n",
            "\t\tTrain step - Step 11580, Loss 0.0024205660447478294\n",
            "\t\tTrain step - Step 11610, Loss 0.002306330483406782\n",
            "\t\tTrain step - Step 11640, Loss 0.0030887520406395197\n",
            "\t\tTrain step - Step 11670, Loss 0.002473615575581789\n",
            "\t\tTrain step - Step 11700, Loss 0.002266889438033104\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.0026053157315722533 - Train Accuracy: 0.9678125\n",
            "\t\t\tVal Loss: 0.015579936536960303 - Val Accuracy: 0.744\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 11730, Loss 0.002937782322987914\n",
            "\t\tTrain step - Step 11760, Loss 0.002294612815603614\n",
            "\t\tTrain step - Step 11790, Loss 0.0030254488810896873\n",
            "\t\tTrain step - Step 11820, Loss 0.0031512847635895014\n",
            "\t\tTrain step - Step 11850, Loss 0.0022106505930423737\n",
            "\t\tTrain step - Step 11880, Loss 0.0026135980151593685\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.0025088338440816317 - Train Accuracy: 0.9688839285714286\n",
            "\t\t\tVal Loss: 0.016203399701043963 - Val Accuracy: 0.7372\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 11910, Loss 0.00411812961101532\n",
            "\t\tTrain step - Step 11940, Loss 0.0020388083066791296\n",
            "\t\tTrain step - Step 11970, Loss 0.002712975023314357\n",
            "\t\tTrain step - Step 12000, Loss 0.002802231814712286\n",
            "\t\tTrain step - Step 12030, Loss 0.002338569611310959\n",
            "\t\tTrain step - Step 12060, Loss 0.0025055643636733294\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.002490979373854186 - Train Accuracy: 0.9700892857142858\n",
            "\t\t\tVal Loss: 0.015433465829119086 - Val Accuracy: 0.7528\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 12090, Loss 0.0019987761043012142\n",
            "\t\tTrain step - Step 12120, Loss 0.0033088105265051126\n",
            "\t\tTrain step - Step 12150, Loss 0.0022256665397435427\n",
            "\t\tTrain step - Step 12180, Loss 0.003688011784106493\n",
            "\t\tTrain step - Step 12210, Loss 0.0025434147100895643\n",
            "\t\tTrain step - Step 12240, Loss 0.002945167012512684\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.002401180459585573 - Train Accuracy: 0.9719196428571428\n",
            "\t\t\tVal Loss: 0.015681000659242272 - Val Accuracy: 0.7468\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:01<00:00, 26.74it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 5:\n",
            "\t\tTrain Mean Accuracy: 0.8351160714285716\n",
            "\t\tVal Mean Accuracy: 0.6537657142857144\n",
            "\t\tTest Accuracy: 0.7472\n",
            "\n",
            "STARTING JOINT TRAINING STAGE 6...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n",
            "\t\tTrain step - Step 30, Loss 0.015853507444262505\n",
            "\t\tTrain step - Step 60, Loss 0.014758361503481865\n",
            "\t\tTrain step - Step 90, Loss 0.015581519342958927\n",
            "\t\tTrain step - Step 120, Loss 0.01734195463359356\n",
            "\t\tTrain step - Step 150, Loss 0.016140347346663475\n",
            "\t\tTrain step - Step 180, Loss 0.01655927486717701\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.016577748014103798 - Train Accuracy: 0.7054315476190476\n",
            "\t\t\tVal Loss: 0.02268562027408431 - Val Accuracy: 0.578\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.015660012140870094\n",
            "\t\tTrain step - Step 240, Loss 0.01702270284295082\n",
            "\t\tTrain step - Step 270, Loss 0.013298743404448032\n",
            "\t\tTrain step - Step 300, Loss 0.014465009793639183\n",
            "\t\tTrain step - Step 330, Loss 0.012900269590318203\n",
            "\t\tTrain step - Step 360, Loss 0.016966862604022026\n",
            "\t\tTrain step - Step 390, Loss 0.014434517361223698\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.014622511759045578 - Train Accuracy: 0.7299107142857143\n",
            "\t\t\tVal Loss: 0.02333194688738634 - Val Accuracy: 0.5796666666666667\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 420, Loss 0.012268013320863247\n",
            "\t\tTrain step - Step 450, Loss 0.015295307151973248\n",
            "\t\tTrain step - Step 480, Loss 0.011624474078416824\n",
            "\t\tTrain step - Step 510, Loss 0.01261714193969965\n",
            "\t\tTrain step - Step 540, Loss 0.01638379506766796\n",
            "\t\tTrain step - Step 570, Loss 0.012391580268740654\n",
            "\t\tTrain step - Step 600, Loss 0.015713153406977654\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.014265662014839194 - Train Accuracy: 0.73984375\n",
            "\t\t\tVal Loss: 0.024709961163656164 - Val Accuracy: 0.567\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.012946431525051594\n",
            "\t\tTrain step - Step 660, Loss 0.013148671947419643\n",
            "\t\tTrain step - Step 690, Loss 0.014660386368632317\n",
            "\t\tTrain step - Step 720, Loss 0.013433546759188175\n",
            "\t\tTrain step - Step 750, Loss 0.015922974795103073\n",
            "\t\tTrain step - Step 780, Loss 0.013401715084910393\n",
            "\t\tTrain step - Step 810, Loss 0.014492382295429707\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.013675480229513986 - Train Accuracy: 0.7527901785714286\n",
            "\t\t\tVal Loss: 0.022891827820179362 - Val Accuracy: 0.5783333333333334\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.014949562028050423\n",
            "\t\tTrain step - Step 870, Loss 0.011532247066497803\n",
            "\t\tTrain step - Step 900, Loss 0.013880040496587753\n",
            "\t\tTrain step - Step 930, Loss 0.014079246670007706\n",
            "\t\tTrain step - Step 960, Loss 0.01417042687535286\n",
            "\t\tTrain step - Step 990, Loss 0.012773422524333\n",
            "\t\tTrain step - Step 1020, Loss 0.016643477603793144\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.013707211298779363 - Train Accuracy: 0.750297619047619\n",
            "\t\t\tVal Loss: 0.02729455924903353 - Val Accuracy: 0.5173333333333333\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 1050, Loss 0.01697126403450966\n",
            "\t\tTrain step - Step 1080, Loss 0.01229056715965271\n",
            "\t\tTrain step - Step 1110, Loss 0.01427390519529581\n",
            "\t\tTrain step - Step 1140, Loss 0.014245367608964443\n",
            "\t\tTrain step - Step 1170, Loss 0.014559967443346977\n",
            "\t\tTrain step - Step 1200, Loss 0.013677065260708332\n",
            "\t\tTrain step - Step 1230, Loss 0.015671348199248314\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.013760849350087699 - Train Accuracy: 0.7489955357142857\n",
            "\t\t\tVal Loss: 0.02122214195939402 - Val Accuracy: 0.6163333333333333\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.013665583916008472\n",
            "\t\tTrain step - Step 1290, Loss 0.013099145144224167\n",
            "\t\tTrain step - Step 1320, Loss 0.014397873543202877\n",
            "\t\tTrain step - Step 1350, Loss 0.013369996100664139\n",
            "\t\tTrain step - Step 1380, Loss 0.01440302561968565\n",
            "\t\tTrain step - Step 1410, Loss 0.01309471856802702\n",
            "\t\tTrain step - Step 1440, Loss 0.01593107171356678\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.013458560699863092 - Train Accuracy: 0.7542782738095238\n",
            "\t\t\tVal Loss: 0.0217230844621857 - Val Accuracy: 0.5943333333333334\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.013015185482800007\n",
            "\t\tTrain step - Step 1500, Loss 0.013656997121870518\n",
            "\t\tTrain step - Step 1530, Loss 0.01442842185497284\n",
            "\t\tTrain step - Step 1560, Loss 0.01424333080649376\n",
            "\t\tTrain step - Step 1590, Loss 0.015071913599967957\n",
            "\t\tTrain step - Step 1620, Loss 0.013174095191061497\n",
            "\t\tTrain step - Step 1650, Loss 0.013274131342768669\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.013389388276707558 - Train Accuracy: 0.7569568452380953\n",
            "\t\t\tVal Loss: 0.02530630270484835 - Val Accuracy: 0.5463333333333333\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.011512004770338535\n",
            "\t\tTrain step - Step 1710, Loss 0.012618781067430973\n",
            "\t\tTrain step - Step 1740, Loss 0.010894400998950005\n",
            "\t\tTrain step - Step 1770, Loss 0.012821253389120102\n",
            "\t\tTrain step - Step 1800, Loss 0.01635368913412094\n",
            "\t\tTrain step - Step 1830, Loss 0.01295363251119852\n",
            "\t\tTrain step - Step 1860, Loss 0.011728423647582531\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.013287664635018223 - Train Accuracy: 0.7572544642857143\n",
            "\t\t\tVal Loss: 0.02255355050632109 - Val Accuracy: 0.5816666666666667\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 1890, Loss 0.01396751869469881\n",
            "\t\tTrain step - Step 1920, Loss 0.010242079384624958\n",
            "\t\tTrain step - Step 1950, Loss 0.012417053803801537\n",
            "\t\tTrain step - Step 1980, Loss 0.01336993183940649\n",
            "\t\tTrain step - Step 2010, Loss 0.011508393101394176\n",
            "\t\tTrain step - Step 2040, Loss 0.015153884887695312\n",
            "\t\tTrain step - Step 2070, Loss 0.012894994579255581\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.013208806328475476 - Train Accuracy: 0.7604166666666666\n",
            "\t\t\tVal Loss: 0.02196678499846409 - Val Accuracy: 0.6043333333333333\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 2100, Loss 0.01091217715293169\n",
            "\t\tTrain step - Step 2130, Loss 0.014884404838085175\n",
            "\t\tTrain step - Step 2160, Loss 0.012647527270019054\n",
            "\t\tTrain step - Step 2190, Loss 0.014278084971010685\n",
            "\t\tTrain step - Step 2220, Loss 0.012212719768285751\n",
            "\t\tTrain step - Step 2250, Loss 0.013763215392827988\n",
            "\t\tTrain step - Step 2280, Loss 0.01274870801717043\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.013029372758631195 - Train Accuracy: 0.7622767857142857\n",
            "\t\t\tVal Loss: 0.01975345293370386 - Val Accuracy: 0.643\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 2310, Loss 0.012345720082521439\n",
            "\t\tTrain step - Step 2340, Loss 0.013404499739408493\n",
            "\t\tTrain step - Step 2370, Loss 0.011886431835591793\n",
            "\t\tTrain step - Step 2400, Loss 0.013192493468523026\n",
            "\t\tTrain step - Step 2430, Loss 0.011527729220688343\n",
            "\t\tTrain step - Step 2460, Loss 0.015085035003721714\n",
            "\t\tTrain step - Step 2490, Loss 0.013518068939447403\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.01306145473250321 - Train Accuracy: 0.7612351190476191\n",
            "\t\t\tVal Loss: 0.021378035928743582 - Val Accuracy: 0.614\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 2520, Loss 0.010223683901131153\n",
            "\t\tTrain step - Step 2550, Loss 0.012116369791328907\n",
            "\t\tTrain step - Step 2580, Loss 0.015614818781614304\n",
            "\t\tTrain step - Step 2610, Loss 0.010164308361709118\n",
            "\t\tTrain step - Step 2640, Loss 0.015185714699327946\n",
            "\t\tTrain step - Step 2670, Loss 0.010838782414793968\n",
            "\t\tTrain step - Step 2700, Loss 0.013846198096871376\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.012844200942310549 - Train Accuracy: 0.7676711309523809\n",
            "\t\t\tVal Loss: 0.0208520763553679 - Val Accuracy: 0.6253333333333333\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 2730, Loss 0.014059371314942837\n",
            "\t\tTrain step - Step 2760, Loss 0.012452979572117329\n",
            "\t\tTrain step - Step 2790, Loss 0.013645481318235397\n",
            "\t\tTrain step - Step 2820, Loss 0.011896196752786636\n",
            "\t\tTrain step - Step 2850, Loss 0.013817592523992062\n",
            "\t\tTrain step - Step 2880, Loss 0.011633269488811493\n",
            "\t\tTrain step - Step 2910, Loss 0.012266134843230247\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.012876583143536534 - Train Accuracy: 0.7674479166666667\n",
            "\t\t\tVal Loss: 0.022837026549192768 - Val Accuracy: 0.5916666666666667\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 2940, Loss 0.011321460828185081\n",
            "\t\tTrain step - Step 2970, Loss 0.01010955311357975\n",
            "\t\tTrain step - Step 3000, Loss 0.013039429672062397\n",
            "\t\tTrain step - Step 3030, Loss 0.011001665145158768\n",
            "\t\tTrain step - Step 3060, Loss 0.013521919026970863\n",
            "\t\tTrain step - Step 3090, Loss 0.0139482282102108\n",
            "\t\tTrain step - Step 3120, Loss 0.010474598966538906\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.01287954869635758 - Train Accuracy: 0.7661830357142857\n",
            "\t\t\tVal Loss: 0.020575594195785623 - Val Accuracy: 0.6276666666666667\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 3150, Loss 0.011993630789220333\n",
            "\t\tTrain step - Step 3180, Loss 0.011926507577300072\n",
            "\t\tTrain step - Step 3210, Loss 0.01295444369316101\n",
            "\t\tTrain step - Step 3240, Loss 0.01110913511365652\n",
            "\t\tTrain step - Step 3270, Loss 0.014880278147757053\n",
            "\t\tTrain step - Step 3300, Loss 0.013520285487174988\n",
            "\t\tTrain step - Step 3330, Loss 0.014037339016795158\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.012669017055027541 - Train Accuracy: 0.7697544642857143\n",
            "\t\t\tVal Loss: 0.02179586421698332 - Val Accuracy: 0.608\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 3360, Loss 0.013033046387135983\n",
            "\t\tTrain step - Step 3390, Loss 0.011674946174025536\n",
            "\t\tTrain step - Step 3420, Loss 0.01275278814136982\n",
            "\t\tTrain step - Step 3450, Loss 0.012182707898318768\n",
            "\t\tTrain step - Step 3480, Loss 0.013016700744628906\n",
            "\t\tTrain step - Step 3510, Loss 0.011862528510391712\n",
            "\t\tTrain step - Step 3540, Loss 0.011778363958001137\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.01278818328643129 - Train Accuracy: 0.7686383928571429\n",
            "\t\t\tVal Loss: 0.021464948503610987 - Val Accuracy: 0.6166666666666667\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 3570, Loss 0.015076357871294022\n",
            "\t\tTrain step - Step 3600, Loss 0.010933020152151585\n",
            "\t\tTrain step - Step 3630, Loss 0.011938066221773624\n",
            "\t\tTrain step - Step 3660, Loss 0.012848067097365856\n",
            "\t\tTrain step - Step 3690, Loss 0.016798727214336395\n",
            "\t\tTrain step - Step 3720, Loss 0.010622805915772915\n",
            "\t\tTrain step - Step 3750, Loss 0.015343187376856804\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.012650282343938238 - Train Accuracy: 0.7722098214285714\n",
            "\t\t\tVal Loss: 0.02296771469991654 - Val Accuracy: 0.594\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 3780, Loss 0.012239472940564156\n",
            "\t\tTrain step - Step 3810, Loss 0.012144222855567932\n",
            "\t\tTrain step - Step 3840, Loss 0.011773915030062199\n",
            "\t\tTrain step - Step 3870, Loss 0.014029694721102715\n",
            "\t\tTrain step - Step 3900, Loss 0.011363912373781204\n",
            "\t\tTrain step - Step 3930, Loss 0.012647352181375027\n",
            "\t\tTrain step - Step 3960, Loss 0.010994289070367813\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.012600769590409028 - Train Accuracy: 0.7701636904761905\n",
            "\t\t\tVal Loss: 0.020574746440009523 - Val Accuracy: 0.6233333333333333\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 3990, Loss 0.011168822646141052\n",
            "\t\tTrain step - Step 4020, Loss 0.012739586643874645\n",
            "\t\tTrain step - Step 4050, Loss 0.011333334259688854\n",
            "\t\tTrain step - Step 4080, Loss 0.010325037874281406\n",
            "\t\tTrain step - Step 4110, Loss 0.010752730071544647\n",
            "\t\tTrain step - Step 4140, Loss 0.012194161303341389\n",
            "\t\tTrain step - Step 4170, Loss 0.011710064485669136\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.012587839444833143 - Train Accuracy: 0.77265625\n",
            "\t\t\tVal Loss: 0.020896240137517452 - Val Accuracy: 0.617\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 4200, Loss 0.010559377260506153\n",
            "\t\tTrain step - Step 4230, Loss 0.010956691578030586\n",
            "\t\tTrain step - Step 4260, Loss 0.01406999584287405\n",
            "\t\tTrain step - Step 4290, Loss 0.013141538016498089\n",
            "\t\tTrain step - Step 4320, Loss 0.010123112238943577\n",
            "\t\tTrain step - Step 4350, Loss 0.012641496025025845\n",
            "\t\tTrain step - Step 4380, Loss 0.011066330596804619\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.01246840094349214 - Train Accuracy: 0.774516369047619\n",
            "\t\t\tVal Loss: 0.02221141945725928 - Val Accuracy: 0.601\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 4410, Loss 0.012972111813724041\n",
            "\t\tTrain step - Step 4440, Loss 0.00893438421189785\n",
            "\t\tTrain step - Step 4470, Loss 0.01309018675237894\n",
            "\t\tTrain step - Step 4500, Loss 0.010200301185250282\n",
            "\t\tTrain step - Step 4530, Loss 0.014218506403267384\n",
            "\t\tTrain step - Step 4560, Loss 0.014744657091796398\n",
            "\t\tTrain step - Step 4590, Loss 0.015262572094798088\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.012567480813179698 - Train Accuracy: 0.7730282738095238\n",
            "\t\t\tVal Loss: 0.020880837847168248 - Val Accuracy: 0.6243333333333333\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 4620, Loss 0.011424275115132332\n",
            "\t\tTrain step - Step 4650, Loss 0.01185084879398346\n",
            "\t\tTrain step - Step 4680, Loss 0.015178758651018143\n",
            "\t\tTrain step - Step 4710, Loss 0.01049239095300436\n",
            "\t\tTrain step - Step 4740, Loss 0.012338703498244286\n",
            "\t\tTrain step - Step 4770, Loss 0.011866590939462185\n",
            "\t\tTrain step - Step 4800, Loss 0.014119983650743961\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.012467783418971867 - Train Accuracy: 0.772061011904762\n",
            "\t\t\tVal Loss: 0.02409120121349891 - Val Accuracy: 0.569\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 4830, Loss 0.011565372347831726\n",
            "\t\tTrain step - Step 4860, Loss 0.012019283138215542\n",
            "\t\tTrain step - Step 4890, Loss 0.01142504159361124\n",
            "\t\tTrain step - Step 4920, Loss 0.015433592721819878\n",
            "\t\tTrain step - Step 4950, Loss 0.011716561391949654\n",
            "\t\tTrain step - Step 4980, Loss 0.013798978179693222\n",
            "\t\tTrain step - Step 5010, Loss 0.012985698878765106\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.012392760431837468 - Train Accuracy: 0.7742559523809524\n",
            "\t\t\tVal Loss: 0.02726644036980967 - Val Accuracy: 0.5443333333333333\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 5040, Loss 0.010107748210430145\n",
            "\t\tTrain step - Step 5070, Loss 0.013907898217439651\n",
            "\t\tTrain step - Step 5100, Loss 0.009774958714842796\n",
            "\t\tTrain step - Step 5130, Loss 0.010153703391551971\n",
            "\t\tTrain step - Step 5160, Loss 0.01018562726676464\n",
            "\t\tTrain step - Step 5190, Loss 0.015673289075493813\n",
            "\t\tTrain step - Step 5220, Loss 0.012546905316412449\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.012502596451945248 - Train Accuracy: 0.7723958333333333\n",
            "\t\t\tVal Loss: 0.019610807687665027 - Val Accuracy: 0.6523333333333333\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 5250, Loss 0.010122018866240978\n",
            "\t\tTrain step - Step 5280, Loss 0.012140654027462006\n",
            "\t\tTrain step - Step 5310, Loss 0.011053993366658688\n",
            "\t\tTrain step - Step 5340, Loss 0.015303353779017925\n",
            "\t\tTrain step - Step 5370, Loss 0.011635961011052132\n",
            "\t\tTrain step - Step 5400, Loss 0.014090786688029766\n",
            "\t\tTrain step - Step 5430, Loss 0.012765290215611458\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.012327803915277833 - Train Accuracy: 0.7765997023809523\n",
            "\t\t\tVal Loss: 0.02163902293735494 - Val Accuracy: 0.6216666666666667\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 5460, Loss 0.015817856416106224\n",
            "\t\tTrain step - Step 5490, Loss 0.013087032362818718\n",
            "\t\tTrain step - Step 5520, Loss 0.014138019643723965\n",
            "\t\tTrain step - Step 5550, Loss 0.013215422630310059\n",
            "\t\tTrain step - Step 5580, Loss 0.011211736127734184\n",
            "\t\tTrain step - Step 5610, Loss 0.012214559130370617\n",
            "\t\tTrain step - Step 5640, Loss 0.014649667777121067\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.012149210824143318 - Train Accuracy: 0.7818824404761905\n",
            "\t\t\tVal Loss: 0.021038545994088054 - Val Accuracy: 0.6123333333333333\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 5670, Loss 0.011487376876175404\n",
            "\t\tTrain step - Step 5700, Loss 0.010912643745541573\n",
            "\t\tTrain step - Step 5730, Loss 0.00981167796999216\n",
            "\t\tTrain step - Step 5760, Loss 0.01442746352404356\n",
            "\t\tTrain step - Step 5790, Loss 0.011819597333669662\n",
            "\t\tTrain step - Step 5820, Loss 0.01707530952990055\n",
            "\t\tTrain step - Step 5850, Loss 0.012465102598071098\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.012422129840013526 - Train Accuracy: 0.7746651785714286\n",
            "\t\t\tVal Loss: 0.020574591976280015 - Val Accuracy: 0.6326666666666667\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 5880, Loss 0.010746861808001995\n",
            "\t\tTrain step - Step 5910, Loss 0.01081663928925991\n",
            "\t\tTrain step - Step 5940, Loss 0.011348268948495388\n",
            "\t\tTrain step - Step 5970, Loss 0.013036159798502922\n",
            "\t\tTrain step - Step 6000, Loss 0.011924072168767452\n",
            "\t\tTrain step - Step 6030, Loss 0.012673655524849892\n",
            "\t\tTrain step - Step 6060, Loss 0.014975097961723804\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.012279457301788387 - Train Accuracy: 0.7780133928571429\n",
            "\t\t\tVal Loss: 0.02103516785427928 - Val Accuracy: 0.6163333333333333\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 6090, Loss 0.01213782373815775\n",
            "\t\tTrain step - Step 6120, Loss 0.010678349062800407\n",
            "\t\tTrain step - Step 6150, Loss 0.014709167182445526\n",
            "\t\tTrain step - Step 6180, Loss 0.01326584629714489\n",
            "\t\tTrain step - Step 6210, Loss 0.01448066160082817\n",
            "\t\tTrain step - Step 6240, Loss 0.011319233104586601\n",
            "\t\tTrain step - Step 6270, Loss 0.011166902258992195\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.012131696469372228 - Train Accuracy: 0.7797619047619048\n",
            "\t\t\tVal Loss: 0.020050954830367118 - Val Accuracy: 0.644\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 6300, Loss 0.012503511272370815\n",
            "\t\tTrain step - Step 6330, Loss 0.011232849210500717\n",
            "\t\tTrain step - Step 6360, Loss 0.012693356722593307\n",
            "\t\tTrain step - Step 6390, Loss 0.013322695158421993\n",
            "\t\tTrain step - Step 6420, Loss 0.010660278610885143\n",
            "\t\tTrain step - Step 6450, Loss 0.010372033342719078\n",
            "\t\tTrain step - Step 6480, Loss 0.01392682921141386\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.012025881988839025 - Train Accuracy: 0.78515625\n",
            "\t\t\tVal Loss: 0.018983221418845158 - Val Accuracy: 0.653\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 6510, Loss 0.01003606989979744\n",
            "\t\tTrain step - Step 6540, Loss 0.010061940178275108\n",
            "\t\tTrain step - Step 6570, Loss 0.00955902598798275\n",
            "\t\tTrain step - Step 6600, Loss 0.012522348202764988\n",
            "\t\tTrain step - Step 6630, Loss 0.011761901900172234\n",
            "\t\tTrain step - Step 6660, Loss 0.012495948933064938\n",
            "\t\tTrain step - Step 6690, Loss 0.014516068622469902\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.012077197299471923 - Train Accuracy: 0.7806547619047619\n",
            "\t\t\tVal Loss: 0.021120347664691508 - Val Accuracy: 0.6233333333333333\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 6720, Loss 0.01162652112543583\n",
            "\t\tTrain step - Step 6750, Loss 0.011706201359629631\n",
            "\t\tTrain step - Step 6780, Loss 0.01174923125654459\n",
            "\t\tTrain step - Step 6810, Loss 0.014636318199336529\n",
            "\t\tTrain step - Step 6840, Loss 0.013607659377157688\n",
            "\t\tTrain step - Step 6870, Loss 0.012748198583722115\n",
            "\t\tTrain step - Step 6900, Loss 0.013020938262343407\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.012160919473639556 - Train Accuracy: 0.7811383928571428\n",
            "\t\t\tVal Loss: 0.021365141108011205 - Val Accuracy: 0.607\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 6930, Loss 0.010722195729613304\n",
            "\t\tTrain step - Step 6960, Loss 0.013350309804081917\n",
            "\t\tTrain step - Step 6990, Loss 0.010988479480147362\n",
            "\t\tTrain step - Step 7020, Loss 0.010605260729789734\n",
            "\t\tTrain step - Step 7050, Loss 0.011281176470220089\n",
            "\t\tTrain step - Step 7080, Loss 0.013499715365469456\n",
            "\t\tTrain step - Step 7110, Loss 0.012047486379742622\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.011901972172338338 - Train Accuracy: 0.7880208333333333\n",
            "\t\t\tVal Loss: 0.020283377341305215 - Val Accuracy: 0.6316666666666667\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 7140, Loss 0.014187400229275227\n",
            "\t\tTrain step - Step 7170, Loss 0.011080116964876652\n",
            "\t\tTrain step - Step 7200, Loss 0.012480787932872772\n",
            "\t\tTrain step - Step 7230, Loss 0.011790173128247261\n",
            "\t\tTrain step - Step 7260, Loss 0.014829861000180244\n",
            "\t\tTrain step - Step 7290, Loss 0.014722432941198349\n",
            "\t\tTrain step - Step 7320, Loss 0.011313796043395996\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.012098606684733004 - Train Accuracy: 0.7824032738095238\n",
            "\t\t\tVal Loss: 0.02239846073401471 - Val Accuracy: 0.607\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 7350, Loss 0.010331851430237293\n",
            "\t\tTrain step - Step 7380, Loss 0.01258392259478569\n",
            "\t\tTrain step - Step 7410, Loss 0.01091501209884882\n",
            "\t\tTrain step - Step 7440, Loss 0.011571945622563362\n",
            "\t\tTrain step - Step 7470, Loss 0.011697244830429554\n",
            "\t\tTrain step - Step 7500, Loss 0.011644315905869007\n",
            "\t\tTrain step - Step 7530, Loss 0.013737074099481106\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.011894574912176246 - Train Accuracy: 0.78515625\n",
            "\t\t\tVal Loss: 0.024083226608733337 - Val Accuracy: 0.587\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 7560, Loss 0.011607937514781952\n",
            "\t\tTrain step - Step 7590, Loss 0.01125725731253624\n",
            "\t\tTrain step - Step 7620, Loss 0.00820718053728342\n",
            "\t\tTrain step - Step 7650, Loss 0.011108717881143093\n",
            "\t\tTrain step - Step 7680, Loss 0.012782152742147446\n",
            "\t\tTrain step - Step 7710, Loss 0.01189888920634985\n",
            "\t\tTrain step - Step 7740, Loss 0.01226356253027916\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.012071364022613992 - Train Accuracy: 0.7827380952380952\n",
            "\t\t\tVal Loss: 0.023933855273450415 - Val Accuracy: 0.584\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 7770, Loss 0.011888552457094193\n",
            "\t\tTrain step - Step 7800, Loss 0.011365048587322235\n",
            "\t\tTrain step - Step 7830, Loss 0.012229971587657928\n",
            "\t\tTrain step - Step 7860, Loss 0.011461727321147919\n",
            "\t\tTrain step - Step 7890, Loss 0.009863539598882198\n",
            "\t\tTrain step - Step 7920, Loss 0.0132865309715271\n",
            "\t\tTrain step - Step 7950, Loss 0.014547106809914112\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.011955037606613976 - Train Accuracy: 0.7866815476190476\n",
            "\t\t\tVal Loss: 0.02086643238241474 - Val Accuracy: 0.6266666666666667\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 7980, Loss 0.011960185132920742\n",
            "\t\tTrain step - Step 8010, Loss 0.010228493250906467\n",
            "\t\tTrain step - Step 8040, Loss 0.008463299833238125\n",
            "\t\tTrain step - Step 8070, Loss 0.013047818094491959\n",
            "\t\tTrain step - Step 8100, Loss 0.009814255870878696\n",
            "\t\tTrain step - Step 8130, Loss 0.012053634971380234\n",
            "\t\tTrain step - Step 8160, Loss 0.012232929468154907\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.011779208352700585 - Train Accuracy: 0.78671875\n",
            "\t\t\tVal Loss: 0.02023580390959978 - Val Accuracy: 0.6296666666666667\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 8190, Loss 0.01097541581839323\n",
            "\t\tTrain step - Step 8220, Loss 0.01217865664511919\n",
            "\t\tTrain step - Step 8250, Loss 0.011400842107832432\n",
            "\t\tTrain step - Step 8280, Loss 0.012243255041539669\n",
            "\t\tTrain step - Step 8310, Loss 0.01291980966925621\n",
            "\t\tTrain step - Step 8340, Loss 0.009575202129781246\n",
            "\t\tTrain step - Step 8370, Loss 0.009864730760455132\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.011755710334650107 - Train Accuracy: 0.7889880952380952\n",
            "\t\t\tVal Loss: 0.02748929088314374 - Val Accuracy: 0.5406666666666666\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 8400, Loss 0.01062051672488451\n",
            "\t\tTrain step - Step 8430, Loss 0.010500509291887283\n",
            "\t\tTrain step - Step 8460, Loss 0.015504898503422737\n",
            "\t\tTrain step - Step 8490, Loss 0.012490563094615936\n",
            "\t\tTrain step - Step 8520, Loss 0.013588713482022285\n",
            "\t\tTrain step - Step 8550, Loss 0.012080345302820206\n",
            "\t\tTrain step - Step 8580, Loss 0.0125497467815876\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.011965936874704701 - Train Accuracy: 0.7847098214285714\n",
            "\t\t\tVal Loss: 0.021023570327088237 - Val Accuracy: 0.6206666666666667\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 8610, Loss 0.011191763915121555\n",
            "\t\tTrain step - Step 8640, Loss 0.012342394329607487\n",
            "\t\tTrain step - Step 8670, Loss 0.011119780130684376\n",
            "\t\tTrain step - Step 8700, Loss 0.011522163636982441\n",
            "\t\tTrain step - Step 8730, Loss 0.012865266762673855\n",
            "\t\tTrain step - Step 8760, Loss 0.010655820369720459\n",
            "\t\tTrain step - Step 8790, Loss 0.011102878488600254\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.011723053442048175 - Train Accuracy: 0.7907366071428571\n",
            "\t\t\tVal Loss: 0.022169766675991315 - Val Accuracy: 0.6143333333333333\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 8820, Loss 0.010163421742618084\n",
            "\t\tTrain step - Step 8850, Loss 0.013273441232740879\n",
            "\t\tTrain step - Step 8880, Loss 0.012204877100884914\n",
            "\t\tTrain step - Step 8910, Loss 0.013042064383625984\n",
            "\t\tTrain step - Step 8940, Loss 0.01302651409059763\n",
            "\t\tTrain step - Step 8970, Loss 0.012823081575334072\n",
            "\t\tTrain step - Step 9000, Loss 0.011243132874369621\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.011735934365008558 - Train Accuracy: 0.7931919642857143\n",
            "\t\t\tVal Loss: 0.021537981849784654 - Val Accuracy: 0.6206666666666667\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 9030, Loss 0.010791731998324394\n",
            "\t\tTrain step - Step 9060, Loss 0.01163304504007101\n",
            "\t\tTrain step - Step 9090, Loss 0.011800305917859077\n",
            "\t\tTrain step - Step 9120, Loss 0.012233366258442402\n",
            "\t\tTrain step - Step 9150, Loss 0.012820896692574024\n",
            "\t\tTrain step - Step 9180, Loss 0.011689078994095325\n",
            "\t\tTrain step - Step 9210, Loss 0.01231842115521431\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.011604251147114804 - Train Accuracy: 0.7914806547619048\n",
            "\t\t\tVal Loss: 0.022432711693303038 - Val Accuracy: 0.6053333333333333\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 9240, Loss 0.01013103500008583\n",
            "\t\tTrain step - Step 9270, Loss 0.00970516912639141\n",
            "\t\tTrain step - Step 9300, Loss 0.014467756263911724\n",
            "\t\tTrain step - Step 9330, Loss 0.011955926194787025\n",
            "\t\tTrain step - Step 9360, Loss 0.011653370223939419\n",
            "\t\tTrain step - Step 9390, Loss 0.011859873309731483\n",
            "\t\tTrain step - Step 9420, Loss 0.014052827842533588\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.011987984384454432 - Train Accuracy: 0.7844122023809523\n",
            "\t\t\tVal Loss: 0.021370745613239706 - Val Accuracy: 0.6076666666666667\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 9450, Loss 0.013011831790208817\n",
            "\t\tTrain step - Step 9480, Loss 0.012016198597848415\n",
            "\t\tTrain step - Step 9510, Loss 0.012063253670930862\n",
            "\t\tTrain step - Step 9540, Loss 0.01126350462436676\n",
            "\t\tTrain step - Step 9570, Loss 0.011252987198531628\n",
            "\t\tTrain step - Step 9600, Loss 0.010273703373968601\n",
            "\t\tTrain step - Step 9630, Loss 0.011994919739663601\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.011683232213060061 - Train Accuracy: 0.7905877976190476\n",
            "\t\t\tVal Loss: 0.021083625499159098 - Val Accuracy: 0.621\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 9660, Loss 0.011409363709390163\n",
            "\t\tTrain step - Step 9690, Loss 0.009434638544917107\n",
            "\t\tTrain step - Step 9720, Loss 0.009989210404455662\n",
            "\t\tTrain step - Step 9750, Loss 0.009291478432714939\n",
            "\t\tTrain step - Step 9780, Loss 0.013632900081574917\n",
            "\t\tTrain step - Step 9810, Loss 0.01414430607110262\n",
            "\t\tTrain step - Step 9840, Loss 0.011543111875653267\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.011565435742072406 - Train Accuracy: 0.7914434523809524\n",
            "\t\t\tVal Loss: 0.0225922042154707 - Val Accuracy: 0.5983333333333334\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 9870, Loss 0.011795507743954659\n",
            "\t\tTrain step - Step 9900, Loss 0.0135538624599576\n",
            "\t\tTrain step - Step 9930, Loss 0.013334016315639019\n",
            "\t\tTrain step - Step 9960, Loss 0.00867810845375061\n",
            "\t\tTrain step - Step 9990, Loss 0.010704509913921356\n",
            "\t\tTrain step - Step 10020, Loss 0.011792216449975967\n",
            "\t\tTrain step - Step 10050, Loss 0.010590510442852974\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.01179895367295969 - Train Accuracy: 0.7880952380952381\n",
            "\t\t\tVal Loss: 0.020165983703918755 - Val Accuracy: 0.64\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 10080, Loss 0.011263282969594002\n",
            "\t\tTrain step - Step 10110, Loss 0.013129410333931446\n",
            "\t\tTrain step - Step 10140, Loss 0.009980292059481144\n",
            "\t\tTrain step - Step 10170, Loss 0.011241618543863297\n",
            "\t\tTrain step - Step 10200, Loss 0.011810577474534512\n",
            "\t\tTrain step - Step 10230, Loss 0.01237519457936287\n",
            "\t\tTrain step - Step 10260, Loss 0.011381427757441998\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.0114580938902994 - Train Accuracy: 0.7956473214285714\n",
            "\t\t\tVal Loss: 0.020860933233052492 - Val Accuracy: 0.626\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 10290, Loss 0.011250493116676807\n",
            "\t\tTrain step - Step 10320, Loss 0.008815672248601913\n",
            "\t\tTrain step - Step 10350, Loss 0.005805680062621832\n",
            "\t\tTrain step - Step 10380, Loss 0.00706814881414175\n",
            "\t\tTrain step - Step 10410, Loss 0.007585606537759304\n",
            "\t\tTrain step - Step 10440, Loss 0.007673983462154865\n",
            "\t\tTrain step - Step 10470, Loss 0.00790905486792326\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.007720456418714353 - Train Accuracy: 0.8727306547619048\n",
            "\t\t\tVal Loss: 0.014816370715076724 - Val Accuracy: 0.7313333333333333\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 10500, Loss 0.00541724544018507\n",
            "\t\tTrain step - Step 10530, Loss 0.008797401562333107\n",
            "\t\tTrain step - Step 10560, Loss 0.006016355473548174\n",
            "\t\tTrain step - Step 10590, Loss 0.005975004285573959\n",
            "\t\tTrain step - Step 10620, Loss 0.006511093117296696\n",
            "\t\tTrain step - Step 10650, Loss 0.004782387521117926\n",
            "\t\tTrain step - Step 10680, Loss 0.007785638328641653\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.006522783424173083 - Train Accuracy: 0.8954241071428571\n",
            "\t\t\tVal Loss: 0.014667691779322922 - Val Accuracy: 0.735\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 10710, Loss 0.004643181338906288\n",
            "\t\tTrain step - Step 10740, Loss 0.004686734173446894\n",
            "\t\tTrain step - Step 10770, Loss 0.0043539670296013355\n",
            "\t\tTrain step - Step 10800, Loss 0.005802718456834555\n",
            "\t\tTrain step - Step 10830, Loss 0.00580425001680851\n",
            "\t\tTrain step - Step 10860, Loss 0.006064047571271658\n",
            "\t\tTrain step - Step 10890, Loss 0.004169919528067112\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.005986245926691308 - Train Accuracy: 0.9055803571428571\n",
            "\t\t\tVal Loss: 0.014987837426209202 - Val Accuracy: 0.7346666666666667\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 10920, Loss 0.005089952610433102\n",
            "\t\tTrain step - Step 10950, Loss 0.005544533487409353\n",
            "\t\tTrain step - Step 10980, Loss 0.0048793707974255085\n",
            "\t\tTrain step - Step 11010, Loss 0.004885647911578417\n",
            "\t\tTrain step - Step 11040, Loss 0.005927069112658501\n",
            "\t\tTrain step - Step 11070, Loss 0.006073750555515289\n",
            "\t\tTrain step - Step 11100, Loss 0.005534632597118616\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.005671224930501055 - Train Accuracy: 0.9132068452380953\n",
            "\t\t\tVal Loss: 0.01526471497102951 - Val Accuracy: 0.7296666666666667\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 11130, Loss 0.004262656904757023\n",
            "\t\tTrain step - Step 11160, Loss 0.004710641223937273\n",
            "\t\tTrain step - Step 11190, Loss 0.004928197246044874\n",
            "\t\tTrain step - Step 11220, Loss 0.005531304981559515\n",
            "\t\tTrain step - Step 11250, Loss 0.0060511198826134205\n",
            "\t\tTrain step - Step 11280, Loss 0.005335502326488495\n",
            "\t\tTrain step - Step 11310, Loss 0.005579299759119749\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.005367881673876019 - Train Accuracy: 0.9172247023809523\n",
            "\t\t\tVal Loss: 0.015259823742477844 - Val Accuracy: 0.731\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 11340, Loss 0.0065794275142252445\n",
            "\t\tTrain step - Step 11370, Loss 0.004290209151804447\n",
            "\t\tTrain step - Step 11400, Loss 0.004533432889729738\n",
            "\t\tTrain step - Step 11430, Loss 0.005146576091647148\n",
            "\t\tTrain step - Step 11460, Loss 0.005965020973235369\n",
            "\t\tTrain step - Step 11490, Loss 0.004972132854163647\n",
            "\t\tTrain step - Step 11520, Loss 0.0041076852940022945\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.005283734618153955 - Train Accuracy: 0.918266369047619\n",
            "\t\t\tVal Loss: 0.01517839952915286 - Val Accuracy: 0.74\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 11550, Loss 0.00485053937882185\n",
            "\t\tTrain step - Step 11580, Loss 0.006009817123413086\n",
            "\t\tTrain step - Step 11610, Loss 0.006888622883707285\n",
            "\t\tTrain step - Step 11640, Loss 0.004412845708429813\n",
            "\t\tTrain step - Step 11670, Loss 0.0060628196224570274\n",
            "\t\tTrain step - Step 11700, Loss 0.004797132685780525\n",
            "\t\tTrain step - Step 11730, Loss 0.006026808638125658\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.005075382318214646 - Train Accuracy: 0.922953869047619\n",
            "\t\t\tVal Loss: 0.015599340355644623 - Val Accuracy: 0.7293333333333333\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 11760, Loss 0.00505600543692708\n",
            "\t\tTrain step - Step 11790, Loss 0.00402810936793685\n",
            "\t\tTrain step - Step 11820, Loss 0.004573352634906769\n",
            "\t\tTrain step - Step 11850, Loss 0.005698334891349077\n",
            "\t\tTrain step - Step 11880, Loss 0.004544510971754789\n",
            "\t\tTrain step - Step 11910, Loss 0.0052405488677322865\n",
            "\t\tTrain step - Step 11940, Loss 0.005694353487342596\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.004980658287448542 - Train Accuracy: 0.9238467261904761\n",
            "\t\t\tVal Loss: 0.015600080291430155 - Val Accuracy: 0.7263333333333334\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 11970, Loss 0.0035819499753415585\n",
            "\t\tTrain step - Step 12000, Loss 0.004352088086307049\n",
            "\t\tTrain step - Step 12030, Loss 0.005006253719329834\n",
            "\t\tTrain step - Step 12060, Loss 0.003474449971690774\n",
            "\t\tTrain step - Step 12090, Loss 0.004137125331908464\n",
            "\t\tTrain step - Step 12120, Loss 0.003357180394232273\n",
            "\t\tTrain step - Step 12150, Loss 0.004035722929984331\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.004765260173007846 - Train Accuracy: 0.9276413690476191\n",
            "\t\t\tVal Loss: 0.015999728619741898 - Val Accuracy: 0.7203333333333334\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 12180, Loss 0.0035907397978007793\n",
            "\t\tTrain step - Step 12210, Loss 0.003969334531575441\n",
            "\t\tTrain step - Step 12240, Loss 0.003990494646131992\n",
            "\t\tTrain step - Step 12270, Loss 0.0033114682883024216\n",
            "\t\tTrain step - Step 12300, Loss 0.00515565974637866\n",
            "\t\tTrain step - Step 12330, Loss 0.0042197369039058685\n",
            "\t\tTrain step - Step 12360, Loss 0.004469692707061768\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.00466279707228144 - Train Accuracy: 0.9303199404761905\n",
            "\t\t\tVal Loss: 0.016769461915828288 - Val Accuracy: 0.7153333333333334\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 12390, Loss 0.004008088260889053\n",
            "\t\tTrain step - Step 12420, Loss 0.0039287651889026165\n",
            "\t\tTrain step - Step 12450, Loss 0.004034803248941898\n",
            "\t\tTrain step - Step 12480, Loss 0.005561010912060738\n",
            "\t\tTrain step - Step 12510, Loss 0.003796772798523307\n",
            "\t\tTrain step - Step 12540, Loss 0.006098107434809208\n",
            "\t\tTrain step - Step 12570, Loss 0.00662706233561039\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.00460713692452936 - Train Accuracy: 0.9317336309523809\n",
            "\t\t\tVal Loss: 0.016407629067543894 - Val Accuracy: 0.7196666666666667\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 12600, Loss 0.004892978351563215\n",
            "\t\tTrain step - Step 12630, Loss 0.005350967403501272\n",
            "\t\tTrain step - Step 12660, Loss 0.005254956893622875\n",
            "\t\tTrain step - Step 12690, Loss 0.006487801671028137\n",
            "\t\tTrain step - Step 12720, Loss 0.004697374999523163\n",
            "\t\tTrain step - Step 12750, Loss 0.005415092688053846\n",
            "\t\tTrain step - Step 12780, Loss 0.004394312389194965\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.004518014511891774 - Train Accuracy: 0.9335193452380952\n",
            "\t\t\tVal Loss: 0.01657352689653635 - Val Accuracy: 0.7133333333333334\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 12810, Loss 0.003608420956879854\n",
            "\t\tTrain step - Step 12840, Loss 0.004521701950579882\n",
            "\t\tTrain step - Step 12870, Loss 0.003583983052521944\n",
            "\t\tTrain step - Step 12900, Loss 0.004845929332077503\n",
            "\t\tTrain step - Step 12930, Loss 0.006130159366875887\n",
            "\t\tTrain step - Step 12960, Loss 0.00632554292678833\n",
            "\t\tTrain step - Step 12990, Loss 0.006449882872402668\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.004438531577276686 - Train Accuracy: 0.9345982142857143\n",
            "\t\t\tVal Loss: 0.016169520056185622 - Val Accuracy: 0.7203333333333334\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 13020, Loss 0.0029136082157492638\n",
            "\t\tTrain step - Step 13050, Loss 0.0027618268504738808\n",
            "\t\tTrain step - Step 13080, Loss 0.004461109638214111\n",
            "\t\tTrain step - Step 13110, Loss 0.005044198594987392\n",
            "\t\tTrain step - Step 13140, Loss 0.00599351990967989\n",
            "\t\tTrain step - Step 13170, Loss 0.004058615770190954\n",
            "\t\tTrain step - Step 13200, Loss 0.00561471376568079\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.004370861929575248 - Train Accuracy: 0.9345238095238095\n",
            "\t\t\tVal Loss: 0.016621396644040942 - Val Accuracy: 0.7213333333333334\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 13230, Loss 0.003352015046402812\n",
            "\t\tTrain step - Step 13260, Loss 0.003692848840728402\n",
            "\t\tTrain step - Step 13290, Loss 0.004449393600225449\n",
            "\t\tTrain step - Step 13320, Loss 0.0030871951021254063\n",
            "\t\tTrain step - Step 13350, Loss 0.003224172629415989\n",
            "\t\tTrain step - Step 13380, Loss 0.002930970164015889\n",
            "\t\tTrain step - Step 13410, Loss 0.0058452109806239605\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.0036940930377958076 - Train Accuracy: 0.9495907738095238\n",
            "\t\t\tVal Loss: 0.015765160826655727 - Val Accuracy: 0.7316666666666667\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 13440, Loss 0.004166045226156712\n",
            "\t\tTrain step - Step 13470, Loss 0.0030208888929337263\n",
            "\t\tTrain step - Step 13500, Loss 0.004086208995431662\n",
            "\t\tTrain step - Step 13530, Loss 0.0034073537681251764\n",
            "\t\tTrain step - Step 13560, Loss 0.002453714609146118\n",
            "\t\tTrain step - Step 13590, Loss 0.003536338685080409\n",
            "\t\tTrain step - Step 13620, Loss 0.0028202813118696213\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.003303830318951181 - Train Accuracy: 0.9572172619047619\n",
            "\t\t\tVal Loss: 0.01578504147861774 - Val Accuracy: 0.7363333333333333\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 13650, Loss 0.003964063245803118\n",
            "\t\tTrain step - Step 13680, Loss 0.0024515395052731037\n",
            "\t\tTrain step - Step 13710, Loss 0.003733639605343342\n",
            "\t\tTrain step - Step 13740, Loss 0.003936680033802986\n",
            "\t\tTrain step - Step 13770, Loss 0.003348848782479763\n",
            "\t\tTrain step - Step 13800, Loss 0.002419455209746957\n",
            "\t\tTrain step - Step 13830, Loss 0.003961291629821062\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.003265892452604714 - Train Accuracy: 0.9562127976190476\n",
            "\t\t\tVal Loss: 0.0156359761992159 - Val Accuracy: 0.7336666666666667\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 13860, Loss 0.004846591968089342\n",
            "\t\tTrain step - Step 13890, Loss 0.0051546478644013405\n",
            "\t\tTrain step - Step 13920, Loss 0.002544925082474947\n",
            "\t\tTrain step - Step 13950, Loss 0.002968442626297474\n",
            "\t\tTrain step - Step 13980, Loss 0.003337593050673604\n",
            "\t\tTrain step - Step 14010, Loss 0.0032417390029877424\n",
            "\t\tTrain step - Step 14040, Loss 0.0026586081366986036\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.0031616129147421035 - Train Accuracy: 0.9603422619047619\n",
            "\t\t\tVal Loss: 0.015648933263340343 - Val Accuracy: 0.7393333333333333\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 14070, Loss 0.002682006685063243\n",
            "\t\tTrain step - Step 14100, Loss 0.00271882233209908\n",
            "\t\tTrain step - Step 14130, Loss 0.0026823291555047035\n",
            "\t\tTrain step - Step 14160, Loss 0.0038515168707817793\n",
            "\t\tTrain step - Step 14190, Loss 0.002629133639857173\n",
            "\t\tTrain step - Step 14220, Loss 0.002722683595493436\n",
            "\t\tTrain step - Step 14250, Loss 0.004047743044793606\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.0031891920553919462 - Train Accuracy: 0.9601934523809523\n",
            "\t\t\tVal Loss: 0.015640361739012103 - Val Accuracy: 0.737\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 14280, Loss 0.003662731498479843\n",
            "\t\tTrain step - Step 14310, Loss 0.002991610439494252\n",
            "\t\tTrain step - Step 14340, Loss 0.0036579540465027094\n",
            "\t\tTrain step - Step 14370, Loss 0.00391078507527709\n",
            "\t\tTrain step - Step 14400, Loss 0.0027050781063735485\n",
            "\t\tTrain step - Step 14430, Loss 0.0037588931154459715\n",
            "\t\tTrain step - Step 14460, Loss 0.003364570438861847\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.0030843478389128687 - Train Accuracy: 0.9606026785714286\n",
            "\t\t\tVal Loss: 0.01560531958239153 - Val Accuracy: 0.7316666666666667\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 14490, Loss 0.0036271640565246344\n",
            "\t\tTrain step - Step 14520, Loss 0.0020609619095921516\n",
            "\t\tTrain step - Step 14550, Loss 0.002802556613460183\n",
            "\t\tTrain step - Step 14580, Loss 0.0032310232054442167\n",
            "\t\tTrain step - Step 14610, Loss 0.002717559225857258\n",
            "\t\tTrain step - Step 14640, Loss 0.0034483610652387142\n",
            "\t\tTrain step - Step 14670, Loss 0.00399772496894002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/47 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.0029870132843609013 - Train Accuracy: 0.9635416666666666\n",
            "\t\t\tVal Loss: 0.0159958153963089 - Val Accuracy: 0.735\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 47/47 [00:01<00:00, 27.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 6:\n",
            "\t\tTrain Mean Accuracy: 0.820268920068027\n",
            "\t\tVal Mean Accuracy: 0.6428333333333335\n",
            "\t\tTest Accuracy: 0.74\n",
            "\n",
            "STARTING JOINT TRAINING STAGE 7...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.017291665077209473\n",
            "\t\tTrain step - Step 60, Loss 0.01716243475675583\n",
            "\t\tTrain step - Step 90, Loss 0.016539881005883217\n",
            "\t\tTrain step - Step 120, Loss 0.018510621041059494\n",
            "\t\tTrain step - Step 150, Loss 0.015391387976706028\n",
            "\t\tTrain step - Step 180, Loss 0.017500298097729683\n",
            "\t\tTrain step - Step 210, Loss 0.018421465530991554\n",
            "\t\tTrain step - Step 240, Loss 0.015621866099536419\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.016581859091311935 - Train Accuracy: 0.7010607215447154\n",
            "\t\t\tVal Loss: 0.026725358130144223 - Val Accuracy: 0.52\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 270, Loss 0.01568686030805111\n",
            "\t\tTrain step - Step 300, Loss 0.013118143193423748\n",
            "\t\tTrain step - Step 330, Loss 0.01385608408600092\n",
            "\t\tTrain step - Step 360, Loss 0.018930558115243912\n",
            "\t\tTrain step - Step 390, Loss 0.016034580767154694\n",
            "\t\tTrain step - Step 420, Loss 0.015257271938025951\n",
            "\t\tTrain step - Step 450, Loss 0.017849523574113846\n",
            "\t\tTrain step - Step 480, Loss 0.014619782567024231\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.015348317658119812 - Train Accuracy: 0.7129382621951219\n",
            "\t\t\tVal Loss: 0.024833407302919244 - Val Accuracy: 0.5454285714285714\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.01342028845101595\n",
            "\t\tTrain step - Step 540, Loss 0.013480599969625473\n",
            "\t\tTrain step - Step 570, Loss 0.014855093322694302\n",
            "\t\tTrain step - Step 600, Loss 0.010963818989694118\n",
            "\t\tTrain step - Step 630, Loss 0.013182492926716805\n",
            "\t\tTrain step - Step 660, Loss 0.015408491715788841\n",
            "\t\tTrain step - Step 690, Loss 0.012588496319949627\n",
            "\t\tTrain step - Step 720, Loss 0.014168846420943737\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.014818329602570795 - Train Accuracy: 0.7273882113821138\n",
            "\t\t\tVal Loss: 0.023154696649206535 - Val Accuracy: 0.574\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.011608149856328964\n",
            "\t\tTrain step - Step 780, Loss 0.014999310486018658\n",
            "\t\tTrain step - Step 810, Loss 0.015265330672264099\n",
            "\t\tTrain step - Step 840, Loss 0.015411939471960068\n",
            "\t\tTrain step - Step 870, Loss 0.013045715168118477\n",
            "\t\tTrain step - Step 900, Loss 0.013842402026057243\n",
            "\t\tTrain step - Step 930, Loss 0.01573304831981659\n",
            "\t\tTrain step - Step 960, Loss 0.012706642039120197\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.014768248605655461 - Train Accuracy: 0.724244156504065\n",
            "\t\t\tVal Loss: 0.02399619103276304 - Val Accuracy: 0.5645714285714286\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.014378545805811882\n",
            "\t\tTrain step - Step 1020, Loss 0.014704015105962753\n",
            "\t\tTrain step - Step 1050, Loss 0.013654369860887527\n",
            "\t\tTrain step - Step 1080, Loss 0.013753475621342659\n",
            "\t\tTrain step - Step 1110, Loss 0.016825318336486816\n",
            "\t\tTrain step - Step 1140, Loss 0.012548064813017845\n",
            "\t\tTrain step - Step 1170, Loss 0.011488382704555988\n",
            "\t\tTrain step - Step 1200, Loss 0.01474916934967041\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.014765921215398041 - Train Accuracy: 0.7263084349593496\n",
            "\t\t\tVal Loss: 0.022671411678727185 - Val Accuracy: 0.5911428571428572\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.012258317321538925\n",
            "\t\tTrain step - Step 1260, Loss 0.014689130708575249\n",
            "\t\tTrain step - Step 1290, Loss 0.012857291847467422\n",
            "\t\tTrain step - Step 1320, Loss 0.014602807350456715\n",
            "\t\tTrain step - Step 1350, Loss 0.016020392999053\n",
            "\t\tTrain step - Step 1380, Loss 0.013765748590230942\n",
            "\t\tTrain step - Step 1410, Loss 0.014875464141368866\n",
            "\t\tTrain step - Step 1440, Loss 0.015637163072824478\n",
            "\t\tTrain step - Step 1470, Loss 0.012735437601804733\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.014594107404411808 - Train Accuracy: 0.7253239329268293\n",
            "\t\t\tVal Loss: 0.023772574162908962 - Val Accuracy: 0.5614285714285714\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 1500, Loss 0.015027408488094807\n",
            "\t\tTrain step - Step 1530, Loss 0.01333104819059372\n",
            "\t\tTrain step - Step 1560, Loss 0.015700560063123703\n",
            "\t\tTrain step - Step 1590, Loss 0.013530739583075047\n",
            "\t\tTrain step - Step 1620, Loss 0.014695288613438606\n",
            "\t\tTrain step - Step 1650, Loss 0.014219390228390694\n",
            "\t\tTrain step - Step 1680, Loss 0.01139479037374258\n",
            "\t\tTrain step - Step 1710, Loss 0.014932570047676563\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.014485947057089912 - Train Accuracy: 0.7310403963414634\n",
            "\t\t\tVal Loss: 0.023608500437278832 - Val Accuracy: 0.5722857142857143\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 1740, Loss 0.013286187313497066\n",
            "\t\tTrain step - Step 1770, Loss 0.016414867714047432\n",
            "\t\tTrain step - Step 1800, Loss 0.012817022390663624\n",
            "\t\tTrain step - Step 1830, Loss 0.012834560126066208\n",
            "\t\tTrain step - Step 1860, Loss 0.015059527941048145\n",
            "\t\tTrain step - Step 1890, Loss 0.011705287732183933\n",
            "\t\tTrain step - Step 1920, Loss 0.013414213433861732\n",
            "\t\tTrain step - Step 1950, Loss 0.013618840835988522\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.014604672732785708 - Train Accuracy: 0.7292936991869918\n",
            "\t\t\tVal Loss: 0.023323669763548032 - Val Accuracy: 0.5748571428571428\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 1980, Loss 0.013666643761098385\n",
            "\t\tTrain step - Step 2010, Loss 0.014386158436536789\n",
            "\t\tTrain step - Step 2040, Loss 0.01409563422203064\n",
            "\t\tTrain step - Step 2070, Loss 0.01596708782017231\n",
            "\t\tTrain step - Step 2100, Loss 0.015283184126019478\n",
            "\t\tTrain step - Step 2130, Loss 0.0135740265250206\n",
            "\t\tTrain step - Step 2160, Loss 0.014826714992523193\n",
            "\t\tTrain step - Step 2190, Loss 0.01394200325012207\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.014539850523649919 - Train Accuracy: 0.7308498475609756\n",
            "\t\t\tVal Loss: 0.024832102170746242 - Val Accuracy: 0.556\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 2220, Loss 0.016746435314416885\n",
            "\t\tTrain step - Step 2250, Loss 0.009257237426936626\n",
            "\t\tTrain step - Step 2280, Loss 0.013823549263179302\n",
            "\t\tTrain step - Step 2310, Loss 0.013241834007203579\n",
            "\t\tTrain step - Step 2340, Loss 0.014432620257139206\n",
            "\t\tTrain step - Step 2370, Loss 0.0164963211864233\n",
            "\t\tTrain step - Step 2400, Loss 0.014819708652794361\n",
            "\t\tTrain step - Step 2430, Loss 0.015353672206401825\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.014432994402733034 - Train Accuracy: 0.7316120426829268\n",
            "\t\t\tVal Loss: 0.023582542980355874 - Val Accuracy: 0.5705714285714286\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 2460, Loss 0.01265875343233347\n",
            "\t\tTrain step - Step 2490, Loss 0.015822244808077812\n",
            "\t\tTrain step - Step 2520, Loss 0.013649695552885532\n",
            "\t\tTrain step - Step 2550, Loss 0.01477554440498352\n",
            "\t\tTrain step - Step 2580, Loss 0.015367853455245495\n",
            "\t\tTrain step - Step 2610, Loss 0.01720653474330902\n",
            "\t\tTrain step - Step 2640, Loss 0.012792682275176048\n",
            "\t\tTrain step - Step 2670, Loss 0.012186829932034016\n",
            "\t\tTrain step - Step 2700, Loss 0.014661255292594433\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.014144820948623545 - Train Accuracy: 0.7390752032520326\n",
            "\t\t\tVal Loss: 0.024952199110495194 - Val Accuracy: 0.5477142857142857\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 2730, Loss 0.012338757514953613\n",
            "\t\tTrain step - Step 2760, Loss 0.013673567213118076\n",
            "\t\tTrain step - Step 2790, Loss 0.01400044746696949\n",
            "\t\tTrain step - Step 2820, Loss 0.015734752640128136\n",
            "\t\tTrain step - Step 2850, Loss 0.013696253299713135\n",
            "\t\tTrain step - Step 2880, Loss 0.015923405066132545\n",
            "\t\tTrain step - Step 2910, Loss 0.01508439239114523\n",
            "\t\tTrain step - Step 2940, Loss 0.013591048307716846\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.014204531078931035 - Train Accuracy: 0.7370744410569106\n",
            "\t\t\tVal Loss: 0.02214341294685645 - Val Accuracy: 0.5937142857142857\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 2970, Loss 0.012276820838451385\n",
            "\t\tTrain step - Step 3000, Loss 0.014358168467879295\n",
            "\t\tTrain step - Step 3030, Loss 0.012063729576766491\n",
            "\t\tTrain step - Step 3060, Loss 0.014681290835142136\n",
            "\t\tTrain step - Step 3090, Loss 0.014774312265217304\n",
            "\t\tTrain step - Step 3120, Loss 0.013818668201565742\n",
            "\t\tTrain step - Step 3150, Loss 0.014457427896559238\n",
            "\t\tTrain step - Step 3180, Loss 0.01685039885342121\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.01440468806833998 - Train Accuracy: 0.7328188516260162\n",
            "\t\t\tVal Loss: 0.022535687794775834 - Val Accuracy: 0.5805714285714285\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 3210, Loss 0.013578951358795166\n",
            "\t\tTrain step - Step 3240, Loss 0.013103775680065155\n",
            "\t\tTrain step - Step 3270, Loss 0.013690310530364513\n",
            "\t\tTrain step - Step 3300, Loss 0.014604778960347176\n",
            "\t\tTrain step - Step 3330, Loss 0.013260570354759693\n",
            "\t\tTrain step - Step 3360, Loss 0.01438814401626587\n",
            "\t\tTrain step - Step 3390, Loss 0.01352515909820795\n",
            "\t\tTrain step - Step 3420, Loss 0.01576421782374382\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.01424664860909305 - Train Accuracy: 0.7344702743902439\n",
            "\t\t\tVal Loss: 0.024418211874685118 - Val Accuracy: 0.5728571428571428\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 3450, Loss 0.013412601314485073\n",
            "\t\tTrain step - Step 3480, Loss 0.012233812361955643\n",
            "\t\tTrain step - Step 3510, Loss 0.011499790474772453\n",
            "\t\tTrain step - Step 3540, Loss 0.012631054036319256\n",
            "\t\tTrain step - Step 3570, Loss 0.013286133296787739\n",
            "\t\tTrain step - Step 3600, Loss 0.011966945603489876\n",
            "\t\tTrain step - Step 3630, Loss 0.011952267959713936\n",
            "\t\tTrain step - Step 3660, Loss 0.013957939110696316\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.014224278483146089 - Train Accuracy: 0.7376143292682927\n",
            "\t\t\tVal Loss: 0.023048708414924995 - Val Accuracy: 0.584\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 3690, Loss 0.01394282653927803\n",
            "\t\tTrain step - Step 3720, Loss 0.013219275511801243\n",
            "\t\tTrain step - Step 3750, Loss 0.013105458579957485\n",
            "\t\tTrain step - Step 3780, Loss 0.014689424075186253\n",
            "\t\tTrain step - Step 3810, Loss 0.01539134606719017\n",
            "\t\tTrain step - Step 3840, Loss 0.013494567945599556\n",
            "\t\tTrain step - Step 3870, Loss 0.013112513348460197\n",
            "\t\tTrain step - Step 3900, Loss 0.015719475224614143\n",
            "\t\tTrain step - Step 3930, Loss 0.0139352697879076\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.014202834330347738 - Train Accuracy: 0.737963668699187\n",
            "\t\t\tVal Loss: 0.023713693421866213 - Val Accuracy: 0.5731428571428572\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 3960, Loss 0.01355223823338747\n",
            "\t\tTrain step - Step 3990, Loss 0.014397477731108665\n",
            "\t\tTrain step - Step 4020, Loss 0.013168186880648136\n",
            "\t\tTrain step - Step 4050, Loss 0.013548668473958969\n",
            "\t\tTrain step - Step 4080, Loss 0.012032625265419483\n",
            "\t\tTrain step - Step 4110, Loss 0.013699274510145187\n",
            "\t\tTrain step - Step 4140, Loss 0.014290105551481247\n",
            "\t\tTrain step - Step 4170, Loss 0.014468402601778507\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.014111508354090335 - Train Accuracy: 0.7382494918699187\n",
            "\t\t\tVal Loss: 0.02225188578345946 - Val Accuracy: 0.5937142857142857\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 4200, Loss 0.014705490320920944\n",
            "\t\tTrain step - Step 4230, Loss 0.012339078821241856\n",
            "\t\tTrain step - Step 4260, Loss 0.013404256664216518\n",
            "\t\tTrain step - Step 4290, Loss 0.012382373213768005\n",
            "\t\tTrain step - Step 4320, Loss 0.01432825904339552\n",
            "\t\tTrain step - Step 4350, Loss 0.015987450256943703\n",
            "\t\tTrain step - Step 4380, Loss 0.012939591892063618\n",
            "\t\tTrain step - Step 4410, Loss 0.014257037080824375\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.014001061878644111 - Train Accuracy: 0.743775406504065\n",
            "\t\t\tVal Loss: 0.0229265236827944 - Val Accuracy: 0.574\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 4440, Loss 0.011612789705395699\n",
            "\t\tTrain step - Step 4470, Loss 0.014638792723417282\n",
            "\t\tTrain step - Step 4500, Loss 0.011918208561837673\n",
            "\t\tTrain step - Step 4530, Loss 0.01445626188069582\n",
            "\t\tTrain step - Step 4560, Loss 0.010813606902956963\n",
            "\t\tTrain step - Step 4590, Loss 0.011649489402770996\n",
            "\t\tTrain step - Step 4620, Loss 0.013440286740660667\n",
            "\t\tTrain step - Step 4650, Loss 0.015676327049732208\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.013862986886131813 - Train Accuracy: 0.7453950711382114\n",
            "\t\t\tVal Loss: 0.02181959438270756 - Val Accuracy: 0.6048571428571429\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 4680, Loss 0.012535381130874157\n",
            "\t\tTrain step - Step 4710, Loss 0.014292308129370213\n",
            "\t\tTrain step - Step 4740, Loss 0.013920985162258148\n",
            "\t\tTrain step - Step 4770, Loss 0.01274443231523037\n",
            "\t\tTrain step - Step 4800, Loss 0.016007093712687492\n",
            "\t\tTrain step - Step 4830, Loss 0.01438179798424244\n",
            "\t\tTrain step - Step 4860, Loss 0.014941476285457611\n",
            "\t\tTrain step - Step 4890, Loss 0.015999725088477135\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.01404051193816027 - Train Accuracy: 0.7380907012195121\n",
            "\t\t\tVal Loss: 0.02245343230398638 - Val Accuracy: 0.5922857142857143\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 4920, Loss 0.01227743923664093\n",
            "\t\tTrain step - Step 4950, Loss 0.010470573790371418\n",
            "\t\tTrain step - Step 4980, Loss 0.014009088277816772\n",
            "\t\tTrain step - Step 5010, Loss 0.014534165151417255\n",
            "\t\tTrain step - Step 5040, Loss 0.013576585799455643\n",
            "\t\tTrain step - Step 5070, Loss 0.01564674638211727\n",
            "\t\tTrain step - Step 5100, Loss 0.013317168690264225\n",
            "\t\tTrain step - Step 5130, Loss 0.013797402381896973\n",
            "\t\tTrain step - Step 5160, Loss 0.014454872347414494\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.013994050374996613 - Train Accuracy: 0.7452362804878049\n",
            "\t\t\tVal Loss: 0.02202212923605527 - Val Accuracy: 0.5954285714285714\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 5190, Loss 0.014298192225396633\n",
            "\t\tTrain step - Step 5220, Loss 0.015447821468114853\n",
            "\t\tTrain step - Step 5250, Loss 0.014606921002268791\n",
            "\t\tTrain step - Step 5280, Loss 0.01293202769011259\n",
            "\t\tTrain step - Step 5310, Loss 0.01381686981767416\n",
            "\t\tTrain step - Step 5340, Loss 0.013808376155793667\n",
            "\t\tTrain step - Step 5370, Loss 0.016105560585856438\n",
            "\t\tTrain step - Step 5400, Loss 0.014887426979839802\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.01390643768027667 - Train Accuracy: 0.7429814532520326\n",
            "\t\t\tVal Loss: 0.02296079650321709 - Val Accuracy: 0.6005714285714285\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 5430, Loss 0.015114939771592617\n",
            "\t\tTrain step - Step 5460, Loss 0.013094669207930565\n",
            "\t\tTrain step - Step 5490, Loss 0.0156526081264019\n",
            "\t\tTrain step - Step 5520, Loss 0.017333945259451866\n",
            "\t\tTrain step - Step 5550, Loss 0.012441360391676426\n",
            "\t\tTrain step - Step 5580, Loss 0.013368730433285236\n",
            "\t\tTrain step - Step 5610, Loss 0.013555106706917286\n",
            "\t\tTrain step - Step 5640, Loss 0.01319971401244402\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.01384861337975031 - Train Accuracy: 0.7452680386178862\n",
            "\t\t\tVal Loss: 0.022899766618918096 - Val Accuracy: 0.5825714285714285\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 5670, Loss 0.013156200759112835\n",
            "\t\tTrain step - Step 5700, Loss 0.016114016994833946\n",
            "\t\tTrain step - Step 5730, Loss 0.015063950791954994\n",
            "\t\tTrain step - Step 5760, Loss 0.013897361233830452\n",
            "\t\tTrain step - Step 5790, Loss 0.014329604804515839\n",
            "\t\tTrain step - Step 5820, Loss 0.014843332581222057\n",
            "\t\tTrain step - Step 5850, Loss 0.01675049588084221\n",
            "\t\tTrain step - Step 5880, Loss 0.014080213382840157\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.01403081910760422 - Train Accuracy: 0.7433625508130082\n",
            "\t\t\tVal Loss: 0.021402724386591996 - Val Accuracy: 0.6054285714285714\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 5910, Loss 0.01380389928817749\n",
            "\t\tTrain step - Step 5940, Loss 0.012328550219535828\n",
            "\t\tTrain step - Step 5970, Loss 0.014670653268694878\n",
            "\t\tTrain step - Step 6000, Loss 0.013611653819680214\n",
            "\t\tTrain step - Step 6030, Loss 0.01408363413065672\n",
            "\t\tTrain step - Step 6060, Loss 0.014051591977477074\n",
            "\t\tTrain step - Step 6090, Loss 0.01442510075867176\n",
            "\t\tTrain step - Step 6120, Loss 0.012949459254741669\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.01380180820398699 - Train Accuracy: 0.7475546239837398\n",
            "\t\t\tVal Loss: 0.02304785811741437 - Val Accuracy: 0.5811428571428572\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 6150, Loss 0.0137943672016263\n",
            "\t\tTrain step - Step 6180, Loss 0.011072926223278046\n",
            "\t\tTrain step - Step 6210, Loss 0.01318896934390068\n",
            "\t\tTrain step - Step 6240, Loss 0.015476011671125889\n",
            "\t\tTrain step - Step 6270, Loss 0.015022129751741886\n",
            "\t\tTrain step - Step 6300, Loss 0.013019557110965252\n",
            "\t\tTrain step - Step 6330, Loss 0.012460722588002682\n",
            "\t\tTrain step - Step 6360, Loss 0.01494645606726408\n",
            "\t\tTrain step - Step 6390, Loss 0.015568599104881287\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.013977394624787375 - Train Accuracy: 0.7445693597560976\n",
            "\t\t\tVal Loss: 0.022856140808601464 - Val Accuracy: 0.5897142857142857\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 6420, Loss 0.011086010374128819\n",
            "\t\tTrain step - Step 6450, Loss 0.01602262444794178\n",
            "\t\tTrain step - Step 6480, Loss 0.01370698306709528\n",
            "\t\tTrain step - Step 6510, Loss 0.014348520897328854\n",
            "\t\tTrain step - Step 6540, Loss 0.013865615241229534\n",
            "\t\tTrain step - Step 6570, Loss 0.0126314926892519\n",
            "\t\tTrain step - Step 6600, Loss 0.012881254777312279\n",
            "\t\tTrain step - Step 6630, Loss 0.01489175297319889\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.01387549535848382 - Train Accuracy: 0.7435848577235772\n",
            "\t\t\tVal Loss: 0.02260789444803127 - Val Accuracy: 0.5854285714285714\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 6660, Loss 0.011122667230665684\n",
            "\t\tTrain step - Step 6690, Loss 0.014757459051907063\n",
            "\t\tTrain step - Step 6720, Loss 0.013977606780827045\n",
            "\t\tTrain step - Step 6750, Loss 0.0170148778706789\n",
            "\t\tTrain step - Step 6780, Loss 0.013632755726575851\n",
            "\t\tTrain step - Step 6810, Loss 0.014972691424190998\n",
            "\t\tTrain step - Step 6840, Loss 0.017037825658917427\n",
            "\t\tTrain step - Step 6870, Loss 0.01493688952177763\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.013648688032223685 - Train Accuracy: 0.7490790142276422\n",
            "\t\t\tVal Loss: 0.023345965393153683 - Val Accuracy: 0.5794285714285714\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 6900, Loss 0.015807855874300003\n",
            "\t\tTrain step - Step 6930, Loss 0.011716248467564583\n",
            "\t\tTrain step - Step 6960, Loss 0.013053970411419868\n",
            "\t\tTrain step - Step 6990, Loss 0.01171391922980547\n",
            "\t\tTrain step - Step 7020, Loss 0.013889458030462265\n",
            "\t\tTrain step - Step 7050, Loss 0.016868531703948975\n",
            "\t\tTrain step - Step 7080, Loss 0.016961336135864258\n",
            "\t\tTrain step - Step 7110, Loss 0.012688400223851204\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.01375626986922045 - Train Accuracy: 0.7481580284552846\n",
            "\t\t\tVal Loss: 0.023368670970999768 - Val Accuracy: 0.5774285714285714\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 7140, Loss 0.010833586566150188\n",
            "\t\tTrain step - Step 7170, Loss 0.013674064539372921\n",
            "\t\tTrain step - Step 7200, Loss 0.017107533290982246\n",
            "\t\tTrain step - Step 7230, Loss 0.014034699648618698\n",
            "\t\tTrain step - Step 7260, Loss 0.012531045824289322\n",
            "\t\tTrain step - Step 7290, Loss 0.013747379183769226\n",
            "\t\tTrain step - Step 7320, Loss 0.01566506177186966\n",
            "\t\tTrain step - Step 7350, Loss 0.01874765194952488\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.01380917221322898 - Train Accuracy: 0.7445693597560976\n",
            "\t\t\tVal Loss: 0.02328425955160388 - Val Accuracy: 0.5831428571428572\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 7380, Loss 0.010983383283019066\n",
            "\t\tTrain step - Step 7410, Loss 0.010478466749191284\n",
            "\t\tTrain step - Step 7440, Loss 0.012050271034240723\n",
            "\t\tTrain step - Step 7470, Loss 0.01337935496121645\n",
            "\t\tTrain step - Step 7500, Loss 0.012464835308492184\n",
            "\t\tTrain step - Step 7530, Loss 0.012847055681049824\n",
            "\t\tTrain step - Step 7560, Loss 0.014725038781762123\n",
            "\t\tTrain step - Step 7590, Loss 0.015582222491502762\n",
            "\t\tTrain step - Step 7620, Loss 0.013411762192845345\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.013721288363562852 - Train Accuracy: 0.7494918699186992\n",
            "\t\t\tVal Loss: 0.022456416061946323 - Val Accuracy: 0.5911428571428572\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 7650, Loss 0.011347858235239983\n",
            "\t\tTrain step - Step 7680, Loss 0.011109818704426289\n",
            "\t\tTrain step - Step 7710, Loss 0.01606466993689537\n",
            "\t\tTrain step - Step 7740, Loss 0.014413422904908657\n",
            "\t\tTrain step - Step 7770, Loss 0.013344170525670052\n",
            "\t\tTrain step - Step 7800, Loss 0.01045179832726717\n",
            "\t\tTrain step - Step 7830, Loss 0.013751329854130745\n",
            "\t\tTrain step - Step 7860, Loss 0.015365495346486568\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.013682902271942637 - Train Accuracy: 0.7486026422764228\n",
            "\t\t\tVal Loss: 0.023006484444652284 - Val Accuracy: 0.5834285714285714\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 7890, Loss 0.012160695157945156\n",
            "\t\tTrain step - Step 7920, Loss 0.00906179565936327\n",
            "\t\tTrain step - Step 7950, Loss 0.015041394159197807\n",
            "\t\tTrain step - Step 7980, Loss 0.013513293117284775\n",
            "\t\tTrain step - Step 8010, Loss 0.01718827895820141\n",
            "\t\tTrain step - Step 8040, Loss 0.013936072587966919\n",
            "\t\tTrain step - Step 8070, Loss 0.015580015257000923\n",
            "\t\tTrain step - Step 8100, Loss 0.014109404757618904\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.013487469722948424 - Train Accuracy: 0.7533028455284553\n",
            "\t\t\tVal Loss: 0.023205923481977413 - Val Accuracy: 0.5785714285714286\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 8130, Loss 0.01420784555375576\n",
            "\t\tTrain step - Step 8160, Loss 0.011230912990868092\n",
            "\t\tTrain step - Step 8190, Loss 0.013402522541582584\n",
            "\t\tTrain step - Step 8220, Loss 0.01194802951067686\n",
            "\t\tTrain step - Step 8250, Loss 0.016142088919878006\n",
            "\t\tTrain step - Step 8280, Loss 0.014644308015704155\n",
            "\t\tTrain step - Step 8310, Loss 0.014297854155302048\n",
            "\t\tTrain step - Step 8340, Loss 0.015372304245829582\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.01362190400893853 - Train Accuracy: 0.7509209857723578\n",
            "\t\t\tVal Loss: 0.021438855212181807 - Val Accuracy: 0.6057142857142858\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 8370, Loss 0.011557154357433319\n",
            "\t\tTrain step - Step 8400, Loss 0.012016777880489826\n",
            "\t\tTrain step - Step 8430, Loss 0.010092564858496189\n",
            "\t\tTrain step - Step 8460, Loss 0.01367573905736208\n",
            "\t\tTrain step - Step 8490, Loss 0.01266628596931696\n",
            "\t\tTrain step - Step 8520, Loss 0.016793427988886833\n",
            "\t\tTrain step - Step 8550, Loss 0.013737279921770096\n",
            "\t\tTrain step - Step 8580, Loss 0.013004726730287075\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.013639084332266717 - Train Accuracy: 0.7509845020325203\n",
            "\t\t\tVal Loss: 0.025472368080435053 - Val Accuracy: 0.5514285714285714\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 8610, Loss 0.013370994478464127\n",
            "\t\tTrain step - Step 8640, Loss 0.013081632554531097\n",
            "\t\tTrain step - Step 8670, Loss 0.0143706314265728\n",
            "\t\tTrain step - Step 8700, Loss 0.012836184352636337\n",
            "\t\tTrain step - Step 8730, Loss 0.012728572823107243\n",
            "\t\tTrain step - Step 8760, Loss 0.01339288242161274\n",
            "\t\tTrain step - Step 8790, Loss 0.011473159305751324\n",
            "\t\tTrain step - Step 8820, Loss 0.011720435693860054\n",
            "\t\tTrain step - Step 8850, Loss 0.016609732061624527\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.013551341509825088 - Train Accuracy: 0.7531440548780488\n",
            "\t\t\tVal Loss: 0.02349988354503044 - Val Accuracy: 0.5771428571428572\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 8880, Loss 0.01302494015544653\n",
            "\t\tTrain step - Step 8910, Loss 0.01231489796191454\n",
            "\t\tTrain step - Step 8940, Loss 0.011221421882510185\n",
            "\t\tTrain step - Step 8970, Loss 0.0125280087813735\n",
            "\t\tTrain step - Step 9000, Loss 0.012819232419133186\n",
            "\t\tTrain step - Step 9030, Loss 0.01563394069671631\n",
            "\t\tTrain step - Step 9060, Loss 0.012472567148506641\n",
            "\t\tTrain step - Step 9090, Loss 0.012465131469070911\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.013634678385243184 - Train Accuracy: 0.748412093495935\n",
            "\t\t\tVal Loss: 0.025348858575203588 - Val Accuracy: 0.5548571428571428\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 9120, Loss 0.011399640701711178\n",
            "\t\tTrain step - Step 9150, Loss 0.012677323073148727\n",
            "\t\tTrain step - Step 9180, Loss 0.013696417212486267\n",
            "\t\tTrain step - Step 9210, Loss 0.013996249064803123\n",
            "\t\tTrain step - Step 9240, Loss 0.017102975398302078\n",
            "\t\tTrain step - Step 9270, Loss 0.013284634798765182\n",
            "\t\tTrain step - Step 9300, Loss 0.013492395170032978\n",
            "\t\tTrain step - Step 9330, Loss 0.01402293797582388\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.013670511339314101 - Train Accuracy: 0.7496506605691057\n",
            "\t\t\tVal Loss: 0.023034301386880025 - Val Accuracy: 0.5797142857142857\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 9360, Loss 0.016011646017432213\n",
            "\t\tTrain step - Step 9390, Loss 0.012624059803783894\n",
            "\t\tTrain step - Step 9420, Loss 0.012227578088641167\n",
            "\t\tTrain step - Step 9450, Loss 0.014711965806782246\n",
            "\t\tTrain step - Step 9480, Loss 0.013423454016447067\n",
            "\t\tTrain step - Step 9510, Loss 0.018186260014772415\n",
            "\t\tTrain step - Step 9540, Loss 0.015334433875977993\n",
            "\t\tTrain step - Step 9570, Loss 0.014619815163314342\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.013504126355264002 - Train Accuracy: 0.7526041666666666\n",
            "\t\t\tVal Loss: 0.024984953060214008 - Val Accuracy: 0.5591428571428572\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 9600, Loss 0.012184171006083488\n",
            "\t\tTrain step - Step 9630, Loss 0.01163404155522585\n",
            "\t\tTrain step - Step 9660, Loss 0.013956747949123383\n",
            "\t\tTrain step - Step 9690, Loss 0.012611579149961472\n",
            "\t\tTrain step - Step 9720, Loss 0.011437381617724895\n",
            "\t\tTrain step - Step 9750, Loss 0.01337382011115551\n",
            "\t\tTrain step - Step 9780, Loss 0.014188526198267937\n",
            "\t\tTrain step - Step 9810, Loss 0.012679820880293846\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.013434025182623446 - Train Accuracy: 0.7545096544715447\n",
            "\t\t\tVal Loss: 0.023213337441640242 - Val Accuracy: 0.5745714285714286\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 9840, Loss 0.01251996960490942\n",
            "\t\tTrain step - Step 9870, Loss 0.013101324439048767\n",
            "\t\tTrain step - Step 9900, Loss 0.013861196115612984\n",
            "\t\tTrain step - Step 9930, Loss 0.01516939140856266\n",
            "\t\tTrain step - Step 9960, Loss 0.013696548528969288\n",
            "\t\tTrain step - Step 9990, Loss 0.015182669274508953\n",
            "\t\tTrain step - Step 10020, Loss 0.014417615719139576\n",
            "\t\tTrain step - Step 10050, Loss 0.014254729263484478\n",
            "\t\tTrain step - Step 10080, Loss 0.013112101703882217\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.013541241532297639 - Train Accuracy: 0.7498094512195121\n",
            "\t\t\tVal Loss: 0.02141785136024867 - Val Accuracy: 0.6054285714285714\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 10110, Loss 0.012662310153245926\n",
            "\t\tTrain step - Step 10140, Loss 0.012469782494008541\n",
            "\t\tTrain step - Step 10170, Loss 0.011158892884850502\n",
            "\t\tTrain step - Step 10200, Loss 0.012469999492168427\n",
            "\t\tTrain step - Step 10230, Loss 0.016423296183347702\n",
            "\t\tTrain step - Step 10260, Loss 0.013799224980175495\n",
            "\t\tTrain step - Step 10290, Loss 0.012717453762888908\n",
            "\t\tTrain step - Step 10320, Loss 0.016536060720682144\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.013293033302950908 - Train Accuracy: 0.7569232723577236\n",
            "\t\t\tVal Loss: 0.02257813699543476 - Val Accuracy: 0.5951428571428572\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 10350, Loss 0.01322915032505989\n",
            "\t\tTrain step - Step 10380, Loss 0.012923106551170349\n",
            "\t\tTrain step - Step 10410, Loss 0.012986716814339161\n",
            "\t\tTrain step - Step 10440, Loss 0.015744369477033615\n",
            "\t\tTrain step - Step 10470, Loss 0.013811454176902771\n",
            "\t\tTrain step - Step 10500, Loss 0.012675158679485321\n",
            "\t\tTrain step - Step 10530, Loss 0.015900954604148865\n",
            "\t\tTrain step - Step 10560, Loss 0.0135200759395957\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.013470457238334467 - Train Accuracy: 0.7534616361788617\n",
            "\t\t\tVal Loss: 0.0250128140074334 - Val Accuracy: 0.5688571428571428\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 10590, Loss 0.015068014152348042\n",
            "\t\tTrain step - Step 10620, Loss 0.01304106879979372\n",
            "\t\tTrain step - Step 10650, Loss 0.01346700917929411\n",
            "\t\tTrain step - Step 10680, Loss 0.015787435695528984\n",
            "\t\tTrain step - Step 10710, Loss 0.013018950819969177\n",
            "\t\tTrain step - Step 10740, Loss 0.012967451475560665\n",
            "\t\tTrain step - Step 10770, Loss 0.01512080430984497\n",
            "\t\tTrain step - Step 10800, Loss 0.010487866587936878\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.01350623180302299 - Train Accuracy: 0.7487931910569106\n",
            "\t\t\tVal Loss: 0.02294062450528145 - Val Accuracy: 0.5888571428571429\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 10830, Loss 0.012433845549821854\n",
            "\t\tTrain step - Step 10860, Loss 0.012847492471337318\n",
            "\t\tTrain step - Step 10890, Loss 0.013359131291508675\n",
            "\t\tTrain step - Step 10920, Loss 0.014892379753291607\n",
            "\t\tTrain step - Step 10950, Loss 0.01377504039555788\n",
            "\t\tTrain step - Step 10980, Loss 0.014201316051185131\n",
            "\t\tTrain step - Step 11010, Loss 0.012439495883882046\n",
            "\t\tTrain step - Step 11040, Loss 0.01602160558104515\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.013540262390473267 - Train Accuracy: 0.7517466971544715\n",
            "\t\t\tVal Loss: 0.02387137125645365 - Val Accuracy: 0.5725714285714286\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 11070, Loss 0.011340945959091187\n",
            "\t\tTrain step - Step 11100, Loss 0.014022738672792912\n",
            "\t\tTrain step - Step 11130, Loss 0.011135957203805447\n",
            "\t\tTrain step - Step 11160, Loss 0.016547193750739098\n",
            "\t\tTrain step - Step 11190, Loss 0.011470536701381207\n",
            "\t\tTrain step - Step 11220, Loss 0.015146493911743164\n",
            "\t\tTrain step - Step 11250, Loss 0.016458844766020775\n",
            "\t\tTrain step - Step 11280, Loss 0.01294588390737772\n",
            "\t\tTrain step - Step 11310, Loss 0.013338162563741207\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.013385915458656666 - Train Accuracy: 0.7574631605691057\n",
            "\t\t\tVal Loss: 0.02133643820083567 - Val Accuracy: 0.6171428571428571\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 11340, Loss 0.012076351791620255\n",
            "\t\tTrain step - Step 11370, Loss 0.012972371652722359\n",
            "\t\tTrain step - Step 11400, Loss 0.011960269883275032\n",
            "\t\tTrain step - Step 11430, Loss 0.013722335919737816\n",
            "\t\tTrain step - Step 11460, Loss 0.014054293744266033\n",
            "\t\tTrain step - Step 11490, Loss 0.014033042825758457\n",
            "\t\tTrain step - Step 11520, Loss 0.013767690397799015\n",
            "\t\tTrain step - Step 11550, Loss 0.01639656536281109\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.013368169455296867 - Train Accuracy: 0.7538109756097561\n",
            "\t\t\tVal Loss: 0.022275826627654687 - Val Accuracy: 0.5974285714285714\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 11580, Loss 0.011655407026410103\n",
            "\t\tTrain step - Step 11610, Loss 0.011269857175648212\n",
            "\t\tTrain step - Step 11640, Loss 0.012655489146709442\n",
            "\t\tTrain step - Step 11670, Loss 0.014900203794240952\n",
            "\t\tTrain step - Step 11700, Loss 0.0175132155418396\n",
            "\t\tTrain step - Step 11730, Loss 0.012704829685389996\n",
            "\t\tTrain step - Step 11760, Loss 0.014166838489472866\n",
            "\t\tTrain step - Step 11790, Loss 0.014268343336880207\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.013290798776154595 - Train Accuracy: 0.7572726117886179\n",
            "\t\t\tVal Loss: 0.02433886072997536 - Val Accuracy: 0.5722857142857143\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 11820, Loss 0.015353030525147915\n",
            "\t\tTrain step - Step 11850, Loss 0.013645904138684273\n",
            "\t\tTrain step - Step 11880, Loss 0.014116098172962666\n",
            "\t\tTrain step - Step 11910, Loss 0.0121377008035779\n",
            "\t\tTrain step - Step 11940, Loss 0.011230802163481712\n",
            "\t\tTrain step - Step 11970, Loss 0.014903228729963303\n",
            "\t\tTrain step - Step 12000, Loss 0.015523093752563\n",
            "\t\tTrain step - Step 12030, Loss 0.012663714587688446\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.013472736279321154 - Train Accuracy: 0.757177337398374\n",
            "\t\t\tVal Loss: 0.021971657406538725 - Val Accuracy: 0.6082857142857143\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 12060, Loss 0.012854018248617649\n",
            "\t\tTrain step - Step 12090, Loss 0.01133021805435419\n",
            "\t\tTrain step - Step 12120, Loss 0.008093676529824734\n",
            "\t\tTrain step - Step 12150, Loss 0.0073394994251430035\n",
            "\t\tTrain step - Step 12180, Loss 0.009231301955878735\n",
            "\t\tTrain step - Step 12210, Loss 0.008792968466877937\n",
            "\t\tTrain step - Step 12240, Loss 0.0089012011885643\n",
            "\t\tTrain step - Step 12270, Loss 0.009199296124279499\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.009366528948814404 - Train Accuracy: 0.8423208841463414\n",
            "\t\t\tVal Loss: 0.01576421980280429 - Val Accuracy: 0.7082857142857143\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 12300, Loss 0.009429274126887321\n",
            "\t\tTrain step - Step 12330, Loss 0.006575392559170723\n",
            "\t\tTrain step - Step 12360, Loss 0.008320643566548824\n",
            "\t\tTrain step - Step 12390, Loss 0.008430193178355694\n",
            "\t\tTrain step - Step 12420, Loss 0.009095449000597\n",
            "\t\tTrain step - Step 12450, Loss 0.0067758262157440186\n",
            "\t\tTrain step - Step 12480, Loss 0.008832797408103943\n",
            "\t\tTrain step - Step 12510, Loss 0.007333403453230858\n",
            "\t\tTrain step - Step 12540, Loss 0.0077043636702001095\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.008000740794676954 - Train Accuracy: 0.8668064024390244\n",
            "\t\t\tVal Loss: 0.016057224262372723 - Val Accuracy: 0.708\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 12570, Loss 0.007108887657523155\n",
            "\t\tTrain step - Step 12600, Loss 0.008974766358733177\n",
            "\t\tTrain step - Step 12630, Loss 0.008173346519470215\n",
            "\t\tTrain step - Step 12660, Loss 0.007593097630888224\n",
            "\t\tTrain step - Step 12690, Loss 0.007072710897773504\n",
            "\t\tTrain step - Step 12720, Loss 0.006262104492634535\n",
            "\t\tTrain step - Step 12750, Loss 0.006784392520785332\n",
            "\t\tTrain step - Step 12780, Loss 0.007243074476718903\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.00758092497036285 - Train Accuracy: 0.8752223069105691\n",
            "\t\t\tVal Loss: 0.01567969170199441 - Val Accuracy: 0.718\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 12810, Loss 0.005570167675614357\n",
            "\t\tTrain step - Step 12840, Loss 0.004472074564546347\n",
            "\t\tTrain step - Step 12870, Loss 0.007062416989356279\n",
            "\t\tTrain step - Step 12900, Loss 0.007368389051407576\n",
            "\t\tTrain step - Step 12930, Loss 0.005950266029685736\n",
            "\t\tTrain step - Step 12960, Loss 0.00788798462599516\n",
            "\t\tTrain step - Step 12990, Loss 0.006940772756934166\n",
            "\t\tTrain step - Step 13020, Loss 0.006281660869717598\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.007224586061618435 - Train Accuracy: 0.8815739329268293\n",
            "\t\t\tVal Loss: 0.016202833703053848 - Val Accuracy: 0.7114285714285714\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 13050, Loss 0.007247865200042725\n",
            "\t\tTrain step - Step 13080, Loss 0.009247589856386185\n",
            "\t\tTrain step - Step 13110, Loss 0.006991282571107149\n",
            "\t\tTrain step - Step 13140, Loss 0.00677519803866744\n",
            "\t\tTrain step - Step 13170, Loss 0.008765851147472858\n",
            "\t\tTrain step - Step 13200, Loss 0.005203141365200281\n",
            "\t\tTrain step - Step 13230, Loss 0.006703588180243969\n",
            "\t\tTrain step - Step 13260, Loss 0.007305734790861607\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.007011738600118495 - Train Accuracy: 0.8867505081300813\n",
            "\t\t\tVal Loss: 0.016525348282552192 - Val Accuracy: 0.7111428571428572\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 13290, Loss 0.006654804572463036\n",
            "\t\tTrain step - Step 13320, Loss 0.007159425877034664\n",
            "\t\tTrain step - Step 13350, Loss 0.004470059648156166\n",
            "\t\tTrain step - Step 13380, Loss 0.006873312406241894\n",
            "\t\tTrain step - Step 13410, Loss 0.008267312310636044\n",
            "\t\tTrain step - Step 13440, Loss 0.006744187790900469\n",
            "\t\tTrain step - Step 13470, Loss 0.007010435685515404\n",
            "\t\tTrain step - Step 13500, Loss 0.007515004836022854\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.00678588614640076 - Train Accuracy: 0.8897675304878049\n",
            "\t\t\tVal Loss: 0.01679805641262127 - Val Accuracy: 0.7031428571428572\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 13530, Loss 0.006808068603277206\n",
            "\t\tTrain step - Step 13560, Loss 0.005004300270229578\n",
            "\t\tTrain step - Step 13590, Loss 0.0064635490998625755\n",
            "\t\tTrain step - Step 13620, Loss 0.007042710203677416\n",
            "\t\tTrain step - Step 13650, Loss 0.005329596810042858\n",
            "\t\tTrain step - Step 13680, Loss 0.006155196111649275\n",
            "\t\tTrain step - Step 13710, Loss 0.006622922141104937\n",
            "\t\tTrain step - Step 13740, Loss 0.007370008155703545\n",
            "\t\tTrain step - Step 13770, Loss 0.006546511314809322\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.006652384374586002 - Train Accuracy: 0.8921811483739838\n",
            "\t\t\tVal Loss: 0.016581980478284613 - Val Accuracy: 0.7097142857142857\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 13800, Loss 0.007336927577853203\n",
            "\t\tTrain step - Step 13830, Loss 0.004208097700029612\n",
            "\t\tTrain step - Step 13860, Loss 0.008270363323390484\n",
            "\t\tTrain step - Step 13890, Loss 0.006133111193776131\n",
            "\t\tTrain step - Step 13920, Loss 0.005299718119204044\n",
            "\t\tTrain step - Step 13950, Loss 0.005752310622483492\n",
            "\t\tTrain step - Step 13980, Loss 0.008436040952801704\n",
            "\t\tTrain step - Step 14010, Loss 0.005472905468195677\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.006439257558904649 - Train Accuracy: 0.8965637703252033\n",
            "\t\t\tVal Loss: 0.01681327013232346 - Val Accuracy: 0.7094285714285714\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 14040, Loss 0.007375351153314114\n",
            "\t\tTrain step - Step 14070, Loss 0.0060440609231591225\n",
            "\t\tTrain step - Step 14100, Loss 0.008186607621610165\n",
            "\t\tTrain step - Step 14130, Loss 0.0071370587684214115\n",
            "\t\tTrain step - Step 14160, Loss 0.006280622910708189\n",
            "\t\tTrain step - Step 14190, Loss 0.005656857509166002\n",
            "\t\tTrain step - Step 14220, Loss 0.0074638607911765575\n",
            "\t\tTrain step - Step 14250, Loss 0.0063985553570091724\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.006324959912231359 - Train Accuracy: 0.8989456300813008\n",
            "\t\t\tVal Loss: 0.016676567278669348 - Val Accuracy: 0.7051428571428572\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 14280, Loss 0.006622639950364828\n",
            "\t\tTrain step - Step 14310, Loss 0.00492530083283782\n",
            "\t\tTrain step - Step 14340, Loss 0.004286987241357565\n",
            "\t\tTrain step - Step 14370, Loss 0.0060401903465390205\n",
            "\t\tTrain step - Step 14400, Loss 0.006257666274905205\n",
            "\t\tTrain step - Step 14430, Loss 0.005684512201696634\n",
            "\t\tTrain step - Step 14460, Loss 0.0068467180244624615\n",
            "\t\tTrain step - Step 14490, Loss 0.006078668870031834\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.006168312858790159 - Train Accuracy: 0.9018356199186992\n",
            "\t\t\tVal Loss: 0.017131224873342683 - Val Accuracy: 0.7071428571428572\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 14520, Loss 0.00798935629427433\n",
            "\t\tTrain step - Step 14550, Loss 0.004826667718589306\n",
            "\t\tTrain step - Step 14580, Loss 0.006169294007122517\n",
            "\t\tTrain step - Step 14610, Loss 0.005021283403038979\n",
            "\t\tTrain step - Step 14640, Loss 0.005127559415996075\n",
            "\t\tTrain step - Step 14670, Loss 0.006151281297206879\n",
            "\t\tTrain step - Step 14700, Loss 0.006001544650644064\n",
            "\t\tTrain step - Step 14730, Loss 0.007416341919451952\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.006143091832348183 - Train Accuracy: 0.9005017784552846\n",
            "\t\t\tVal Loss: 0.017237252023603235 - Val Accuracy: 0.7048571428571428\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 14760, Loss 0.004169958643615246\n",
            "\t\tTrain step - Step 14790, Loss 0.005347320809960365\n",
            "\t\tTrain step - Step 14820, Loss 0.006068864371627569\n",
            "\t\tTrain step - Step 14850, Loss 0.005666710436344147\n",
            "\t\tTrain step - Step 14880, Loss 0.006066368892788887\n",
            "\t\tTrain step - Step 14910, Loss 0.006254617590457201\n",
            "\t\tTrain step - Step 14940, Loss 0.005659917369484901\n",
            "\t\tTrain step - Step 14970, Loss 0.005125114694237709\n",
            "\t\tTrain step - Step 15000, Loss 0.006411298178136349\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.005987767108367771 - Train Accuracy: 0.9020896849593496\n",
            "\t\t\tVal Loss: 0.018052878573403826 - Val Accuracy: 0.6931428571428572\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 15030, Loss 0.004425156861543655\n",
            "\t\tTrain step - Step 15060, Loss 0.004976381082087755\n",
            "\t\tTrain step - Step 15090, Loss 0.004535505082458258\n",
            "\t\tTrain step - Step 15120, Loss 0.006346735171973705\n",
            "\t\tTrain step - Step 15150, Loss 0.00684258621186018\n",
            "\t\tTrain step - Step 15180, Loss 0.00539817102253437\n",
            "\t\tTrain step - Step 15210, Loss 0.007018447853624821\n",
            "\t\tTrain step - Step 15240, Loss 0.008558100089430809\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.0059551760654639055 - Train Accuracy: 0.9042174796747967\n",
            "\t\t\tVal Loss: 0.01796524309819298 - Val Accuracy: 0.6868571428571428\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 15270, Loss 0.00634161988273263\n",
            "\t\tTrain step - Step 15300, Loss 0.004546645097434521\n",
            "\t\tTrain step - Step 15330, Loss 0.0050933146849274635\n",
            "\t\tTrain step - Step 15360, Loss 0.003912897780537605\n",
            "\t\tTrain step - Step 15390, Loss 0.0045630852691829205\n",
            "\t\tTrain step - Step 15420, Loss 0.006237397436052561\n",
            "\t\tTrain step - Step 15450, Loss 0.004217840731143951\n",
            "\t\tTrain step - Step 15480, Loss 0.007238748949021101\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.005941547086174653 - Train Accuracy: 0.9047256097560976\n",
            "\t\t\tVal Loss: 0.017800710945656256 - Val Accuracy: 0.6897142857142857\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 15510, Loss 0.005253109615296125\n",
            "\t\tTrain step - Step 15540, Loss 0.005545161664485931\n",
            "\t\tTrain step - Step 15570, Loss 0.0045859310775995255\n",
            "\t\tTrain step - Step 15600, Loss 0.005723198410123587\n",
            "\t\tTrain step - Step 15630, Loss 0.004118171986192465\n",
            "\t\tTrain step - Step 15660, Loss 0.004038652870804071\n",
            "\t\tTrain step - Step 15690, Loss 0.00528242951259017\n",
            "\t\tTrain step - Step 15720, Loss 0.004737967625260353\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.004939308506436646 - Train Accuracy: 0.9268610264227642\n",
            "\t\t\tVal Loss: 0.016618741376857673 - Val Accuracy: 0.7137142857142857\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 15750, Loss 0.003999596927314997\n",
            "\t\tTrain step - Step 15780, Loss 0.004762657452374697\n",
            "\t\tTrain step - Step 15810, Loss 0.0045857843942940235\n",
            "\t\tTrain step - Step 15840, Loss 0.005244417116045952\n",
            "\t\tTrain step - Step 15870, Loss 0.004759430885314941\n",
            "\t\tTrain step - Step 15900, Loss 0.004099452402442694\n",
            "\t\tTrain step - Step 15930, Loss 0.005071671679615974\n",
            "\t\tTrain step - Step 15960, Loss 0.0038928824942559004\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.004681598327910088 - Train Accuracy: 0.9326727642276422\n",
            "\t\t\tVal Loss: 0.016553750511125793 - Val Accuracy: 0.7142857142857143\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 15990, Loss 0.005989420227706432\n",
            "\t\tTrain step - Step 16020, Loss 0.004545561969280243\n",
            "\t\tTrain step - Step 16050, Loss 0.004601468797773123\n",
            "\t\tTrain step - Step 16080, Loss 0.003293045097962022\n",
            "\t\tTrain step - Step 16110, Loss 0.0037608519196510315\n",
            "\t\tTrain step - Step 16140, Loss 0.0048601506277918816\n",
            "\t\tTrain step - Step 16170, Loss 0.004243077244609594\n",
            "\t\tTrain step - Step 16200, Loss 0.004856935702264309\n",
            "\t\tTrain step - Step 16230, Loss 0.006249537225812674\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.004544857721889346 - Train Accuracy: 0.9339748475609756\n",
            "\t\t\tVal Loss: 0.016371024888940156 - Val Accuracy: 0.7265714285714285\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 16260, Loss 0.004397579934448004\n",
            "\t\tTrain step - Step 16290, Loss 0.00508775282651186\n",
            "\t\tTrain step - Step 16320, Loss 0.003997013438493013\n",
            "\t\tTrain step - Step 16350, Loss 0.00332000944763422\n",
            "\t\tTrain step - Step 16380, Loss 0.004365192726254463\n",
            "\t\tTrain step - Step 16410, Loss 0.003483261913061142\n",
            "\t\tTrain step - Step 16440, Loss 0.004347085487097502\n",
            "\t\tTrain step - Step 16470, Loss 0.00497272377833724\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.004401451532304953 - Train Accuracy: 0.936547256097561\n",
            "\t\t\tVal Loss: 0.01678007428667375 - Val Accuracy: 0.7168571428571429\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 16500, Loss 0.0039593931287527084\n",
            "\t\tTrain step - Step 16530, Loss 0.0031807534396648407\n",
            "\t\tTrain step - Step 16560, Loss 0.004494030959904194\n",
            "\t\tTrain step - Step 16590, Loss 0.004020778462290764\n",
            "\t\tTrain step - Step 16620, Loss 0.004179083742201328\n",
            "\t\tTrain step - Step 16650, Loss 0.0037144797388464212\n",
            "\t\tTrain step - Step 16680, Loss 0.004865674301981926\n",
            "\t\tTrain step - Step 16710, Loss 0.004758498165756464\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.0043336940244052225 - Train Accuracy: 0.9409616361788617\n",
            "\t\t\tVal Loss: 0.016474711991447424 - Val Accuracy: 0.7225714285714285\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 16740, Loss 0.0038165603764355183\n",
            "\t\tTrain step - Step 16770, Loss 0.004910261370241642\n",
            "\t\tTrain step - Step 16800, Loss 0.004725667182356119\n",
            "\t\tTrain step - Step 16830, Loss 0.004061605781316757\n",
            "\t\tTrain step - Step 16860, Loss 0.0063407509587705135\n",
            "\t\tTrain step - Step 16890, Loss 0.0041734278202056885\n",
            "\t\tTrain step - Step 16920, Loss 0.004396079573780298\n",
            "\t\tTrain step - Step 16950, Loss 0.003239038400352001\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.0043206242740351135 - Train Accuracy: 0.9398818597560976\n",
            "\t\t\tVal Loss: 0.016936690130803202 - Val Accuracy: 0.7142857142857143\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 16980, Loss 0.004003400448709726\n",
            "\t\tTrain step - Step 17010, Loss 0.004973976872861385\n",
            "\t\tTrain step - Step 17040, Loss 0.004571049008518457\n",
            "\t\tTrain step - Step 17070, Loss 0.003402318572625518\n",
            "\t\tTrain step - Step 17100, Loss 0.0036941312719136477\n",
            "\t\tTrain step - Step 17130, Loss 0.004465675912797451\n",
            "\t\tTrain step - Step 17160, Loss 0.004050722345709801\n",
            "\t\tTrain step - Step 17190, Loss 0.003782798070460558\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/55 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.004238704944453467 - Train Accuracy: 0.9405805386178862\n",
            "\t\t\tVal Loss: 0.017051432181947997 - Val Accuracy: 0.7128571428571429\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 55/55 [00:02<00:00, 26.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 7:\n",
            "\t\tTrain Mean Accuracy: 0.7910287819396051\n",
            "\t\tVal Mean Accuracy: 0.6185183673469388\n",
            "\t\tTest Accuracy: 0.7231428571428572\n",
            "\n",
            "STARTING JOINT TRAINING STAGE 8...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.016256535425782204\n",
            "\t\tTrain step - Step 60, Loss 0.015762867406010628\n",
            "\t\tTrain step - Step 90, Loss 0.017615938559174538\n",
            "\t\tTrain step - Step 120, Loss 0.01964614912867546\n",
            "\t\tTrain step - Step 150, Loss 0.017053870484232903\n",
            "\t\tTrain step - Step 180, Loss 0.018066253513097763\n",
            "\t\tTrain step - Step 210, Loss 0.01847440004348755\n",
            "\t\tTrain step - Step 240, Loss 0.01674763299524784\n",
            "\t\tTrain step - Step 270, Loss 0.019383948296308517\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.0177330562871387 - Train Accuracy: 0.6739045818505338\n",
            "\t\t\tVal Loss: 0.027332325174938887 - Val Accuracy: 0.51425\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.014131869189441204\n",
            "\t\tTrain step - Step 330, Loss 0.01704425737261772\n",
            "\t\tTrain step - Step 360, Loss 0.016042226925492287\n",
            "\t\tTrain step - Step 390, Loss 0.014019928872585297\n",
            "\t\tTrain step - Step 420, Loss 0.016498129814863205\n",
            "\t\tTrain step - Step 450, Loss 0.01665428839623928\n",
            "\t\tTrain step - Step 480, Loss 0.018244119361042976\n",
            "\t\tTrain step - Step 510, Loss 0.020256828516721725\n",
            "\t\tTrain step - Step 540, Loss 0.01468394510447979\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.01644545644720572 - Train Accuracy: 0.6898632117437722\n",
            "\t\t\tVal Loss: 0.02507697808323428 - Val Accuracy: 0.54375\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.01589554361999035\n",
            "\t\tTrain step - Step 600, Loss 0.014496246352791786\n",
            "\t\tTrain step - Step 630, Loss 0.015669558197259903\n",
            "\t\tTrain step - Step 660, Loss 0.016380006447434425\n",
            "\t\tTrain step - Step 690, Loss 0.01451960764825344\n",
            "\t\tTrain step - Step 720, Loss 0.01602814719080925\n",
            "\t\tTrain step - Step 750, Loss 0.014930169098079205\n",
            "\t\tTrain step - Step 780, Loss 0.018239833414554596\n",
            "\t\tTrain step - Step 810, Loss 0.015058008953928947\n",
            "\t\tTrain step - Step 840, Loss 0.014524409547448158\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.016329165233226223 - Train Accuracy: 0.6963411921708185\n",
            "\t\t\tVal Loss: 0.023800551804015413 - Val Accuracy: 0.575\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 870, Loss 0.016050249338150024\n",
            "\t\tTrain step - Step 900, Loss 0.015847181901335716\n",
            "\t\tTrain step - Step 930, Loss 0.0169368963688612\n",
            "\t\tTrain step - Step 960, Loss 0.01807287149131298\n",
            "\t\tTrain step - Step 990, Loss 0.016643524169921875\n",
            "\t\tTrain step - Step 1020, Loss 0.01651761494576931\n",
            "\t\tTrain step - Step 1050, Loss 0.01685193181037903\n",
            "\t\tTrain step - Step 1080, Loss 0.014878141693770885\n",
            "\t\tTrain step - Step 1110, Loss 0.018546687439084053\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.01607326104627173 - Train Accuracy: 0.7030137900355872\n",
            "\t\t\tVal Loss: 0.02267682208912447 - Val Accuracy: 0.5815\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.01518323179334402\n",
            "\t\tTrain step - Step 1170, Loss 0.01514637190848589\n",
            "\t\tTrain step - Step 1200, Loss 0.012980310246348381\n",
            "\t\tTrain step - Step 1230, Loss 0.01381021086126566\n",
            "\t\tTrain step - Step 1260, Loss 0.014379672706127167\n",
            "\t\tTrain step - Step 1290, Loss 0.01666828617453575\n",
            "\t\tTrain step - Step 1320, Loss 0.015380661934614182\n",
            "\t\tTrain step - Step 1350, Loss 0.01655854657292366\n",
            "\t\tTrain step - Step 1380, Loss 0.017806729301810265\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.016049729603810032 - Train Accuracy: 0.6998721085409253\n",
            "\t\t\tVal Loss: 0.022931046041776426 - Val Accuracy: 0.57\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.013452684506773949\n",
            "\t\tTrain step - Step 1440, Loss 0.014210066758096218\n",
            "\t\tTrain step - Step 1470, Loss 0.011759531684219837\n",
            "\t\tTrain step - Step 1500, Loss 0.014343995600938797\n",
            "\t\tTrain step - Step 1530, Loss 0.0142383286729455\n",
            "\t\tTrain step - Step 1560, Loss 0.017177743837237358\n",
            "\t\tTrain step - Step 1590, Loss 0.015283218584954739\n",
            "\t\tTrain step - Step 1620, Loss 0.015207328833639622\n",
            "\t\tTrain step - Step 1650, Loss 0.013914360664784908\n",
            "\t\tTrain step - Step 1680, Loss 0.01744111068546772\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.0157813817971913 - Train Accuracy: 0.7078792259786477\n",
            "\t\t\tVal Loss: 0.02244047581916675 - Val Accuracy: 0.58525\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 1710, Loss 0.013456916436553001\n",
            "\t\tTrain step - Step 1740, Loss 0.01495504379272461\n",
            "\t\tTrain step - Step 1770, Loss 0.01979847624897957\n",
            "\t\tTrain step - Step 1800, Loss 0.015935901552438736\n",
            "\t\tTrain step - Step 1830, Loss 0.01672314666211605\n",
            "\t\tTrain step - Step 1860, Loss 0.0145372673869133\n",
            "\t\tTrain step - Step 1890, Loss 0.016969559714198112\n",
            "\t\tTrain step - Step 1920, Loss 0.014877406880259514\n",
            "\t\tTrain step - Step 1950, Loss 0.014864552766084671\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.015823983292350564 - Train Accuracy: 0.7056828291814946\n",
            "\t\t\tVal Loss: 0.025995525778853334 - Val Accuracy: 0.527\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 1980, Loss 0.016532080247998238\n",
            "\t\tTrain step - Step 2010, Loss 0.013318270444869995\n",
            "\t\tTrain step - Step 2040, Loss 0.013081188313663006\n",
            "\t\tTrain step - Step 2070, Loss 0.01604650355875492\n",
            "\t\tTrain step - Step 2100, Loss 0.015500529669225216\n",
            "\t\tTrain step - Step 2130, Loss 0.017045777291059494\n",
            "\t\tTrain step - Step 2160, Loss 0.0186162032186985\n",
            "\t\tTrain step - Step 2190, Loss 0.01649653911590576\n",
            "\t\tTrain step - Step 2220, Loss 0.01979726552963257\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.015720810976502523 - Train Accuracy: 0.7088245106761566\n",
            "\t\t\tVal Loss: 0.023613059282070026 - Val Accuracy: 0.57325\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 2250, Loss 0.013762576505541801\n",
            "\t\tTrain step - Step 2280, Loss 0.015055999159812927\n",
            "\t\tTrain step - Step 2310, Loss 0.01837179996073246\n",
            "\t\tTrain step - Step 2340, Loss 0.013290469534695148\n",
            "\t\tTrain step - Step 2370, Loss 0.018881196156144142\n",
            "\t\tTrain step - Step 2400, Loss 0.01511405035853386\n",
            "\t\tTrain step - Step 2430, Loss 0.017887283116579056\n",
            "\t\tTrain step - Step 2460, Loss 0.016713125631213188\n",
            "\t\tTrain step - Step 2490, Loss 0.0148672079667449\n",
            "\t\tTrain step - Step 2520, Loss 0.01625281199812889\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.015889074928475234 - Train Accuracy: 0.7046263345195729\n",
            "\t\t\tVal Loss: 0.023417109565343708 - Val Accuracy: 0.577\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 2550, Loss 0.013761075213551521\n",
            "\t\tTrain step - Step 2580, Loss 0.015984278172254562\n",
            "\t\tTrain step - Step 2610, Loss 0.017138749361038208\n",
            "\t\tTrain step - Step 2640, Loss 0.015407986007630825\n",
            "\t\tTrain step - Step 2670, Loss 0.015295341610908508\n",
            "\t\tTrain step - Step 2700, Loss 0.01592859998345375\n",
            "\t\tTrain step - Step 2730, Loss 0.01861358806490898\n",
            "\t\tTrain step - Step 2760, Loss 0.01663975790143013\n",
            "\t\tTrain step - Step 2790, Loss 0.01748013310134411\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.015527512473833095 - Train Accuracy: 0.7113545373665481\n",
            "\t\t\tVal Loss: 0.02313447347842157 - Val Accuracy: 0.57425\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 2820, Loss 0.014860398136079311\n",
            "\t\tTrain step - Step 2850, Loss 0.01567501202225685\n",
            "\t\tTrain step - Step 2880, Loss 0.01404024101793766\n",
            "\t\tTrain step - Step 2910, Loss 0.016850003972649574\n",
            "\t\tTrain step - Step 2940, Loss 0.012325833551585674\n",
            "\t\tTrain step - Step 2970, Loss 0.01572982221841812\n",
            "\t\tTrain step - Step 3000, Loss 0.016450971364974976\n",
            "\t\tTrain step - Step 3030, Loss 0.017579657956957817\n",
            "\t\tTrain step - Step 3060, Loss 0.016034763306379318\n",
            "\t\tTrain step - Step 3090, Loss 0.0187635887414217\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.015657254567641592 - Train Accuracy: 0.7132173042704626\n",
            "\t\t\tVal Loss: 0.02419718648889102 - Val Accuracy: 0.56275\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 3120, Loss 0.015721628442406654\n",
            "\t\tTrain step - Step 3150, Loss 0.01536891795694828\n",
            "\t\tTrain step - Step 3180, Loss 0.015907930210232735\n",
            "\t\tTrain step - Step 3210, Loss 0.016727618873119354\n",
            "\t\tTrain step - Step 3240, Loss 0.017179112881422043\n",
            "\t\tTrain step - Step 3270, Loss 0.016933856531977654\n",
            "\t\tTrain step - Step 3300, Loss 0.01668928936123848\n",
            "\t\tTrain step - Step 3330, Loss 0.014573533087968826\n",
            "\t\tTrain step - Step 3360, Loss 0.0159626267850399\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.015480158489290293 - Train Accuracy: 0.7140235765124555\n",
            "\t\t\tVal Loss: 0.023157529067248106 - Val Accuracy: 0.5735\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 3390, Loss 0.012385542504489422\n",
            "\t\tTrain step - Step 3420, Loss 0.01280459389090538\n",
            "\t\tTrain step - Step 3450, Loss 0.015021457336843014\n",
            "\t\tTrain step - Step 3480, Loss 0.01826879195868969\n",
            "\t\tTrain step - Step 3510, Loss 0.013567709363996983\n",
            "\t\tTrain step - Step 3540, Loss 0.014079628512263298\n",
            "\t\tTrain step - Step 3570, Loss 0.014213882386684418\n",
            "\t\tTrain step - Step 3600, Loss 0.015236527658998966\n",
            "\t\tTrain step - Step 3630, Loss 0.016042394563555717\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.015456391756963051 - Train Accuracy: 0.7164145907473309\n",
            "\t\t\tVal Loss: 0.02239029054180719 - Val Accuracy: 0.5865\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 3660, Loss 0.014201679266989231\n",
            "\t\tTrain step - Step 3690, Loss 0.014784758910536766\n",
            "\t\tTrain step - Step 3720, Loss 0.014003920368850231\n",
            "\t\tTrain step - Step 3750, Loss 0.015227660536766052\n",
            "\t\tTrain step - Step 3780, Loss 0.018433479592204094\n",
            "\t\tTrain step - Step 3810, Loss 0.01625794544816017\n",
            "\t\tTrain step - Step 3840, Loss 0.01471697073429823\n",
            "\t\tTrain step - Step 3870, Loss 0.016337275505065918\n",
            "\t\tTrain step - Step 3900, Loss 0.0167348962277174\n",
            "\t\tTrain step - Step 3930, Loss 0.01576520875096321\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.015467955031534955 - Train Accuracy: 0.7178325177935944\n",
            "\t\t\tVal Loss: 0.024528645095415413 - Val Accuracy: 0.55575\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 3960, Loss 0.013522067107260227\n",
            "\t\tTrain step - Step 3990, Loss 0.013937070034444332\n",
            "\t\tTrain step - Step 4020, Loss 0.017484353855252266\n",
            "\t\tTrain step - Step 4050, Loss 0.017816537991166115\n",
            "\t\tTrain step - Step 4080, Loss 0.012647585943341255\n",
            "\t\tTrain step - Step 4110, Loss 0.013904726132750511\n",
            "\t\tTrain step - Step 4140, Loss 0.018326563760638237\n",
            "\t\tTrain step - Step 4170, Loss 0.0137814125046134\n",
            "\t\tTrain step - Step 4200, Loss 0.013388234190642834\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.015480606120702846 - Train Accuracy: 0.7145518238434164\n",
            "\t\t\tVal Loss: 0.022738970306818374 - Val Accuracy: 0.59275\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 4230, Loss 0.017691057175397873\n",
            "\t\tTrain step - Step 4260, Loss 0.01574273593723774\n",
            "\t\tTrain step - Step 4290, Loss 0.012724177911877632\n",
            "\t\tTrain step - Step 4320, Loss 0.016149912029504776\n",
            "\t\tTrain step - Step 4350, Loss 0.013802437111735344\n",
            "\t\tTrain step - Step 4380, Loss 0.016626382246613503\n",
            "\t\tTrain step - Step 4410, Loss 0.015682730823755264\n",
            "\t\tTrain step - Step 4440, Loss 0.01572457328438759\n",
            "\t\tTrain step - Step 4470, Loss 0.014908179640769958\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.015205064225027145 - Train Accuracy: 0.7194450622775801\n",
            "\t\t\tVal Loss: 0.02473492143326439 - Val Accuracy: 0.5515\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 4500, Loss 0.015218748711049557\n",
            "\t\tTrain step - Step 4530, Loss 0.012653999030590057\n",
            "\t\tTrain step - Step 4560, Loss 0.01670101098716259\n",
            "\t\tTrain step - Step 4590, Loss 0.014827127568423748\n",
            "\t\tTrain step - Step 4620, Loss 0.01865125633776188\n",
            "\t\tTrain step - Step 4650, Loss 0.014090489596128464\n",
            "\t\tTrain step - Step 4680, Loss 0.014680900610983372\n",
            "\t\tTrain step - Step 4710, Loss 0.016770144924521446\n",
            "\t\tTrain step - Step 4740, Loss 0.015985915437340736\n",
            "\t\tTrain step - Step 4770, Loss 0.01589273102581501\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.015484419001723735 - Train Accuracy: 0.7133563167259787\n",
            "\t\t\tVal Loss: 0.022944549535168335 - Val Accuracy: 0.58175\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 4800, Loss 0.01572467014193535\n",
            "\t\tTrain step - Step 4830, Loss 0.01422928087413311\n",
            "\t\tTrain step - Step 4860, Loss 0.013745482079684734\n",
            "\t\tTrain step - Step 4890, Loss 0.015031306073069572\n",
            "\t\tTrain step - Step 4920, Loss 0.015371489338576794\n",
            "\t\tTrain step - Step 4950, Loss 0.012348760850727558\n",
            "\t\tTrain step - Step 4980, Loss 0.014813155867159367\n",
            "\t\tTrain step - Step 5010, Loss 0.01742877997457981\n",
            "\t\tTrain step - Step 5040, Loss 0.015417832881212234\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.015287161821307236 - Train Accuracy: 0.7186665925266904\n",
            "\t\t\tVal Loss: 0.022957526860409416 - Val Accuracy: 0.57775\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 5070, Loss 0.015372034162282944\n",
            "\t\tTrain step - Step 5100, Loss 0.012968732975423336\n",
            "\t\tTrain step - Step 5130, Loss 0.014073152095079422\n",
            "\t\tTrain step - Step 5160, Loss 0.012925097718834877\n",
            "\t\tTrain step - Step 5190, Loss 0.01218500081449747\n",
            "\t\tTrain step - Step 5220, Loss 0.015876853838562965\n",
            "\t\tTrain step - Step 5250, Loss 0.015496165491640568\n",
            "\t\tTrain step - Step 5280, Loss 0.017914623022079468\n",
            "\t\tTrain step - Step 5310, Loss 0.01531985867768526\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.015303285756012511 - Train Accuracy: 0.7184997775800712\n",
            "\t\t\tVal Loss: 0.0246375240967609 - Val Accuracy: 0.56925\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 5340, Loss 0.014124211855232716\n",
            "\t\tTrain step - Step 5370, Loss 0.017690293490886688\n",
            "\t\tTrain step - Step 5400, Loss 0.014665527269244194\n",
            "\t\tTrain step - Step 5430, Loss 0.015107636339962482\n",
            "\t\tTrain step - Step 5460, Loss 0.017568623647093773\n",
            "\t\tTrain step - Step 5490, Loss 0.015262503176927567\n",
            "\t\tTrain step - Step 5520, Loss 0.015030687674880028\n",
            "\t\tTrain step - Step 5550, Loss 0.015403054654598236\n",
            "\t\tTrain step - Step 5580, Loss 0.014716618694365025\n",
            "\t\tTrain step - Step 5610, Loss 0.01677059568464756\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.015106634134128424 - Train Accuracy: 0.7196674822064056\n",
            "\t\t\tVal Loss: 0.021876489801798016 - Val Accuracy: 0.58975\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 5640, Loss 0.014006149023771286\n",
            "\t\tTrain step - Step 5670, Loss 0.014845078811049461\n",
            "\t\tTrain step - Step 5700, Loss 0.013742019422352314\n",
            "\t\tTrain step - Step 5730, Loss 0.01316208578646183\n",
            "\t\tTrain step - Step 5760, Loss 0.014575541019439697\n",
            "\t\tTrain step - Step 5790, Loss 0.012057543732225895\n",
            "\t\tTrain step - Step 5820, Loss 0.01687779650092125\n",
            "\t\tTrain step - Step 5850, Loss 0.016398681327700615\n",
            "\t\tTrain step - Step 5880, Loss 0.018203148618340492\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.015146588886759883 - Train Accuracy: 0.7208907918149466\n",
            "\t\t\tVal Loss: 0.02437210365314968 - Val Accuracy: 0.5585\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 5910, Loss 0.018841903656721115\n",
            "\t\tTrain step - Step 5940, Loss 0.01738481968641281\n",
            "\t\tTrain step - Step 5970, Loss 0.015090364962816238\n",
            "\t\tTrain step - Step 6000, Loss 0.015207449905574322\n",
            "\t\tTrain step - Step 6030, Loss 0.016511444002389908\n",
            "\t\tTrain step - Step 6060, Loss 0.015881342813372612\n",
            "\t\tTrain step - Step 6090, Loss 0.015439944341778755\n",
            "\t\tTrain step - Step 6120, Loss 0.013650350272655487\n",
            "\t\tTrain step - Step 6150, Loss 0.015369969420135021\n",
            "\t\tTrain step - Step 6180, Loss 0.014276244677603245\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.01516553304850843 - Train Accuracy: 0.7235876334519573\n",
            "\t\t\tVal Loss: 0.023591289558680728 - Val Accuracy: 0.57025\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 6210, Loss 0.013469074852764606\n",
            "\t\tTrain step - Step 6240, Loss 0.014325401745736599\n",
            "\t\tTrain step - Step 6270, Loss 0.01720208115875721\n",
            "\t\tTrain step - Step 6300, Loss 0.015042134560644627\n",
            "\t\tTrain step - Step 6330, Loss 0.014663156121969223\n",
            "\t\tTrain step - Step 6360, Loss 0.017020752653479576\n",
            "\t\tTrain step - Step 6390, Loss 0.015253229066729546\n",
            "\t\tTrain step - Step 6420, Loss 0.015864340588450432\n",
            "\t\tTrain step - Step 6450, Loss 0.015523508191108704\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.015172595184733859 - Train Accuracy: 0.720668371886121\n",
            "\t\t\tVal Loss: 0.024672329425811768 - Val Accuracy: 0.5545\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 6480, Loss 0.01594565063714981\n",
            "\t\tTrain step - Step 6510, Loss 0.015690913423895836\n",
            "\t\tTrain step - Step 6540, Loss 0.01387129258364439\n",
            "\t\tTrain step - Step 6570, Loss 0.013015184551477432\n",
            "\t\tTrain step - Step 6600, Loss 0.015221592970192432\n",
            "\t\tTrain step - Step 6630, Loss 0.013670239597558975\n",
            "\t\tTrain step - Step 6660, Loss 0.012842617928981781\n",
            "\t\tTrain step - Step 6690, Loss 0.017327306792140007\n",
            "\t\tTrain step - Step 6720, Loss 0.014207611791789532\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.015210998907446649 - Train Accuracy: 0.7203347419928826\n",
            "\t\t\tVal Loss: 0.024139754386851564 - Val Accuracy: 0.55825\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 6750, Loss 0.018271582201123238\n",
            "\t\tTrain step - Step 6780, Loss 0.011787787079811096\n",
            "\t\tTrain step - Step 6810, Loss 0.015738120302557945\n",
            "\t\tTrain step - Step 6840, Loss 0.017498930916190147\n",
            "\t\tTrain step - Step 6870, Loss 0.014706284739077091\n",
            "\t\tTrain step - Step 6900, Loss 0.015141853131353855\n",
            "\t\tTrain step - Step 6930, Loss 0.016922060400247574\n",
            "\t\tTrain step - Step 6960, Loss 0.014130000956356525\n",
            "\t\tTrain step - Step 6990, Loss 0.015506252646446228\n",
            "\t\tTrain step - Step 7020, Loss 0.014644192531704903\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.015086827822878054 - Train Accuracy: 0.7228369661921709\n",
            "\t\t\tVal Loss: 0.02139787026681006 - Val Accuracy: 0.616\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 7050, Loss 0.016878819093108177\n",
            "\t\tTrain step - Step 7080, Loss 0.01537497527897358\n",
            "\t\tTrain step - Step 7110, Loss 0.015500560402870178\n",
            "\t\tTrain step - Step 7140, Loss 0.017972081899642944\n",
            "\t\tTrain step - Step 7170, Loss 0.01654517464339733\n",
            "\t\tTrain step - Step 7200, Loss 0.015453802421689034\n",
            "\t\tTrain step - Step 7230, Loss 0.012651150114834309\n",
            "\t\tTrain step - Step 7260, Loss 0.015361370518803596\n",
            "\t\tTrain step - Step 7290, Loss 0.015626324340701103\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.014982220438371985 - Train Accuracy: 0.7278136120996441\n",
            "\t\t\tVal Loss: 0.024072202562820166 - Val Accuracy: 0.5585\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 7320, Loss 0.014594882726669312\n",
            "\t\tTrain step - Step 7350, Loss 0.013654975220561028\n",
            "\t\tTrain step - Step 7380, Loss 0.014332300052046776\n",
            "\t\tTrain step - Step 7410, Loss 0.014490210451185703\n",
            "\t\tTrain step - Step 7440, Loss 0.014423193410038948\n",
            "\t\tTrain step - Step 7470, Loss 0.015639670193195343\n",
            "\t\tTrain step - Step 7500, Loss 0.01634383574128151\n",
            "\t\tTrain step - Step 7530, Loss 0.016215123236179352\n",
            "\t\tTrain step - Step 7560, Loss 0.014092483557760715\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.015147051919795228 - Train Accuracy: 0.7221975088967971\n",
            "\t\t\tVal Loss: 0.023862271307734773 - Val Accuracy: 0.574\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 7590, Loss 0.01546148955821991\n",
            "\t\tTrain step - Step 7620, Loss 0.014629739336669445\n",
            "\t\tTrain step - Step 7650, Loss 0.013189067132771015\n",
            "\t\tTrain step - Step 7680, Loss 0.018135422840714455\n",
            "\t\tTrain step - Step 7710, Loss 0.01701478846371174\n",
            "\t\tTrain step - Step 7740, Loss 0.01728779636323452\n",
            "\t\tTrain step - Step 7770, Loss 0.013599824160337448\n",
            "\t\tTrain step - Step 7800, Loss 0.01736444979906082\n",
            "\t\tTrain step - Step 7830, Loss 0.017021914944052696\n",
            "\t\tTrain step - Step 7860, Loss 0.015221254900097847\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.015016468904673841 - Train Accuracy: 0.7233930160142349\n",
            "\t\t\tVal Loss: 0.022152770485263318 - Val Accuracy: 0.58775\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 7890, Loss 0.011819128878414631\n",
            "\t\tTrain step - Step 7920, Loss 0.011707011610269547\n",
            "\t\tTrain step - Step 7950, Loss 0.015045251697301865\n",
            "\t\tTrain step - Step 7980, Loss 0.012971539050340652\n",
            "\t\tTrain step - Step 8010, Loss 0.015468209981918335\n",
            "\t\tTrain step - Step 8040, Loss 0.013799850828945637\n",
            "\t\tTrain step - Step 8070, Loss 0.013752584345638752\n",
            "\t\tTrain step - Step 8100, Loss 0.014352676458656788\n",
            "\t\tTrain step - Step 8130, Loss 0.013879291713237762\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.015001677235197342 - Train Accuracy: 0.7256450177935944\n",
            "\t\t\tVal Loss: 0.022737467661499977 - Val Accuracy: 0.56925\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 8160, Loss 0.014184259809553623\n",
            "\t\tTrain step - Step 8190, Loss 0.013398612849414349\n",
            "\t\tTrain step - Step 8220, Loss 0.014543311670422554\n",
            "\t\tTrain step - Step 8250, Loss 0.014120206236839294\n",
            "\t\tTrain step - Step 8280, Loss 0.015772931277751923\n",
            "\t\tTrain step - Step 8310, Loss 0.01996539905667305\n",
            "\t\tTrain step - Step 8340, Loss 0.013977502472698689\n",
            "\t\tTrain step - Step 8370, Loss 0.014117059297859669\n",
            "\t\tTrain step - Step 8400, Loss 0.01868709735572338\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.01504885683373094 - Train Accuracy: 0.7247553380782918\n",
            "\t\t\tVal Loss: 0.021935124677838758 - Val Accuracy: 0.59075\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 8430, Loss 0.017045559361577034\n",
            "\t\tTrain step - Step 8460, Loss 0.014363586902618408\n",
            "\t\tTrain step - Step 8490, Loss 0.011871776543557644\n",
            "\t\tTrain step - Step 8520, Loss 0.016322951763868332\n",
            "\t\tTrain step - Step 8550, Loss 0.013730408623814583\n",
            "\t\tTrain step - Step 8580, Loss 0.015015850774943829\n",
            "\t\tTrain step - Step 8610, Loss 0.015068690292537212\n",
            "\t\tTrain step - Step 8640, Loss 0.012497167102992535\n",
            "\t\tTrain step - Step 8670, Loss 0.013410715386271477\n",
            "\t\tTrain step - Step 8700, Loss 0.016175124794244766\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.014898112003966582 - Train Accuracy: 0.7264790925266904\n",
            "\t\t\tVal Loss: 0.021627229725709185 - Val Accuracy: 0.60025\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 8730, Loss 0.013200216926634312\n",
            "\t\tTrain step - Step 8760, Loss 0.013990412466228008\n",
            "\t\tTrain step - Step 8790, Loss 0.017893018200993538\n",
            "\t\tTrain step - Step 8820, Loss 0.01451544463634491\n",
            "\t\tTrain step - Step 8850, Loss 0.013790737837553024\n",
            "\t\tTrain step - Step 8880, Loss 0.018237832933664322\n",
            "\t\tTrain step - Step 8910, Loss 0.017396649345755577\n",
            "\t\tTrain step - Step 8940, Loss 0.015076996758580208\n",
            "\t\tTrain step - Step 8970, Loss 0.016704199835658073\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.014858462330736087 - Train Accuracy: 0.7239768683274022\n",
            "\t\t\tVal Loss: 0.023231179045978934 - Val Accuracy: 0.5655\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 9000, Loss 0.015646109357476234\n",
            "\t\tTrain step - Step 9030, Loss 0.013569330796599388\n",
            "\t\tTrain step - Step 9060, Loss 0.016888970509171486\n",
            "\t\tTrain step - Step 9090, Loss 0.01467833761125803\n",
            "\t\tTrain step - Step 9120, Loss 0.01916465349495411\n",
            "\t\tTrain step - Step 9150, Loss 0.01733197644352913\n",
            "\t\tTrain step - Step 9180, Loss 0.012594987638294697\n",
            "\t\tTrain step - Step 9210, Loss 0.015959328040480614\n",
            "\t\tTrain step - Step 9240, Loss 0.016046136617660522\n",
            "\t\tTrain step - Step 9270, Loss 0.017516471445560455\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.014886090830233598 - Train Accuracy: 0.7255616103202847\n",
            "\t\t\tVal Loss: 0.022243669838644564 - Val Accuracy: 0.59375\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 9300, Loss 0.013688583858311176\n",
            "\t\tTrain step - Step 9330, Loss 0.014598582871258259\n",
            "\t\tTrain step - Step 9360, Loss 0.01802411675453186\n",
            "\t\tTrain step - Step 9390, Loss 0.014035822823643684\n",
            "\t\tTrain step - Step 9420, Loss 0.0123590724542737\n",
            "\t\tTrain step - Step 9450, Loss 0.016833916306495667\n",
            "\t\tTrain step - Step 9480, Loss 0.01819508709013462\n",
            "\t\tTrain step - Step 9510, Loss 0.015021245926618576\n",
            "\t\tTrain step - Step 9540, Loss 0.01465196255594492\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.014803199230086762 - Train Accuracy: 0.7299266014234875\n",
            "\t\t\tVal Loss: 0.024479764222633094 - Val Accuracy: 0.564\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 9570, Loss 0.010391993448138237\n",
            "\t\tTrain step - Step 9600, Loss 0.015716716647148132\n",
            "\t\tTrain step - Step 9630, Loss 0.012439836747944355\n",
            "\t\tTrain step - Step 9660, Loss 0.013388571329414845\n",
            "\t\tTrain step - Step 9690, Loss 0.013674844987690449\n",
            "\t\tTrain step - Step 9720, Loss 0.01712397113442421\n",
            "\t\tTrain step - Step 9750, Loss 0.01215673889964819\n",
            "\t\tTrain step - Step 9780, Loss 0.015949949622154236\n",
            "\t\tTrain step - Step 9810, Loss 0.016318485140800476\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.014886256552622835 - Train Accuracy: 0.7278692170818505\n",
            "\t\t\tVal Loss: 0.023411773523548618 - Val Accuracy: 0.571\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 9840, Loss 0.01282101683318615\n",
            "\t\tTrain step - Step 9870, Loss 0.014028441160917282\n",
            "\t\tTrain step - Step 9900, Loss 0.013910111971199512\n",
            "\t\tTrain step - Step 9930, Loss 0.011972593143582344\n",
            "\t\tTrain step - Step 9960, Loss 0.0145207354798913\n",
            "\t\tTrain step - Step 9990, Loss 0.015814730897545815\n",
            "\t\tTrain step - Step 10020, Loss 0.01592092588543892\n",
            "\t\tTrain step - Step 10050, Loss 0.015253514982759953\n",
            "\t\tTrain step - Step 10080, Loss 0.01474750880151987\n",
            "\t\tTrain step - Step 10110, Loss 0.0172024704515934\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.014824327870248899 - Train Accuracy: 0.7289813167259787\n",
            "\t\t\tVal Loss: 0.02525404017069377 - Val Accuracy: 0.55875\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 10140, Loss 0.013911530375480652\n",
            "\t\tTrain step - Step 10170, Loss 0.01319802924990654\n",
            "\t\tTrain step - Step 10200, Loss 0.014761428348720074\n",
            "\t\tTrain step - Step 10230, Loss 0.015581334941089153\n",
            "\t\tTrain step - Step 10260, Loss 0.018429407849907875\n",
            "\t\tTrain step - Step 10290, Loss 0.016591666266322136\n",
            "\t\tTrain step - Step 10320, Loss 0.015491681173443794\n",
            "\t\tTrain step - Step 10350, Loss 0.014806992374360561\n",
            "\t\tTrain step - Step 10380, Loss 0.016704097390174866\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.014790307902780716 - Train Accuracy: 0.7305660587188612\n",
            "\t\t\tVal Loss: 0.022081796661950648 - Val Accuracy: 0.60325\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 10410, Loss 0.01582488976418972\n",
            "\t\tTrain step - Step 10440, Loss 0.01724209263920784\n",
            "\t\tTrain step - Step 10470, Loss 0.016028985381126404\n",
            "\t\tTrain step - Step 10500, Loss 0.013943635858595371\n",
            "\t\tTrain step - Step 10530, Loss 0.01774831861257553\n",
            "\t\tTrain step - Step 10560, Loss 0.013277179561555386\n",
            "\t\tTrain step - Step 10590, Loss 0.014829508028924465\n",
            "\t\tTrain step - Step 10620, Loss 0.012415985576808453\n",
            "\t\tTrain step - Step 10650, Loss 0.015346052125096321\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.014953872285040885 - Train Accuracy: 0.7244495106761566\n",
            "\t\t\tVal Loss: 0.022522431128891185 - Val Accuracy: 0.58375\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 10680, Loss 0.013764653354883194\n",
            "\t\tTrain step - Step 10710, Loss 0.01318007055670023\n",
            "\t\tTrain step - Step 10740, Loss 0.016796093434095383\n",
            "\t\tTrain step - Step 10770, Loss 0.016136491671204567\n",
            "\t\tTrain step - Step 10800, Loss 0.014053372666239738\n",
            "\t\tTrain step - Step 10830, Loss 0.01589580811560154\n",
            "\t\tTrain step - Step 10860, Loss 0.01761074922978878\n",
            "\t\tTrain step - Step 10890, Loss 0.013105759397149086\n",
            "\t\tTrain step - Step 10920, Loss 0.019008824601769447\n",
            "\t\tTrain step - Step 10950, Loss 0.015345442108809948\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.01478371923968355 - Train Accuracy: 0.7277302046263345\n",
            "\t\t\tVal Loss: 0.021364430023822933 - Val Accuracy: 0.61125\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 10980, Loss 0.013048007152974606\n",
            "\t\tTrain step - Step 11010, Loss 0.012962650507688522\n",
            "\t\tTrain step - Step 11040, Loss 0.01582355611026287\n",
            "\t\tTrain step - Step 11070, Loss 0.015203437767922878\n",
            "\t\tTrain step - Step 11100, Loss 0.015359855256974697\n",
            "\t\tTrain step - Step 11130, Loss 0.014672758057713509\n",
            "\t\tTrain step - Step 11160, Loss 0.015406955033540726\n",
            "\t\tTrain step - Step 11190, Loss 0.01622975617647171\n",
            "\t\tTrain step - Step 11220, Loss 0.013924817554652691\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.014771374340212218 - Train Accuracy: 0.7285364768683275\n",
            "\t\t\tVal Loss: 0.022959806956350803 - Val Accuracy: 0.57575\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 11250, Loss 0.014144571498036385\n",
            "\t\tTrain step - Step 11280, Loss 0.012836136855185032\n",
            "\t\tTrain step - Step 11310, Loss 0.01126091182231903\n",
            "\t\tTrain step - Step 11340, Loss 0.01341457199305296\n",
            "\t\tTrain step - Step 11370, Loss 0.014106521382927895\n",
            "\t\tTrain step - Step 11400, Loss 0.014890210703015327\n",
            "\t\tTrain step - Step 11430, Loss 0.016433855518698692\n",
            "\t\tTrain step - Step 11460, Loss 0.015865018591284752\n",
            "\t\tTrain step - Step 11490, Loss 0.014292093925178051\n",
            "\t\tTrain step - Step 11520, Loss 0.01620491035282612\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.014707438359401616 - Train Accuracy: 0.7311499110320284\n",
            "\t\t\tVal Loss: 0.021833706850884482 - Val Accuracy: 0.59725\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 11550, Loss 0.01071659941226244\n",
            "\t\tTrain step - Step 11580, Loss 0.0157220046967268\n",
            "\t\tTrain step - Step 11610, Loss 0.013694346882402897\n",
            "\t\tTrain step - Step 11640, Loss 0.014219919219613075\n",
            "\t\tTrain step - Step 11670, Loss 0.015319105237722397\n",
            "\t\tTrain step - Step 11700, Loss 0.015315495431423187\n",
            "\t\tTrain step - Step 11730, Loss 0.016667919233441353\n",
            "\t\tTrain step - Step 11760, Loss 0.016310250386595726\n",
            "\t\tTrain step - Step 11790, Loss 0.01827879622578621\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.014664525868788733 - Train Accuracy: 0.7335131227758007\n",
            "\t\t\tVal Loss: 0.025242137839086354 - Val Accuracy: 0.55025\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 11820, Loss 0.011647208593785763\n",
            "\t\tTrain step - Step 11850, Loss 0.012565180659294128\n",
            "\t\tTrain step - Step 11880, Loss 0.013583259657025337\n",
            "\t\tTrain step - Step 11910, Loss 0.013768421486020088\n",
            "\t\tTrain step - Step 11940, Loss 0.01520467922091484\n",
            "\t\tTrain step - Step 11970, Loss 0.017385799437761307\n",
            "\t\tTrain step - Step 12000, Loss 0.01413316372781992\n",
            "\t\tTrain step - Step 12030, Loss 0.016336530447006226\n",
            "\t\tTrain step - Step 12060, Loss 0.01333692017942667\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.014682151871034046 - Train Accuracy: 0.7293983540925267\n",
            "\t\t\tVal Loss: 0.022751649958081543 - Val Accuracy: 0.5935\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 12090, Loss 0.014404408633708954\n",
            "\t\tTrain step - Step 12120, Loss 0.012496800161898136\n",
            "\t\tTrain step - Step 12150, Loss 0.012601980939507484\n",
            "\t\tTrain step - Step 12180, Loss 0.015413356944918633\n",
            "\t\tTrain step - Step 12210, Loss 0.012000860646367073\n",
            "\t\tTrain step - Step 12240, Loss 0.014332907274365425\n",
            "\t\tTrain step - Step 12270, Loss 0.014739817939698696\n",
            "\t\tTrain step - Step 12300, Loss 0.014122100546956062\n",
            "\t\tTrain step - Step 12330, Loss 0.016166578978300095\n",
            "\t\tTrain step - Step 12360, Loss 0.01644202135503292\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.014659042539757765 - Train Accuracy: 0.7295095640569395\n",
            "\t\t\tVal Loss: 0.023477403534343466 - Val Accuracy: 0.57825\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 12390, Loss 0.012933948077261448\n",
            "\t\tTrain step - Step 12420, Loss 0.015291444957256317\n",
            "\t\tTrain step - Step 12450, Loss 0.014067260548472404\n",
            "\t\tTrain step - Step 12480, Loss 0.014947171323001385\n",
            "\t\tTrain step - Step 12510, Loss 0.015887314453721046\n",
            "\t\tTrain step - Step 12540, Loss 0.015255515463650227\n",
            "\t\tTrain step - Step 12570, Loss 0.014423281885683537\n",
            "\t\tTrain step - Step 12600, Loss 0.015188640914857388\n",
            "\t\tTrain step - Step 12630, Loss 0.014638041146099567\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.014806766321491516 - Train Accuracy: 0.7296207740213523\n",
            "\t\t\tVal Loss: 0.023291469260584563 - Val Accuracy: 0.5905\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 12660, Loss 0.013553774915635586\n",
            "\t\tTrain step - Step 12690, Loss 0.01263086311519146\n",
            "\t\tTrain step - Step 12720, Loss 0.013554994948208332\n",
            "\t\tTrain step - Step 12750, Loss 0.014646352268755436\n",
            "\t\tTrain step - Step 12780, Loss 0.01308080181479454\n",
            "\t\tTrain step - Step 12810, Loss 0.015980059280991554\n",
            "\t\tTrain step - Step 12840, Loss 0.01608327217400074\n",
            "\t\tTrain step - Step 12870, Loss 0.016389260068535805\n",
            "\t\tTrain step - Step 12900, Loss 0.013531350530683994\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.014648771387428788 - Train Accuracy: 0.7345418149466192\n",
            "\t\t\tVal Loss: 0.02392980837612413 - Val Accuracy: 0.5635\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 12930, Loss 0.014273515902459621\n",
            "\t\tTrain step - Step 12960, Loss 0.014315526932477951\n",
            "\t\tTrain step - Step 12990, Loss 0.013612820766866207\n",
            "\t\tTrain step - Step 13020, Loss 0.015269279479980469\n",
            "\t\tTrain step - Step 13050, Loss 0.0164044126868248\n",
            "\t\tTrain step - Step 13080, Loss 0.010698378086090088\n",
            "\t\tTrain step - Step 13110, Loss 0.014652466401457787\n",
            "\t\tTrain step - Step 13140, Loss 0.01592518575489521\n",
            "\t\tTrain step - Step 13170, Loss 0.014427990652620792\n",
            "\t\tTrain step - Step 13200, Loss 0.015146338380873203\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.01466036776538103 - Train Accuracy: 0.7304548487544484\n",
            "\t\t\tVal Loss: 0.02359875405090861 - Val Accuracy: 0.573\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 13230, Loss 0.01721494272351265\n",
            "\t\tTrain step - Step 13260, Loss 0.011792277917265892\n",
            "\t\tTrain step - Step 13290, Loss 0.01259956881403923\n",
            "\t\tTrain step - Step 13320, Loss 0.01355763804167509\n",
            "\t\tTrain step - Step 13350, Loss 0.016191594302654266\n",
            "\t\tTrain step - Step 13380, Loss 0.014391223900020123\n",
            "\t\tTrain step - Step 13410, Loss 0.01789398118853569\n",
            "\t\tTrain step - Step 13440, Loss 0.013746530748903751\n",
            "\t\tTrain step - Step 13470, Loss 0.014048297889530659\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.01470444958948686 - Train Accuracy: 0.7308996886120996\n",
            "\t\t\tVal Loss: 0.02190962969325483 - Val Accuracy: 0.60325\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 13500, Loss 0.014537987299263477\n",
            "\t\tTrain step - Step 13530, Loss 0.012186088599264622\n",
            "\t\tTrain step - Step 13560, Loss 0.01420143898576498\n",
            "\t\tTrain step - Step 13590, Loss 0.014864764176309109\n",
            "\t\tTrain step - Step 13620, Loss 0.012065095826983452\n",
            "\t\tTrain step - Step 13650, Loss 0.016953080892562866\n",
            "\t\tTrain step - Step 13680, Loss 0.01232223678380251\n",
            "\t\tTrain step - Step 13710, Loss 0.011709551326930523\n",
            "\t\tTrain step - Step 13740, Loss 0.01646522432565689\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.01470463093555801 - Train Accuracy: 0.73012121886121\n",
            "\t\t\tVal Loss: 0.02323147776769474 - Val Accuracy: 0.56875\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 13770, Loss 0.015089745633304119\n",
            "\t\tTrain step - Step 13800, Loss 0.011668307706713676\n",
            "\t\tTrain step - Step 13830, Loss 0.010333623737096786\n",
            "\t\tTrain step - Step 13860, Loss 0.010266824625432491\n",
            "\t\tTrain step - Step 13890, Loss 0.013263806700706482\n",
            "\t\tTrain step - Step 13920, Loss 0.008058886043727398\n",
            "\t\tTrain step - Step 13950, Loss 0.009234175086021423\n",
            "\t\tTrain step - Step 13980, Loss 0.008908952586352825\n",
            "\t\tTrain step - Step 14010, Loss 0.009670029394328594\n",
            "\t\tTrain step - Step 14040, Loss 0.009866956621408463\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.010497678535264583 - Train Accuracy: 0.8202290925266904\n",
            "\t\t\tVal Loss: 0.016269889383693226 - Val Accuracy: 0.70275\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 14070, Loss 0.010495596565306187\n",
            "\t\tTrain step - Step 14100, Loss 0.008996271528303623\n",
            "\t\tTrain step - Step 14130, Loss 0.0077894870191812515\n",
            "\t\tTrain step - Step 14160, Loss 0.008035233244299889\n",
            "\t\tTrain step - Step 14190, Loss 0.00867167767137289\n",
            "\t\tTrain step - Step 14220, Loss 0.008988354355096817\n",
            "\t\tTrain step - Step 14250, Loss 0.008009654469788074\n",
            "\t\tTrain step - Step 14280, Loss 0.009433608502149582\n",
            "\t\tTrain step - Step 14310, Loss 0.008414472453296185\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.009284107949173748 - Train Accuracy: 0.8435831850533808\n",
            "\t\t\tVal Loss: 0.016741450526751578 - Val Accuracy: 0.692\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 14340, Loss 0.009075144305825233\n",
            "\t\tTrain step - Step 14370, Loss 0.00955954845994711\n",
            "\t\tTrain step - Step 14400, Loss 0.010164964012801647\n",
            "\t\tTrain step - Step 14430, Loss 0.009144793264567852\n",
            "\t\tTrain step - Step 14460, Loss 0.008595404215157032\n",
            "\t\tTrain step - Step 14490, Loss 0.009165724739432335\n",
            "\t\tTrain step - Step 14520, Loss 0.008776327595114708\n",
            "\t\tTrain step - Step 14550, Loss 0.007090943865478039\n",
            "\t\tTrain step - Step 14580, Loss 0.008978232741355896\n",
            "\t\tTrain step - Step 14610, Loss 0.009180638939142227\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.008702687818053247 - Train Accuracy: 0.853341859430605\n",
            "\t\t\tVal Loss: 0.016517279276740737 - Val Accuracy: 0.70275\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 14640, Loss 0.0074834153056144714\n",
            "\t\tTrain step - Step 14670, Loss 0.011146007105708122\n",
            "\t\tTrain step - Step 14700, Loss 0.00958419032394886\n",
            "\t\tTrain step - Step 14730, Loss 0.00869829673320055\n",
            "\t\tTrain step - Step 14760, Loss 0.008017203770577908\n",
            "\t\tTrain step - Step 14790, Loss 0.009150856174528599\n",
            "\t\tTrain step - Step 14820, Loss 0.007307619787752628\n",
            "\t\tTrain step - Step 14850, Loss 0.006491832435131073\n",
            "\t\tTrain step - Step 14880, Loss 0.009383516386151314\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.008420400285026145 - Train Accuracy: 0.8589023576512456\n",
            "\t\t\tVal Loss: 0.01656171136710327 - Val Accuracy: 0.70825\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 14910, Loss 0.00803589541465044\n",
            "\t\tTrain step - Step 14940, Loss 0.008807561360299587\n",
            "\t\tTrain step - Step 14970, Loss 0.008561024442315102\n",
            "\t\tTrain step - Step 15000, Loss 0.008169891312718391\n",
            "\t\tTrain step - Step 15030, Loss 0.007910970598459244\n",
            "\t\tTrain step - Step 15060, Loss 0.006906077265739441\n",
            "\t\tTrain step - Step 15090, Loss 0.008871868252754211\n",
            "\t\tTrain step - Step 15120, Loss 0.008968542329967022\n",
            "\t\tTrain step - Step 15150, Loss 0.008539928123354912\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.008095184104099498 - Train Accuracy: 0.8645740658362989\n",
            "\t\t\tVal Loss: 0.01669706941174809 - Val Accuracy: 0.6975\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 15180, Loss 0.008315694518387318\n",
            "\t\tTrain step - Step 15210, Loss 0.006588272284716368\n",
            "\t\tTrain step - Step 15240, Loss 0.007483322639018297\n",
            "\t\tTrain step - Step 15270, Loss 0.006998786702752113\n",
            "\t\tTrain step - Step 15300, Loss 0.008957996964454651\n",
            "\t\tTrain step - Step 15330, Loss 0.006618887651711702\n",
            "\t\tTrain step - Step 15360, Loss 0.0067983353510499\n",
            "\t\tTrain step - Step 15390, Loss 0.010348350740969181\n",
            "\t\tTrain step - Step 15420, Loss 0.01104109175503254\n",
            "\t\tTrain step - Step 15450, Loss 0.00899676512926817\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.007917750114740744 - Train Accuracy: 0.8689390569395018\n",
            "\t\t\tVal Loss: 0.017114325979491696 - Val Accuracy: 0.696\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 15480, Loss 0.006788692437112331\n",
            "\t\tTrain step - Step 15510, Loss 0.006246740464121103\n",
            "\t\tTrain step - Step 15540, Loss 0.007107267156243324\n",
            "\t\tTrain step - Step 15570, Loss 0.009046744555234909\n",
            "\t\tTrain step - Step 15600, Loss 0.006292338017374277\n",
            "\t\tTrain step - Step 15630, Loss 0.007822712883353233\n",
            "\t\tTrain step - Step 15660, Loss 0.008605501614511013\n",
            "\t\tTrain step - Step 15690, Loss 0.00762160774320364\n",
            "\t\tTrain step - Step 15720, Loss 0.007288899272680283\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.00782504923528995 - Train Accuracy: 0.8709408362989324\n",
            "\t\t\tVal Loss: 0.01708077994408086 - Val Accuracy: 0.69875\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 15750, Loss 0.007989723235368729\n",
            "\t\tTrain step - Step 15780, Loss 0.0075799389742314816\n",
            "\t\tTrain step - Step 15810, Loss 0.007195622660219669\n",
            "\t\tTrain step - Step 15840, Loss 0.006780318915843964\n",
            "\t\tTrain step - Step 15870, Loss 0.010016493499279022\n",
            "\t\tTrain step - Step 15900, Loss 0.007665964309126139\n",
            "\t\tTrain step - Step 15930, Loss 0.008757012896239758\n",
            "\t\tTrain step - Step 15960, Loss 0.008320137858390808\n",
            "\t\tTrain step - Step 15990, Loss 0.00642347801476717\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.007582207266705316 - Train Accuracy: 0.8758062722419929\n",
            "\t\t\tVal Loss: 0.017082526988815516 - Val Accuracy: 0.69875\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 16020, Loss 0.008104906417429447\n",
            "\t\tTrain step - Step 16050, Loss 0.007426531054079533\n",
            "\t\tTrain step - Step 16080, Loss 0.006474102381616831\n",
            "\t\tTrain step - Step 16110, Loss 0.005097972694784403\n",
            "\t\tTrain step - Step 16140, Loss 0.007097087800502777\n",
            "\t\tTrain step - Step 16170, Loss 0.009267364628612995\n",
            "\t\tTrain step - Step 16200, Loss 0.008889610879123211\n",
            "\t\tTrain step - Step 16230, Loss 0.006850036326795816\n",
            "\t\tTrain step - Step 16260, Loss 0.008537564426660538\n",
            "\t\tTrain step - Step 16290, Loss 0.006405997090041637\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.007551519203520118 - Train Accuracy: 0.8763067170818505\n",
            "\t\t\tVal Loss: 0.017474019041401334 - Val Accuracy: 0.694\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 16320, Loss 0.007332615554332733\n",
            "\t\tTrain step - Step 16350, Loss 0.005433702375739813\n",
            "\t\tTrain step - Step 16380, Loss 0.008548274636268616\n",
            "\t\tTrain step - Step 16410, Loss 0.006274711806327105\n",
            "\t\tTrain step - Step 16440, Loss 0.006231942214071751\n",
            "\t\tTrain step - Step 16470, Loss 0.010354244150221348\n",
            "\t\tTrain step - Step 16500, Loss 0.0055367592722177505\n",
            "\t\tTrain step - Step 16530, Loss 0.007446783594787121\n",
            "\t\tTrain step - Step 16560, Loss 0.0076970299705863\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.007391230912474763 - Train Accuracy: 0.8781138790035588\n",
            "\t\t\tVal Loss: 0.017626682412810624 - Val Accuracy: 0.68975\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 16590, Loss 0.006966657470911741\n",
            "\t\tTrain step - Step 16620, Loss 0.007060556672513485\n",
            "\t\tTrain step - Step 16650, Loss 0.00855166558176279\n",
            "\t\tTrain step - Step 16680, Loss 0.008617333136498928\n",
            "\t\tTrain step - Step 16710, Loss 0.0065598264336586\n",
            "\t\tTrain step - Step 16740, Loss 0.007678023539483547\n",
            "\t\tTrain step - Step 16770, Loss 0.008812090381979942\n",
            "\t\tTrain step - Step 16800, Loss 0.008666743524372578\n",
            "\t\tTrain step - Step 16830, Loss 0.006529051344841719\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.007305013526270822 - Train Accuracy: 0.8786421263345195\n",
            "\t\t\tVal Loss: 0.017673096037469804 - Val Accuracy: 0.6935\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 16860, Loss 0.00784739013761282\n",
            "\t\tTrain step - Step 16890, Loss 0.0068895816802978516\n",
            "\t\tTrain step - Step 16920, Loss 0.005880946759134531\n",
            "\t\tTrain step - Step 16950, Loss 0.00826495885848999\n",
            "\t\tTrain step - Step 16980, Loss 0.005392725579440594\n",
            "\t\tTrain step - Step 17010, Loss 0.007941286079585552\n",
            "\t\tTrain step - Step 17040, Loss 0.00839726161211729\n",
            "\t\tTrain step - Step 17070, Loss 0.006543987896293402\n",
            "\t\tTrain step - Step 17100, Loss 0.007805727422237396\n",
            "\t\tTrain step - Step 17130, Loss 0.006692088674753904\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.00727142104746449 - Train Accuracy: 0.8820062277580071\n",
            "\t\t\tVal Loss: 0.017296486243139952 - Val Accuracy: 0.69025\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 17160, Loss 0.007384220138192177\n",
            "\t\tTrain step - Step 17190, Loss 0.0055871582590043545\n",
            "\t\tTrain step - Step 17220, Loss 0.008453589864075184\n",
            "\t\tTrain step - Step 17250, Loss 0.00695683341473341\n",
            "\t\tTrain step - Step 17280, Loss 0.00759255513548851\n",
            "\t\tTrain step - Step 17310, Loss 0.007326370105147362\n",
            "\t\tTrain step - Step 17340, Loss 0.008998817764222622\n",
            "\t\tTrain step - Step 17370, Loss 0.006920935586094856\n",
            "\t\tTrain step - Step 17400, Loss 0.008779557421803474\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.007162995752464198 - Train Accuracy: 0.8834797597864769\n",
            "\t\t\tVal Loss: 0.01858479630027432 - Val Accuracy: 0.67775\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 17430, Loss 0.006125861778855324\n",
            "\t\tTrain step - Step 17460, Loss 0.0048858714289963245\n",
            "\t\tTrain step - Step 17490, Loss 0.006014339625835419\n",
            "\t\tTrain step - Step 17520, Loss 0.008208704181015491\n",
            "\t\tTrain step - Step 17550, Loss 0.00867146160453558\n",
            "\t\tTrain step - Step 17580, Loss 0.006776995025575161\n",
            "\t\tTrain step - Step 17610, Loss 0.007855976931750774\n",
            "\t\tTrain step - Step 17640, Loss 0.00787261687219143\n",
            "\t\tTrain step - Step 17670, Loss 0.007963634096086025\n",
            "\t\tTrain step - Step 17700, Loss 0.005756651051342487\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.007113196416443141 - Train Accuracy: 0.8820618327402135\n",
            "\t\t\tVal Loss: 0.018131703924154863 - Val Accuracy: 0.69075\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 17730, Loss 0.0071984813548624516\n",
            "\t\tTrain step - Step 17760, Loss 0.006535711698234081\n",
            "\t\tTrain step - Step 17790, Loss 0.006128883454948664\n",
            "\t\tTrain step - Step 17820, Loss 0.004679979290813208\n",
            "\t\tTrain step - Step 17850, Loss 0.004957069177180529\n",
            "\t\tTrain step - Step 17880, Loss 0.007914549671113491\n",
            "\t\tTrain step - Step 17910, Loss 0.005182373337447643\n",
            "\t\tTrain step - Step 17940, Loss 0.005654640030115843\n",
            "\t\tTrain step - Step 17970, Loss 0.006799396593123674\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.005978819275327902 - Train Accuracy: 0.9094750889679716\n",
            "\t\t\tVal Loss: 0.01636596398020629 - Val Accuracy: 0.7185\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 18000, Loss 0.004700087942183018\n",
            "\t\tTrain step - Step 18030, Loss 0.004656223114579916\n",
            "\t\tTrain step - Step 18060, Loss 0.0067814127542078495\n",
            "\t\tTrain step - Step 18090, Loss 0.004745347425341606\n",
            "\t\tTrain step - Step 18120, Loss 0.004217904061079025\n",
            "\t\tTrain step - Step 18150, Loss 0.005010990891605616\n",
            "\t\tTrain step - Step 18180, Loss 0.004656149074435234\n",
            "\t\tTrain step - Step 18210, Loss 0.0046621146611869335\n",
            "\t\tTrain step - Step 18240, Loss 0.005452632904052734\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.00557337764458353 - Train Accuracy: 0.9176768238434164\n",
            "\t\t\tVal Loss: 0.016590139290201478 - Val Accuracy: 0.7155\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 18270, Loss 0.004665079526603222\n",
            "\t\tTrain step - Step 18300, Loss 0.005362840835005045\n",
            "\t\tTrain step - Step 18330, Loss 0.004654832184314728\n",
            "\t\tTrain step - Step 18360, Loss 0.008087574504315853\n",
            "\t\tTrain step - Step 18390, Loss 0.0060415673069655895\n",
            "\t\tTrain step - Step 18420, Loss 0.0057600997388362885\n",
            "\t\tTrain step - Step 18450, Loss 0.004791656043380499\n",
            "\t\tTrain step - Step 18480, Loss 0.004395081661641598\n",
            "\t\tTrain step - Step 18510, Loss 0.004293942824006081\n",
            "\t\tTrain step - Step 18540, Loss 0.006636475212872028\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.0054489660368456745 - Train Accuracy: 0.9202624555160143\n",
            "\t\t\tVal Loss: 0.016677391802659258 - Val Accuracy: 0.71525\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 18570, Loss 0.005539467092603445\n",
            "\t\tTrain step - Step 18600, Loss 0.00432145269587636\n",
            "\t\tTrain step - Step 18630, Loss 0.006148000713437796\n",
            "\t\tTrain step - Step 18660, Loss 0.0060043856501579285\n",
            "\t\tTrain step - Step 18690, Loss 0.0038660108111798763\n",
            "\t\tTrain step - Step 18720, Loss 0.00470054941251874\n",
            "\t\tTrain step - Step 18750, Loss 0.0050772689282894135\n",
            "\t\tTrain step - Step 18780, Loss 0.0073242164216935635\n",
            "\t\tTrain step - Step 18810, Loss 0.00669910479336977\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.005376421753648549 - Train Accuracy: 0.9200400355871886\n",
            "\t\t\tVal Loss: 0.01665029530704487 - Val Accuracy: 0.71425\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 18840, Loss 0.006787285674363375\n",
            "\t\tTrain step - Step 18870, Loss 0.005852204281836748\n",
            "\t\tTrain step - Step 18900, Loss 0.004672379698604345\n",
            "\t\tTrain step - Step 18930, Loss 0.004569804761558771\n",
            "\t\tTrain step - Step 18960, Loss 0.00594355771318078\n",
            "\t\tTrain step - Step 18990, Loss 0.003660049755126238\n",
            "\t\tTrain step - Step 19020, Loss 0.003803639905527234\n",
            "\t\tTrain step - Step 19050, Loss 0.005765779875218868\n",
            "\t\tTrain step - Step 19080, Loss 0.00572630763053894\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.005243207880683588 - Train Accuracy: 0.921875\n",
            "\t\t\tVal Loss: 0.016423871667939238 - Val Accuracy: 0.716\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 19110, Loss 0.0052628302946686745\n",
            "\t\tTrain step - Step 19140, Loss 0.00490388460457325\n",
            "\t\tTrain step - Step 19170, Loss 0.004514752421528101\n",
            "\t\tTrain step - Step 19200, Loss 0.005199441686272621\n",
            "\t\tTrain step - Step 19230, Loss 0.004827793221920729\n",
            "\t\tTrain step - Step 19260, Loss 0.004443270154297352\n",
            "\t\tTrain step - Step 19290, Loss 0.004076495300978422\n",
            "\t\tTrain step - Step 19320, Loss 0.00573004363104701\n",
            "\t\tTrain step - Step 19350, Loss 0.005189220421016216\n",
            "\t\tTrain step - Step 19380, Loss 0.004801127128303051\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.005137206757030188 - Train Accuracy: 0.9256283362989324\n",
            "\t\t\tVal Loss: 0.016761662787757814 - Val Accuracy: 0.7135\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 19410, Loss 0.004780437797307968\n",
            "\t\tTrain step - Step 19440, Loss 0.007017794530838728\n",
            "\t\tTrain step - Step 19470, Loss 0.00516511732712388\n",
            "\t\tTrain step - Step 19500, Loss 0.006816588342189789\n",
            "\t\tTrain step - Step 19530, Loss 0.006295075174421072\n",
            "\t\tTrain step - Step 19560, Loss 0.005630515515804291\n",
            "\t\tTrain step - Step 19590, Loss 0.006197790149599314\n",
            "\t\tTrain step - Step 19620, Loss 0.006364944390952587\n",
            "\t\tTrain step - Step 19650, Loss 0.005008946172893047\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/63 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.005122737484251636 - Train Accuracy: 0.9261843861209964\n",
            "\t\t\tVal Loss: 0.016861845855601132 - Val Accuracy: 0.70775\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 63/63 [00:02<00:00, 26.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 8:\n",
            "\t\tTrain Mean Accuracy: 0.7690073716319269\n",
            "\t\tVal Mean Accuracy: 0.6125607142857142\n",
            "\t\tTest Accuracy: 0.706875\n",
            "\n",
            "STARTING JOINT TRAINING STAGE 9...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.017423368990421295\n",
            "\t\tTrain step - Step 60, Loss 0.019002586603164673\n",
            "\t\tTrain step - Step 90, Loss 0.021893547847867012\n",
            "\t\tTrain step - Step 120, Loss 0.01688504032790661\n",
            "\t\tTrain step - Step 150, Loss 0.01997443102300167\n",
            "\t\tTrain step - Step 180, Loss 0.017598891630768776\n",
            "\t\tTrain step - Step 210, Loss 0.016538474708795547\n",
            "\t\tTrain step - Step 240, Loss 0.01789095252752304\n",
            "\t\tTrain step - Step 270, Loss 0.018871285021305084\n",
            "\t\tTrain step - Step 300, Loss 0.02212023176252842\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.018198735322331704 - Train Accuracy: 0.6633455300632911\n",
            "\t\t\tVal Loss: 0.024153920589014888 - Val Accuracy: 0.5555555555555556\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.01490656565874815\n",
            "\t\tTrain step - Step 360, Loss 0.01938706822693348\n",
            "\t\tTrain step - Step 390, Loss 0.01602916605770588\n",
            "\t\tTrain step - Step 420, Loss 0.014236614108085632\n",
            "\t\tTrain step - Step 450, Loss 0.02021835930645466\n",
            "\t\tTrain step - Step 480, Loss 0.019350584596395493\n",
            "\t\tTrain step - Step 510, Loss 0.01835007220506668\n",
            "\t\tTrain step - Step 540, Loss 0.019719727337360382\n",
            "\t\tTrain step - Step 570, Loss 0.017791712656617165\n",
            "\t\tTrain step - Step 600, Loss 0.019139837473630905\n",
            "\t\tTrain step - Step 630, Loss 0.021900756284594536\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.017268733958466145 - Train Accuracy: 0.6771162974683544\n",
            "\t\t\tVal Loss: 0.023309883997879095 - Val Accuracy: 0.5631111111111111\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 660, Loss 0.018700851127505302\n",
            "\t\tTrain step - Step 690, Loss 0.016667883843183517\n",
            "\t\tTrain step - Step 720, Loss 0.01676396280527115\n",
            "\t\tTrain step - Step 750, Loss 0.017885996028780937\n",
            "\t\tTrain step - Step 780, Loss 0.015809493139386177\n",
            "\t\tTrain step - Step 810, Loss 0.016168104484677315\n",
            "\t\tTrain step - Step 840, Loss 0.01844649203121662\n",
            "\t\tTrain step - Step 870, Loss 0.017806019634008408\n",
            "\t\tTrain step - Step 900, Loss 0.016123425215482712\n",
            "\t\tTrain step - Step 930, Loss 0.015821868553757668\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.016936191646500103 - Train Accuracy: 0.6865110759493671\n",
            "\t\t\tVal Loss: 0.02433685660879645 - Val Accuracy: 0.5486666666666666\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.01513643842190504\n",
            "\t\tTrain step - Step 990, Loss 0.018782133236527443\n",
            "\t\tTrain step - Step 1020, Loss 0.019281839951872826\n",
            "\t\tTrain step - Step 1050, Loss 0.016599711030721664\n",
            "\t\tTrain step - Step 1080, Loss 0.018249018117785454\n",
            "\t\tTrain step - Step 1110, Loss 0.01850312203168869\n",
            "\t\tTrain step - Step 1140, Loss 0.016594920307397842\n",
            "\t\tTrain step - Step 1170, Loss 0.016452059149742126\n",
            "\t\tTrain step - Step 1200, Loss 0.02003694884479046\n",
            "\t\tTrain step - Step 1230, Loss 0.014697055332362652\n",
            "\t\tTrain step - Step 1260, Loss 0.019697509706020355\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.016879305482217218 - Train Accuracy: 0.6850276898734177\n",
            "\t\t\tVal Loss: 0.024381351579601567 - Val Accuracy: 0.558\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 1290, Loss 0.013395106419920921\n",
            "\t\tTrain step - Step 1320, Loss 0.01648186333477497\n",
            "\t\tTrain step - Step 1350, Loss 0.019788751378655434\n",
            "\t\tTrain step - Step 1380, Loss 0.01557778287678957\n",
            "\t\tTrain step - Step 1410, Loss 0.01622624881565571\n",
            "\t\tTrain step - Step 1440, Loss 0.017340967431664467\n",
            "\t\tTrain step - Step 1470, Loss 0.01796538010239601\n",
            "\t\tTrain step - Step 1500, Loss 0.016252513974905014\n",
            "\t\tTrain step - Step 1530, Loss 0.014446253888309002\n",
            "\t\tTrain step - Step 1560, Loss 0.01929035596549511\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.016737659473585177 - Train Accuracy: 0.692667128164557\n",
            "\t\t\tVal Loss: 0.02337562484252784 - Val Accuracy: 0.5657777777777778\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 1590, Loss 0.020740188658237457\n",
            "\t\tTrain step - Step 1620, Loss 0.01474024262279272\n",
            "\t\tTrain step - Step 1650, Loss 0.017402976751327515\n",
            "\t\tTrain step - Step 1680, Loss 0.014655990526080132\n",
            "\t\tTrain step - Step 1710, Loss 0.017047004774212837\n",
            "\t\tTrain step - Step 1740, Loss 0.018329573795199394\n",
            "\t\tTrain step - Step 1770, Loss 0.019565805792808533\n",
            "\t\tTrain step - Step 1800, Loss 0.019262954592704773\n",
            "\t\tTrain step - Step 1830, Loss 0.01766141876578331\n",
            "\t\tTrain step - Step 1860, Loss 0.017118846997618675\n",
            "\t\tTrain step - Step 1890, Loss 0.020595477893948555\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.016878158113435855 - Train Accuracy: 0.6875247231012658\n",
            "\t\t\tVal Loss: 0.02337014043910636 - Val Accuracy: 0.5755555555555556\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 1920, Loss 0.01426316611468792\n",
            "\t\tTrain step - Step 1950, Loss 0.0154888816177845\n",
            "\t\tTrain step - Step 1980, Loss 0.017465025186538696\n",
            "\t\tTrain step - Step 2010, Loss 0.0144880972802639\n",
            "\t\tTrain step - Step 2040, Loss 0.01403551921248436\n",
            "\t\tTrain step - Step 2070, Loss 0.014639935456216335\n",
            "\t\tTrain step - Step 2100, Loss 0.018727416172623634\n",
            "\t\tTrain step - Step 2130, Loss 0.014945092611014843\n",
            "\t\tTrain step - Step 2160, Loss 0.016652312129735947\n",
            "\t\tTrain step - Step 2190, Loss 0.01834331639111042\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.016643343012944997 - Train Accuracy: 0.6924940664556962\n",
            "\t\t\tVal Loss: 0.025901383590987988 - Val Accuracy: 0.5348888888888889\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 2220, Loss 0.016636278480291367\n",
            "\t\tTrain step - Step 2250, Loss 0.014510867185890675\n",
            "\t\tTrain step - Step 2280, Loss 0.0166353490203619\n",
            "\t\tTrain step - Step 2310, Loss 0.016719132661819458\n",
            "\t\tTrain step - Step 2340, Loss 0.01631244458258152\n",
            "\t\tTrain step - Step 2370, Loss 0.01462619286030531\n",
            "\t\tTrain step - Step 2400, Loss 0.016133546829223633\n",
            "\t\tTrain step - Step 2430, Loss 0.015956608578562737\n",
            "\t\tTrain step - Step 2460, Loss 0.02088320441544056\n",
            "\t\tTrain step - Step 2490, Loss 0.017122110351920128\n",
            "\t\tTrain step - Step 2520, Loss 0.0191320963203907\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.01660938700366341 - Train Accuracy: 0.6926424050632911\n",
            "\t\t\tVal Loss: 0.02489725024335914 - Val Accuracy: 0.5455555555555556\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 2550, Loss 0.015913987532258034\n",
            "\t\tTrain step - Step 2580, Loss 0.019711825996637344\n",
            "\t\tTrain step - Step 2610, Loss 0.02006777748465538\n",
            "\t\tTrain step - Step 2640, Loss 0.014435057528316975\n",
            "\t\tTrain step - Step 2670, Loss 0.01728803478181362\n",
            "\t\tTrain step - Step 2700, Loss 0.01819917932152748\n",
            "\t\tTrain step - Step 2730, Loss 0.016598863527178764\n",
            "\t\tTrain step - Step 2760, Loss 0.016967780888080597\n",
            "\t\tTrain step - Step 2790, Loss 0.016372499987483025\n",
            "\t\tTrain step - Step 2820, Loss 0.0173362847417593\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.016700363163895244 - Train Accuracy: 0.690145371835443\n",
            "\t\t\tVal Loss: 0.023368399719604187 - Val Accuracy: 0.5771111111111111\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 2850, Loss 0.018838007003068924\n",
            "\t\tTrain step - Step 2880, Loss 0.015970680862665176\n",
            "\t\tTrain step - Step 2910, Loss 0.017380045726895332\n",
            "\t\tTrain step - Step 2940, Loss 0.01790482923388481\n",
            "\t\tTrain step - Step 2970, Loss 0.01816999725997448\n",
            "\t\tTrain step - Step 3000, Loss 0.01811797544360161\n",
            "\t\tTrain step - Step 3030, Loss 0.02031116373836994\n",
            "\t\tTrain step - Step 3060, Loss 0.01611730270087719\n",
            "\t\tTrain step - Step 3090, Loss 0.019049566239118576\n",
            "\t\tTrain step - Step 3120, Loss 0.01855749823153019\n",
            "\t\tTrain step - Step 3150, Loss 0.018582651391625404\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.01661759651195305 - Train Accuracy: 0.6945460838607594\n",
            "\t\t\tVal Loss: 0.025580311349282663 - Val Accuracy: 0.542\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 3180, Loss 0.014975177124142647\n",
            "\t\tTrain step - Step 3210, Loss 0.0151815265417099\n",
            "\t\tTrain step - Step 3240, Loss 0.015600486658513546\n",
            "\t\tTrain step - Step 3270, Loss 0.015981126576662064\n",
            "\t\tTrain step - Step 3300, Loss 0.01745167374610901\n",
            "\t\tTrain step - Step 3330, Loss 0.017856905236840248\n",
            "\t\tTrain step - Step 3360, Loss 0.017825793474912643\n",
            "\t\tTrain step - Step 3390, Loss 0.017647763714194298\n",
            "\t\tTrain step - Step 3420, Loss 0.018153296783566475\n",
            "\t\tTrain step - Step 3450, Loss 0.018254905939102173\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.016434653217114414 - Train Accuracy: 0.6968700553797469\n",
            "\t\t\tVal Loss: 0.023886723055814702 - Val Accuracy: 0.5675555555555556\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 3480, Loss 0.018862657248973846\n",
            "\t\tTrain step - Step 3510, Loss 0.013987066224217415\n",
            "\t\tTrain step - Step 3540, Loss 0.014397596940398216\n",
            "\t\tTrain step - Step 3570, Loss 0.01590541936457157\n",
            "\t\tTrain step - Step 3600, Loss 0.01594386249780655\n",
            "\t\tTrain step - Step 3630, Loss 0.014340431429445744\n",
            "\t\tTrain step - Step 3660, Loss 0.01827799715101719\n",
            "\t\tTrain step - Step 3690, Loss 0.018297184258699417\n",
            "\t\tTrain step - Step 3720, Loss 0.014584867283701897\n",
            "\t\tTrain step - Step 3750, Loss 0.016266468912363052\n",
            "\t\tTrain step - Step 3780, Loss 0.014484550803899765\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.016446826599326125 - Train Accuracy: 0.6957080696202531\n",
            "\t\t\tVal Loss: 0.0237240435089916 - Val Accuracy: 0.5644444444444444\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 3810, Loss 0.014895567670464516\n",
            "\t\tTrain step - Step 3840, Loss 0.015029619447886944\n",
            "\t\tTrain step - Step 3870, Loss 0.014766080304980278\n",
            "\t\tTrain step - Step 3900, Loss 0.015827598050236702\n",
            "\t\tTrain step - Step 3930, Loss 0.016323909163475037\n",
            "\t\tTrain step - Step 3960, Loss 0.016996396705508232\n",
            "\t\tTrain step - Step 3990, Loss 0.018691303208470345\n",
            "\t\tTrain step - Step 4020, Loss 0.015006761997938156\n",
            "\t\tTrain step - Step 4050, Loss 0.017360392957925797\n",
            "\t\tTrain step - Step 4080, Loss 0.018157217651605606\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.016439383165745794 - Train Accuracy: 0.6981309335443038\n",
            "\t\t\tVal Loss: 0.024330439873867564 - Val Accuracy: 0.5613333333333334\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 4110, Loss 0.016771988943219185\n",
            "\t\tTrain step - Step 4140, Loss 0.011699085123836994\n",
            "\t\tTrain step - Step 4170, Loss 0.015409663319587708\n",
            "\t\tTrain step - Step 4200, Loss 0.01638128235936165\n",
            "\t\tTrain step - Step 4230, Loss 0.0160926915705204\n",
            "\t\tTrain step - Step 4260, Loss 0.017340054735541344\n",
            "\t\tTrain step - Step 4290, Loss 0.01728805899620056\n",
            "\t\tTrain step - Step 4320, Loss 0.0159340538084507\n",
            "\t\tTrain step - Step 4350, Loss 0.01732569746673107\n",
            "\t\tTrain step - Step 4380, Loss 0.020129747688770294\n",
            "\t\tTrain step - Step 4410, Loss 0.016590921208262444\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.016366414914402782 - Train Accuracy: 0.6983287183544303\n",
            "\t\t\tVal Loss: 0.024846019766603906 - Val Accuracy: 0.5428888888888889\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 4440, Loss 0.01591692678630352\n",
            "\t\tTrain step - Step 4470, Loss 0.012544531375169754\n",
            "\t\tTrain step - Step 4500, Loss 0.017936620861291885\n",
            "\t\tTrain step - Step 4530, Loss 0.017107626423239708\n",
            "\t\tTrain step - Step 4560, Loss 0.016583947464823723\n",
            "\t\tTrain step - Step 4590, Loss 0.016707709059119225\n",
            "\t\tTrain step - Step 4620, Loss 0.016805198043584824\n",
            "\t\tTrain step - Step 4650, Loss 0.019248859956860542\n",
            "\t\tTrain step - Step 4680, Loss 0.01295950822532177\n",
            "\t\tTrain step - Step 4710, Loss 0.019263770431280136\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.01646533982439226 - Train Accuracy: 0.6959305775316456\n",
            "\t\t\tVal Loss: 0.02378547721956339 - Val Accuracy: 0.5602222222222222\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 4740, Loss 0.015801621600985527\n",
            "\t\tTrain step - Step 4770, Loss 0.014339872635900974\n",
            "\t\tTrain step - Step 4800, Loss 0.015827445313334465\n",
            "\t\tTrain step - Step 4830, Loss 0.015560731291770935\n",
            "\t\tTrain step - Step 4860, Loss 0.012907862663269043\n",
            "\t\tTrain step - Step 4890, Loss 0.016953131183981895\n",
            "\t\tTrain step - Step 4920, Loss 0.015972362831234932\n",
            "\t\tTrain step - Step 4950, Loss 0.01834634318947792\n",
            "\t\tTrain step - Step 4980, Loss 0.017233116552233696\n",
            "\t\tTrain step - Step 5010, Loss 0.01688981242477894\n",
            "\t\tTrain step - Step 5040, Loss 0.017206238582730293\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.016325441156690823 - Train Accuracy: 0.6977106408227848\n",
            "\t\t\tVal Loss: 0.024782992446691625 - Val Accuracy: 0.5537777777777778\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 5070, Loss 0.013392363674938679\n",
            "\t\tTrain step - Step 5100, Loss 0.01680624485015869\n",
            "\t\tTrain step - Step 5130, Loss 0.01561675313860178\n",
            "\t\tTrain step - Step 5160, Loss 0.015850955620408058\n",
            "\t\tTrain step - Step 5190, Loss 0.01816975511610508\n",
            "\t\tTrain step - Step 5220, Loss 0.01693269982933998\n",
            "\t\tTrain step - Step 5250, Loss 0.016087649390101433\n",
            "\t\tTrain step - Step 5280, Loss 0.01591665670275688\n",
            "\t\tTrain step - Step 5310, Loss 0.017643991857767105\n",
            "\t\tTrain step - Step 5340, Loss 0.017917226999998093\n",
            "\t\tTrain step - Step 5370, Loss 0.019386589527130127\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.01624448135601286 - Train Accuracy: 0.700899920886076\n",
            "\t\t\tVal Loss: 0.022337709087878466 - Val Accuracy: 0.5953333333333334\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 5400, Loss 0.016561903059482574\n",
            "\t\tTrain step - Step 5430, Loss 0.01720367558300495\n",
            "\t\tTrain step - Step 5460, Loss 0.01776028610765934\n",
            "\t\tTrain step - Step 5490, Loss 0.01629718951880932\n",
            "\t\tTrain step - Step 5520, Loss 0.017026949673891068\n",
            "\t\tTrain step - Step 5550, Loss 0.017325326800346375\n",
            "\t\tTrain step - Step 5580, Loss 0.014891876839101315\n",
            "\t\tTrain step - Step 5610, Loss 0.014822589233517647\n",
            "\t\tTrain step - Step 5640, Loss 0.016977930441498756\n",
            "\t\tTrain step - Step 5670, Loss 0.016348494216799736\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.01628157022538819 - Train Accuracy: 0.6990456882911392\n",
            "\t\t\tVal Loss: 0.024789478138296142 - Val Accuracy: 0.57\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 5700, Loss 0.014082795940339565\n",
            "\t\tTrain step - Step 5730, Loss 0.015001369640231133\n",
            "\t\tTrain step - Step 5760, Loss 0.012629828415811062\n",
            "\t\tTrain step - Step 5790, Loss 0.01865004003047943\n",
            "\t\tTrain step - Step 5820, Loss 0.019360294565558434\n",
            "\t\tTrain step - Step 5850, Loss 0.01550426334142685\n",
            "\t\tTrain step - Step 5880, Loss 0.016494255512952805\n",
            "\t\tTrain step - Step 5910, Loss 0.018559655174613\n",
            "\t\tTrain step - Step 5940, Loss 0.014723935164511204\n",
            "\t\tTrain step - Step 5970, Loss 0.017514552921056747\n",
            "\t\tTrain step - Step 6000, Loss 0.01674705184996128\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.016296371508130354 - Train Accuracy: 0.6995895965189873\n",
            "\t\t\tVal Loss: 0.023674805131223466 - Val Accuracy: 0.5733333333333334\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 6030, Loss 0.014023547060787678\n",
            "\t\tTrain step - Step 6060, Loss 0.014499985612928867\n",
            "\t\tTrain step - Step 6090, Loss 0.0190872885286808\n",
            "\t\tTrain step - Step 6120, Loss 0.016379648819565773\n",
            "\t\tTrain step - Step 6150, Loss 0.01690092124044895\n",
            "\t\tTrain step - Step 6180, Loss 0.016634564846754074\n",
            "\t\tTrain step - Step 6210, Loss 0.018922515213489532\n",
            "\t\tTrain step - Step 6240, Loss 0.01576455868780613\n",
            "\t\tTrain step - Step 6270, Loss 0.014910758472979069\n",
            "\t\tTrain step - Step 6300, Loss 0.016584089025855064\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.016313588780150573 - Train Accuracy: 0.7009246439873418\n",
            "\t\t\tVal Loss: 0.02316243561088211 - Val Accuracy: 0.5744444444444444\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 6330, Loss 0.014412540942430496\n",
            "\t\tTrain step - Step 6360, Loss 0.012653561308979988\n",
            "\t\tTrain step - Step 6390, Loss 0.017513670027256012\n",
            "\t\tTrain step - Step 6420, Loss 0.015710800886154175\n",
            "\t\tTrain step - Step 6450, Loss 0.015782874077558517\n",
            "\t\tTrain step - Step 6480, Loss 0.014837968163192272\n",
            "\t\tTrain step - Step 6510, Loss 0.014477445743978024\n",
            "\t\tTrain step - Step 6540, Loss 0.016245193779468536\n",
            "\t\tTrain step - Step 6570, Loss 0.015019504353404045\n",
            "\t\tTrain step - Step 6600, Loss 0.014681187458336353\n",
            "\t\tTrain step - Step 6630, Loss 0.015816491097211838\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.01620747282205126 - Train Accuracy: 0.7003560126582279\n",
            "\t\t\tVal Loss: 0.02205721208722227 - Val Accuracy: 0.586\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 6660, Loss 0.014549074694514275\n",
            "\t\tTrain step - Step 6690, Loss 0.0123740928247571\n",
            "\t\tTrain step - Step 6720, Loss 0.014852077700197697\n",
            "\t\tTrain step - Step 6750, Loss 0.017863376066088676\n",
            "\t\tTrain step - Step 6780, Loss 0.017658183351159096\n",
            "\t\tTrain step - Step 6810, Loss 0.014572528190910816\n",
            "\t\tTrain step - Step 6840, Loss 0.01737809181213379\n",
            "\t\tTrain step - Step 6870, Loss 0.016464021056890488\n",
            "\t\tTrain step - Step 6900, Loss 0.01766163855791092\n",
            "\t\tTrain step - Step 6930, Loss 0.016802962869405746\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.016167871736555914 - Train Accuracy: 0.7020619066455697\n",
            "\t\t\tVal Loss: 0.024391212604112096 - Val Accuracy: 0.5557777777777778\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 6960, Loss 0.015829147771000862\n",
            "\t\tTrain step - Step 6990, Loss 0.015786707401275635\n",
            "\t\tTrain step - Step 7020, Loss 0.019515689462423325\n",
            "\t\tTrain step - Step 7050, Loss 0.015767227858304977\n",
            "\t\tTrain step - Step 7080, Loss 0.014424210414290428\n",
            "\t\tTrain step - Step 7110, Loss 0.014777273871004581\n",
            "\t\tTrain step - Step 7140, Loss 0.016000518575310707\n",
            "\t\tTrain step - Step 7170, Loss 0.014802572317421436\n",
            "\t\tTrain step - Step 7200, Loss 0.01939854398369789\n",
            "\t\tTrain step - Step 7230, Loss 0.017186855897307396\n",
            "\t\tTrain step - Step 7260, Loss 0.01853029988706112\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.01615403541894276 - Train Accuracy: 0.7013943829113924\n",
            "\t\t\tVal Loss: 0.024965822282764647 - Val Accuracy: 0.5464444444444444\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 7290, Loss 0.015210398472845554\n",
            "\t\tTrain step - Step 7320, Loss 0.01534124556928873\n",
            "\t\tTrain step - Step 7350, Loss 0.017029428854584694\n",
            "\t\tTrain step - Step 7380, Loss 0.018642039969563484\n",
            "\t\tTrain step - Step 7410, Loss 0.017244691029191017\n",
            "\t\tTrain step - Step 7440, Loss 0.017529834061861038\n",
            "\t\tTrain step - Step 7470, Loss 0.01766759343445301\n",
            "\t\tTrain step - Step 7500, Loss 0.015145010314881802\n",
            "\t\tTrain step - Step 7530, Loss 0.018803682178258896\n",
            "\t\tTrain step - Step 7560, Loss 0.014681954868137836\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.016073226239060677 - Train Accuracy: 0.7041386471518988\n",
            "\t\t\tVal Loss: 0.026380513354928956 - Val Accuracy: 0.5304444444444445\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 7590, Loss 0.01344861276447773\n",
            "\t\tTrain step - Step 7620, Loss 0.01453267503529787\n",
            "\t\tTrain step - Step 7650, Loss 0.014422554522752762\n",
            "\t\tTrain step - Step 7680, Loss 0.017260724678635597\n",
            "\t\tTrain step - Step 7710, Loss 0.018870260566473007\n",
            "\t\tTrain step - Step 7740, Loss 0.01630614884197712\n",
            "\t\tTrain step - Step 7770, Loss 0.018316354602575302\n",
            "\t\tTrain step - Step 7800, Loss 0.015330149792134762\n",
            "\t\tTrain step - Step 7830, Loss 0.015571782365441322\n",
            "\t\tTrain step - Step 7860, Loss 0.017895232886075974\n",
            "\t\tTrain step - Step 7890, Loss 0.014857633970677853\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.01622725891456291 - Train Accuracy: 0.7014191060126582\n",
            "\t\t\tVal Loss: 0.023151711211539805 - Val Accuracy: 0.5746666666666667\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 7920, Loss 0.015537142753601074\n",
            "\t\tTrain step - Step 7950, Loss 0.016180910170078278\n",
            "\t\tTrain step - Step 7980, Loss 0.0137547068297863\n",
            "\t\tTrain step - Step 8010, Loss 0.01627323031425476\n",
            "\t\tTrain step - Step 8040, Loss 0.018024813383817673\n",
            "\t\tTrain step - Step 8070, Loss 0.015325458720326424\n",
            "\t\tTrain step - Step 8100, Loss 0.014380596578121185\n",
            "\t\tTrain step - Step 8130, Loss 0.013859132304787636\n",
            "\t\tTrain step - Step 8160, Loss 0.016054658219218254\n",
            "\t\tTrain step - Step 8190, Loss 0.014343327842652798\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.016004807471969647 - Train Accuracy: 0.7065615110759493\n",
            "\t\t\tVal Loss: 0.022040479661275942 - Val Accuracy: 0.5924444444444444\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 8220, Loss 0.01443431805819273\n",
            "\t\tTrain step - Step 8250, Loss 0.017432641237974167\n",
            "\t\tTrain step - Step 8280, Loss 0.014697570353746414\n",
            "\t\tTrain step - Step 8310, Loss 0.01501796580851078\n",
            "\t\tTrain step - Step 8340, Loss 0.017316997051239014\n",
            "\t\tTrain step - Step 8370, Loss 0.014675443060696125\n",
            "\t\tTrain step - Step 8400, Loss 0.012399137020111084\n",
            "\t\tTrain step - Step 8430, Loss 0.01658453978598118\n",
            "\t\tTrain step - Step 8460, Loss 0.01528714969754219\n",
            "\t\tTrain step - Step 8490, Loss 0.016956349834799767\n",
            "\t\tTrain step - Step 8520, Loss 0.01776568964123726\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.01604880951344967 - Train Accuracy: 0.7036194620253164\n",
            "\t\t\tVal Loss: 0.023634745584179957 - Val Accuracy: 0.5735555555555556\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 8550, Loss 0.016050316393375397\n",
            "\t\tTrain step - Step 8580, Loss 0.014580783434212208\n",
            "\t\tTrain step - Step 8610, Loss 0.015802115201950073\n",
            "\t\tTrain step - Step 8640, Loss 0.014731080271303654\n",
            "\t\tTrain step - Step 8670, Loss 0.01644688844680786\n",
            "\t\tTrain step - Step 8700, Loss 0.01761787198483944\n",
            "\t\tTrain step - Step 8730, Loss 0.014737479388713837\n",
            "\t\tTrain step - Step 8760, Loss 0.014388001523911953\n",
            "\t\tTrain step - Step 8790, Loss 0.02080533280968666\n",
            "\t\tTrain step - Step 8820, Loss 0.015558557584881783\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.016344502450356 - Train Accuracy: 0.6992929193037974\n",
            "\t\t\tVal Loss: 0.024660431624700625 - Val Accuracy: 0.5517777777777778\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 8850, Loss 0.014958345331251621\n",
            "\t\tTrain step - Step 8880, Loss 0.012457546778023243\n",
            "\t\tTrain step - Step 8910, Loss 0.01351851411163807\n",
            "\t\tTrain step - Step 8940, Loss 0.019096048548817635\n",
            "\t\tTrain step - Step 8970, Loss 0.01569489948451519\n",
            "\t\tTrain step - Step 9000, Loss 0.013695859350264072\n",
            "\t\tTrain step - Step 9030, Loss 0.016870614141225815\n",
            "\t\tTrain step - Step 9060, Loss 0.01767348125576973\n",
            "\t\tTrain step - Step 9090, Loss 0.018397441133856773\n",
            "\t\tTrain step - Step 9120, Loss 0.016153544187545776\n",
            "\t\tTrain step - Step 9150, Loss 0.018795663490891457\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.016105169999189203 - Train Accuracy: 0.7046825553797469\n",
            "\t\t\tVal Loss: 0.024327886109757755 - Val Accuracy: 0.5526666666666666\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 9180, Loss 0.017320116981863976\n",
            "\t\tTrain step - Step 9210, Loss 0.014131969772279263\n",
            "\t\tTrain step - Step 9240, Loss 0.015719417482614517\n",
            "\t\tTrain step - Step 9270, Loss 0.015384986065328121\n",
            "\t\tTrain step - Step 9300, Loss 0.016377856954932213\n",
            "\t\tTrain step - Step 9330, Loss 0.012653280980885029\n",
            "\t\tTrain step - Step 9360, Loss 0.01716812327504158\n",
            "\t\tTrain step - Step 9390, Loss 0.014643903821706772\n",
            "\t\tTrain step - Step 9420, Loss 0.013458730652928352\n",
            "\t\tTrain step - Step 9450, Loss 0.017740342766046524\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.01604771054102273 - Train Accuracy: 0.705918710443038\n",
            "\t\t\tVal Loss: 0.022704619319281645 - Val Accuracy: 0.5791111111111111\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 9480, Loss 0.011644282378256321\n",
            "\t\tTrain step - Step 9510, Loss 0.015061967074871063\n",
            "\t\tTrain step - Step 9540, Loss 0.017493505030870438\n",
            "\t\tTrain step - Step 9570, Loss 0.015102779492735863\n",
            "\t\tTrain step - Step 9600, Loss 0.016699375584721565\n",
            "\t\tTrain step - Step 9630, Loss 0.015027372166514397\n",
            "\t\tTrain step - Step 9660, Loss 0.01809638738632202\n",
            "\t\tTrain step - Step 9690, Loss 0.016456641256809235\n",
            "\t\tTrain step - Step 9720, Loss 0.01698240265250206\n",
            "\t\tTrain step - Step 9750, Loss 0.01668829843401909\n",
            "\t\tTrain step - Step 9780, Loss 0.01763920858502388\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.01610192146057947 - Train Accuracy: 0.7048803401898734\n",
            "\t\t\tVal Loss: 0.02345943955394129 - Val Accuracy: 0.5782222222222222\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 9810, Loss 0.015375670976936817\n",
            "\t\tTrain step - Step 9840, Loss 0.013745368458330631\n",
            "\t\tTrain step - Step 9870, Loss 0.015340630896389484\n",
            "\t\tTrain step - Step 9900, Loss 0.01709197275340557\n",
            "\t\tTrain step - Step 9930, Loss 0.01748643070459366\n",
            "\t\tTrain step - Step 9960, Loss 0.014954477548599243\n",
            "\t\tTrain step - Step 9990, Loss 0.017641598358750343\n",
            "\t\tTrain step - Step 10020, Loss 0.016570065170526505\n",
            "\t\tTrain step - Step 10050, Loss 0.01568463258445263\n",
            "\t\tTrain step - Step 10080, Loss 0.01712988317012787\n",
            "\t\tTrain step - Step 10110, Loss 0.014245607890188694\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.016015311735505355 - Train Accuracy: 0.705770371835443\n",
            "\t\t\tVal Loss: 0.02271660719998181 - Val Accuracy: 0.5877777777777777\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 10140, Loss 0.014834942296147346\n",
            "\t\tTrain step - Step 10170, Loss 0.014753108844161034\n",
            "\t\tTrain step - Step 10200, Loss 0.015798909589648247\n",
            "\t\tTrain step - Step 10230, Loss 0.015077504329383373\n",
            "\t\tTrain step - Step 10260, Loss 0.01617417111992836\n",
            "\t\tTrain step - Step 10290, Loss 0.018935611471533775\n",
            "\t\tTrain step - Step 10320, Loss 0.01789971999824047\n",
            "\t\tTrain step - Step 10350, Loss 0.01945381984114647\n",
            "\t\tTrain step - Step 10380, Loss 0.014219867065548897\n",
            "\t\tTrain step - Step 10410, Loss 0.01707606017589569\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.016165579427505218 - Train Accuracy: 0.7005537974683544\n",
            "\t\t\tVal Loss: 0.023964618591384754 - Val Accuracy: 0.5546666666666666\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 10440, Loss 0.015771543607115746\n",
            "\t\tTrain step - Step 10470, Loss 0.01508584339171648\n",
            "\t\tTrain step - Step 10500, Loss 0.01695699617266655\n",
            "\t\tTrain step - Step 10530, Loss 0.014353753998875618\n",
            "\t\tTrain step - Step 10560, Loss 0.016683559864759445\n",
            "\t\tTrain step - Step 10590, Loss 0.018857840448617935\n",
            "\t\tTrain step - Step 10620, Loss 0.014734439551830292\n",
            "\t\tTrain step - Step 10650, Loss 0.014580289833247662\n",
            "\t\tTrain step - Step 10680, Loss 0.014727776870131493\n",
            "\t\tTrain step - Step 10710, Loss 0.016987429931759834\n",
            "\t\tTrain step - Step 10740, Loss 0.017231369391083717\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.015955720692165668 - Train Accuracy: 0.7075751582278481\n",
            "\t\t\tVal Loss: 0.022592387705420453 - Val Accuracy: 0.5817777777777777\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 10770, Loss 0.015106323175132275\n",
            "\t\tTrain step - Step 10800, Loss 0.016257289797067642\n",
            "\t\tTrain step - Step 10830, Loss 0.016417087987065315\n",
            "\t\tTrain step - Step 10860, Loss 0.014382658526301384\n",
            "\t\tTrain step - Step 10890, Loss 0.015650084242224693\n",
            "\t\tTrain step - Step 10920, Loss 0.018848270177841187\n",
            "\t\tTrain step - Step 10950, Loss 0.017915029078722\n",
            "\t\tTrain step - Step 10980, Loss 0.016531670466065407\n",
            "\t\tTrain step - Step 11010, Loss 0.01663936674594879\n",
            "\t\tTrain step - Step 11040, Loss 0.016930915415287018\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.016027572815294697 - Train Accuracy: 0.7069818037974683\n",
            "\t\t\tVal Loss: 0.023605696598274842 - Val Accuracy: 0.5764444444444444\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 11070, Loss 0.014804434031248093\n",
            "\t\tTrain step - Step 11100, Loss 0.015071536414325237\n",
            "\t\tTrain step - Step 11130, Loss 0.016248386353254318\n",
            "\t\tTrain step - Step 11160, Loss 0.014883643947541714\n",
            "\t\tTrain step - Step 11190, Loss 0.013681022450327873\n",
            "\t\tTrain step - Step 11220, Loss 0.018721753731369972\n",
            "\t\tTrain step - Step 11250, Loss 0.015067330561578274\n",
            "\t\tTrain step - Step 11280, Loss 0.018025578930974007\n",
            "\t\tTrain step - Step 11310, Loss 0.016424518078565598\n",
            "\t\tTrain step - Step 11340, Loss 0.016014445573091507\n",
            "\t\tTrain step - Step 11370, Loss 0.01595955155789852\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.015911377989981747 - Train Accuracy: 0.7089102056962026\n",
            "\t\t\tVal Loss: 0.02282992644338972 - Val Accuracy: 0.5886666666666667\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 11400, Loss 0.015315989963710308\n",
            "\t\tTrain step - Step 11430, Loss 0.01615113765001297\n",
            "\t\tTrain step - Step 11460, Loss 0.014129972085356712\n",
            "\t\tTrain step - Step 11490, Loss 0.015063545666635036\n",
            "\t\tTrain step - Step 11520, Loss 0.012653774581849575\n",
            "\t\tTrain step - Step 11550, Loss 0.016962869092822075\n",
            "\t\tTrain step - Step 11580, Loss 0.014702457934617996\n",
            "\t\tTrain step - Step 11610, Loss 0.015616263262927532\n",
            "\t\tTrain step - Step 11640, Loss 0.01749647967517376\n",
            "\t\tTrain step - Step 11670, Loss 0.015884684398770332\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.01597761777465385 - Train Accuracy: 0.7057950949367089\n",
            "\t\t\tVal Loss: 0.02369356618469788 - Val Accuracy: 0.5655555555555556\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 11700, Loss 0.018537934869527817\n",
            "\t\tTrain step - Step 11730, Loss 0.016419699415564537\n",
            "\t\tTrain step - Step 11760, Loss 0.01512644998729229\n",
            "\t\tTrain step - Step 11790, Loss 0.01441018283367157\n",
            "\t\tTrain step - Step 11820, Loss 0.017091069370508194\n",
            "\t\tTrain step - Step 11850, Loss 0.014001991599798203\n",
            "\t\tTrain step - Step 11880, Loss 0.014953101985156536\n",
            "\t\tTrain step - Step 11910, Loss 0.018110398203134537\n",
            "\t\tTrain step - Step 11940, Loss 0.015268990769982338\n",
            "\t\tTrain step - Step 11970, Loss 0.016688477247953415\n",
            "\t\tTrain step - Step 12000, Loss 0.016671866178512573\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.016044503879509394 - Train Accuracy: 0.7044106012658228\n",
            "\t\t\tVal Loss: 0.023687588025091424 - Val Accuracy: 0.5713333333333334\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 12030, Loss 0.014346393756568432\n",
            "\t\tTrain step - Step 12060, Loss 0.012940142303705215\n",
            "\t\tTrain step - Step 12090, Loss 0.014319024048745632\n",
            "\t\tTrain step - Step 12120, Loss 0.015429415740072727\n",
            "\t\tTrain step - Step 12150, Loss 0.015392433851957321\n",
            "\t\tTrain step - Step 12180, Loss 0.016084592789411545\n",
            "\t\tTrain step - Step 12210, Loss 0.018490850925445557\n",
            "\t\tTrain step - Step 12240, Loss 0.01646554283797741\n",
            "\t\tTrain step - Step 12270, Loss 0.01573539525270462\n",
            "\t\tTrain step - Step 12300, Loss 0.01553418580442667\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.015974815139146167 - Train Accuracy: 0.7067098496835443\n",
            "\t\t\tVal Loss: 0.023492758809071448 - Val Accuracy: 0.586\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 12330, Loss 0.011901037767529488\n",
            "\t\tTrain step - Step 12360, Loss 0.015542800538241863\n",
            "\t\tTrain step - Step 12390, Loss 0.017173221334815025\n",
            "\t\tTrain step - Step 12420, Loss 0.015364419668912888\n",
            "\t\tTrain step - Step 12450, Loss 0.015853744000196457\n",
            "\t\tTrain step - Step 12480, Loss 0.01515882182866335\n",
            "\t\tTrain step - Step 12510, Loss 0.014620738103985786\n",
            "\t\tTrain step - Step 12540, Loss 0.014789890497922897\n",
            "\t\tTrain step - Step 12570, Loss 0.014780726283788681\n",
            "\t\tTrain step - Step 12600, Loss 0.016661303117871284\n",
            "\t\tTrain step - Step 12630, Loss 0.017275743186473846\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.01585533635254619 - Train Accuracy: 0.7099485759493671\n",
            "\t\t\tVal Loss: 0.023174554290663864 - Val Accuracy: 0.5695555555555556\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 12660, Loss 0.013929030857980251\n",
            "\t\tTrain step - Step 12690, Loss 0.016067704185843468\n",
            "\t\tTrain step - Step 12720, Loss 0.014337577857077122\n",
            "\t\tTrain step - Step 12750, Loss 0.017281820997595787\n",
            "\t\tTrain step - Step 12780, Loss 0.014107667841017246\n",
            "\t\tTrain step - Step 12810, Loss 0.016133839264512062\n",
            "\t\tTrain step - Step 12840, Loss 0.01566639170050621\n",
            "\t\tTrain step - Step 12870, Loss 0.016669927164912224\n",
            "\t\tTrain step - Step 12900, Loss 0.017467552796006203\n",
            "\t\tTrain step - Step 12930, Loss 0.015059935860335827\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.015933868946814086 - Train Accuracy: 0.7084404667721519\n",
            "\t\t\tVal Loss: 0.024732808582484722 - Val Accuracy: 0.554\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 12960, Loss 0.015945784747600555\n",
            "\t\tTrain step - Step 12990, Loss 0.012571481987833977\n",
            "\t\tTrain step - Step 13020, Loss 0.01489225123077631\n",
            "\t\tTrain step - Step 13050, Loss 0.015352736227214336\n",
            "\t\tTrain step - Step 13080, Loss 0.019003156572580338\n",
            "\t\tTrain step - Step 13110, Loss 0.014966115355491638\n",
            "\t\tTrain step - Step 13140, Loss 0.01579730585217476\n",
            "\t\tTrain step - Step 13170, Loss 0.015446441248059273\n",
            "\t\tTrain step - Step 13200, Loss 0.016558226197957993\n",
            "\t\tTrain step - Step 13230, Loss 0.018456339836120605\n",
            "\t\tTrain step - Step 13260, Loss 0.017555134370923042\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.015828363912745932 - Train Accuracy: 0.7106902689873418\n",
            "\t\t\tVal Loss: 0.021599776318503752 - Val Accuracy: 0.5897777777777777\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 13290, Loss 0.01716621033847332\n",
            "\t\tTrain step - Step 13320, Loss 0.016227392479777336\n",
            "\t\tTrain step - Step 13350, Loss 0.01541847176849842\n",
            "\t\tTrain step - Step 13380, Loss 0.01341028418391943\n",
            "\t\tTrain step - Step 13410, Loss 0.01612158678472042\n",
            "\t\tTrain step - Step 13440, Loss 0.014210603199899197\n",
            "\t\tTrain step - Step 13470, Loss 0.01338829006999731\n",
            "\t\tTrain step - Step 13500, Loss 0.016483796760439873\n",
            "\t\tTrain step - Step 13530, Loss 0.016625581309199333\n",
            "\t\tTrain step - Step 13560, Loss 0.014811445958912373\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.01586740772546375 - Train Accuracy: 0.710665545886076\n",
            "\t\t\tVal Loss: 0.02536547665173809 - Val Accuracy: 0.5546666666666666\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 13590, Loss 0.015584586188197136\n",
            "\t\tTrain step - Step 13620, Loss 0.016141211614012718\n",
            "\t\tTrain step - Step 13650, Loss 0.014409713447093964\n",
            "\t\tTrain step - Step 13680, Loss 0.014898370020091534\n",
            "\t\tTrain step - Step 13710, Loss 0.01666429080069065\n",
            "\t\tTrain step - Step 13740, Loss 0.018235545605421066\n",
            "\t\tTrain step - Step 13770, Loss 0.0148611543700099\n",
            "\t\tTrain step - Step 13800, Loss 0.014140170067548752\n",
            "\t\tTrain step - Step 13830, Loss 0.015648888424038887\n",
            "\t\tTrain step - Step 13860, Loss 0.01685011200606823\n",
            "\t\tTrain step - Step 13890, Loss 0.016356302425265312\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.015884994470243212 - Train Accuracy: 0.7075257120253164\n",
            "\t\t\tVal Loss: 0.02304260833706293 - Val Accuracy: 0.5708888888888889\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 13920, Loss 0.01622270606458187\n",
            "\t\tTrain step - Step 13950, Loss 0.01853400468826294\n",
            "\t\tTrain step - Step 13980, Loss 0.01616525836288929\n",
            "\t\tTrain step - Step 14010, Loss 0.013939314521849155\n",
            "\t\tTrain step - Step 14040, Loss 0.01600007899105549\n",
            "\t\tTrain step - Step 14070, Loss 0.01687774807214737\n",
            "\t\tTrain step - Step 14100, Loss 0.01819819211959839\n",
            "\t\tTrain step - Step 14130, Loss 0.015352798625826836\n",
            "\t\tTrain step - Step 14160, Loss 0.015919996425509453\n",
            "\t\tTrain step - Step 14190, Loss 0.01751406118273735\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.015885706404459816 - Train Accuracy: 0.7076740506329114\n",
            "\t\t\tVal Loss: 0.023469332243419357 - Val Accuracy: 0.5624444444444444\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 14220, Loss 0.013292293064296246\n",
            "\t\tTrain step - Step 14250, Loss 0.015216318890452385\n",
            "\t\tTrain step - Step 14280, Loss 0.013935093767940998\n",
            "\t\tTrain step - Step 14310, Loss 0.013079524040222168\n",
            "\t\tTrain step - Step 14340, Loss 0.01583796553313732\n",
            "\t\tTrain step - Step 14370, Loss 0.015624930150806904\n",
            "\t\tTrain step - Step 14400, Loss 0.01577562466263771\n",
            "\t\tTrain step - Step 14430, Loss 0.016327179968357086\n",
            "\t\tTrain step - Step 14460, Loss 0.015015484765172005\n",
            "\t\tTrain step - Step 14490, Loss 0.017147285863757133\n",
            "\t\tTrain step - Step 14520, Loss 0.01531869824975729\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.015930176827514284 - Train Accuracy: 0.7064626186708861\n",
            "\t\t\tVal Loss: 0.023796975819600955 - Val Accuracy: 0.5611111111111111\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 14550, Loss 0.014810818247497082\n",
            "\t\tTrain step - Step 14580, Loss 0.015063218772411346\n",
            "\t\tTrain step - Step 14610, Loss 0.014451727271080017\n",
            "\t\tTrain step - Step 14640, Loss 0.01650753989815712\n",
            "\t\tTrain step - Step 14670, Loss 0.015725577250123024\n",
            "\t\tTrain step - Step 14700, Loss 0.01771451160311699\n",
            "\t\tTrain step - Step 14730, Loss 0.015528383664786816\n",
            "\t\tTrain step - Step 14760, Loss 0.01837647333741188\n",
            "\t\tTrain step - Step 14790, Loss 0.015995455905795097\n",
            "\t\tTrain step - Step 14820, Loss 0.015540708787739277\n",
            "\t\tTrain step - Step 14850, Loss 0.017140740528702736\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.01601422957993478 - Train Accuracy: 0.7049050632911392\n",
            "\t\t\tVal Loss: 0.022960189419488113 - Val Accuracy: 0.5797777777777777\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 14880, Loss 0.01587795652449131\n",
            "\t\tTrain step - Step 14910, Loss 0.013591300696134567\n",
            "\t\tTrain step - Step 14940, Loss 0.0161613579839468\n",
            "\t\tTrain step - Step 14970, Loss 0.015395818278193474\n",
            "\t\tTrain step - Step 15000, Loss 0.015067634172737598\n",
            "\t\tTrain step - Step 15030, Loss 0.01402425765991211\n",
            "\t\tTrain step - Step 15060, Loss 0.015595896169543266\n",
            "\t\tTrain step - Step 15090, Loss 0.0168218482285738\n",
            "\t\tTrain step - Step 15120, Loss 0.015147976577281952\n",
            "\t\tTrain step - Step 15150, Loss 0.015866434201598167\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.015737541629991764 - Train Accuracy: 0.7095530063291139\n",
            "\t\t\tVal Loss: 0.02314748542590274 - Val Accuracy: 0.5693333333333334\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 15180, Loss 0.017849218100309372\n",
            "\t\tTrain step - Step 15210, Loss 0.01588146574795246\n",
            "\t\tTrain step - Step 15240, Loss 0.015854692086577415\n",
            "\t\tTrain step - Step 15270, Loss 0.01475558988749981\n",
            "\t\tTrain step - Step 15300, Loss 0.018835600465536118\n",
            "\t\tTrain step - Step 15330, Loss 0.015903515741229057\n",
            "\t\tTrain step - Step 15360, Loss 0.0176247525960207\n",
            "\t\tTrain step - Step 15390, Loss 0.018116669729351997\n",
            "\t\tTrain step - Step 15420, Loss 0.015670230612158775\n",
            "\t\tTrain step - Step 15450, Loss 0.013470406644046307\n",
            "\t\tTrain step - Step 15480, Loss 0.016126006841659546\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.015655402898717717 - Train Accuracy: 0.7134098101265823\n",
            "\t\t\tVal Loss: 0.023049560142681003 - Val Accuracy: 0.5804444444444444\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 15510, Loss 0.012091748416423798\n",
            "\t\tTrain step - Step 15540, Loss 0.008868029341101646\n",
            "\t\tTrain step - Step 15570, Loss 0.013826783746480942\n",
            "\t\tTrain step - Step 15600, Loss 0.012828162871301174\n",
            "\t\tTrain step - Step 15630, Loss 0.013291005976498127\n",
            "\t\tTrain step - Step 15660, Loss 0.009705009870231152\n",
            "\t\tTrain step - Step 15690, Loss 0.011861572042107582\n",
            "\t\tTrain step - Step 15720, Loss 0.00901821069419384\n",
            "\t\tTrain step - Step 15750, Loss 0.010452406480908394\n",
            "\t\tTrain step - Step 15780, Loss 0.011791808530688286\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.011558200913493204 - Train Accuracy: 0.7987292325949367\n",
            "\t\t\tVal Loss: 0.016503285771856707 - Val Accuracy: 0.6913333333333334\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 15810, Loss 0.01092870905995369\n",
            "\t\tTrain step - Step 15840, Loss 0.009112945757806301\n",
            "\t\tTrain step - Step 15870, Loss 0.010954332537949085\n",
            "\t\tTrain step - Step 15900, Loss 0.010265562683343887\n",
            "\t\tTrain step - Step 15930, Loss 0.007807306945323944\n",
            "\t\tTrain step - Step 15960, Loss 0.0111356470733881\n",
            "\t\tTrain step - Step 15990, Loss 0.009816745296120644\n",
            "\t\tTrain step - Step 16020, Loss 0.011532058008015156\n",
            "\t\tTrain step - Step 16050, Loss 0.010069599375128746\n",
            "\t\tTrain step - Step 16080, Loss 0.00951467826962471\n",
            "\t\tTrain step - Step 16110, Loss 0.010084620676934719\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.010277195982458187 - Train Accuracy: 0.8241198575949367\n",
            "\t\t\tVal Loss: 0.016608450691112213 - Val Accuracy: 0.6942222222222222\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 16140, Loss 0.009905291721224785\n",
            "\t\tTrain step - Step 16170, Loss 0.00965521577745676\n",
            "\t\tTrain step - Step 16200, Loss 0.008507465943694115\n",
            "\t\tTrain step - Step 16230, Loss 0.010244378820061684\n",
            "\t\tTrain step - Step 16260, Loss 0.009245110675692558\n",
            "\t\tTrain step - Step 16290, Loss 0.009367001242935658\n",
            "\t\tTrain step - Step 16320, Loss 0.010392011143267155\n",
            "\t\tTrain step - Step 16350, Loss 0.010608658194541931\n",
            "\t\tTrain step - Step 16380, Loss 0.011116757057607174\n",
            "\t\tTrain step - Step 16410, Loss 0.010382251814007759\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.009791027551186802 - Train Accuracy: 0.8333415743670886\n",
            "\t\t\tVal Loss: 0.01693944543755303 - Val Accuracy: 0.688\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 16440, Loss 0.009176618419587612\n",
            "\t\tTrain step - Step 16470, Loss 0.01079745963215828\n",
            "\t\tTrain step - Step 16500, Loss 0.008846900425851345\n",
            "\t\tTrain step - Step 16530, Loss 0.00934383925050497\n",
            "\t\tTrain step - Step 16560, Loss 0.008373378776013851\n",
            "\t\tTrain step - Step 16590, Loss 0.008760633878409863\n",
            "\t\tTrain step - Step 16620, Loss 0.008579672314226627\n",
            "\t\tTrain step - Step 16650, Loss 0.009055445902049541\n",
            "\t\tTrain step - Step 16680, Loss 0.007011433131992817\n",
            "\t\tTrain step - Step 16710, Loss 0.011427199468016624\n",
            "\t\tTrain step - Step 16740, Loss 0.009806625545024872\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.009463671301609447 - Train Accuracy: 0.8393492879746836\n",
            "\t\t\tVal Loss: 0.01730150905334287 - Val Accuracy: 0.6857777777777778\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 16770, Loss 0.007235122378915548\n",
            "\t\tTrain step - Step 16800, Loss 0.009137529879808426\n",
            "\t\tTrain step - Step 16830, Loss 0.009948497638106346\n",
            "\t\tTrain step - Step 16860, Loss 0.01104370690882206\n",
            "\t\tTrain step - Step 16890, Loss 0.007570965681225061\n",
            "\t\tTrain step - Step 16920, Loss 0.009664282202720642\n",
            "\t\tTrain step - Step 16950, Loss 0.009836150333285332\n",
            "\t\tTrain step - Step 16980, Loss 0.010223831981420517\n",
            "\t\tTrain step - Step 17010, Loss 0.011663918383419514\n",
            "\t\tTrain step - Step 17040, Loss 0.008779721334576607\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.009187643855362188 - Train Accuracy: 0.8446400316455697\n",
            "\t\t\tVal Loss: 0.017354977938036125 - Val Accuracy: 0.6924444444444444\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 17070, Loss 0.009345694445073605\n",
            "\t\tTrain step - Step 17100, Loss 0.010443258099257946\n",
            "\t\tTrain step - Step 17130, Loss 0.008526825346052647\n",
            "\t\tTrain step - Step 17160, Loss 0.007119740825146437\n",
            "\t\tTrain step - Step 17190, Loss 0.008549519814550877\n",
            "\t\tTrain step - Step 17220, Loss 0.010323761031031609\n",
            "\t\tTrain step - Step 17250, Loss 0.008597669191658497\n",
            "\t\tTrain step - Step 17280, Loss 0.010013258084654808\n",
            "\t\tTrain step - Step 17310, Loss 0.009617161937057972\n",
            "\t\tTrain step - Step 17340, Loss 0.00891140103340149\n",
            "\t\tTrain step - Step 17370, Loss 0.009793493896722794\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.008992278485712183 - Train Accuracy: 0.8481012658227848\n",
            "\t\t\tVal Loss: 0.017071297159418464 - Val Accuracy: 0.69\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 17400, Loss 0.009523455053567886\n",
            "\t\tTrain step - Step 17430, Loss 0.0072321477346122265\n",
            "\t\tTrain step - Step 17460, Loss 0.007678647991269827\n",
            "\t\tTrain step - Step 17490, Loss 0.009730181656777859\n",
            "\t\tTrain step - Step 17520, Loss 0.00697436323389411\n",
            "\t\tTrain step - Step 17550, Loss 0.007603317964822054\n",
            "\t\tTrain step - Step 17580, Loss 0.00785538274794817\n",
            "\t\tTrain step - Step 17610, Loss 0.009645478799939156\n",
            "\t\tTrain step - Step 17640, Loss 0.009295494295656681\n",
            "\t\tTrain step - Step 17670, Loss 0.010870163328945637\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.008866093918692934 - Train Accuracy: 0.8503510680379747\n",
            "\t\t\tVal Loss: 0.017349569734910295 - Val Accuracy: 0.6773333333333333\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 17700, Loss 0.007915372960269451\n",
            "\t\tTrain step - Step 17730, Loss 0.008758697658777237\n",
            "\t\tTrain step - Step 17760, Loss 0.00766085647046566\n",
            "\t\tTrain step - Step 17790, Loss 0.007361020892858505\n",
            "\t\tTrain step - Step 17820, Loss 0.008965251967310905\n",
            "\t\tTrain step - Step 17850, Loss 0.011315559968352318\n",
            "\t\tTrain step - Step 17880, Loss 0.009242285043001175\n",
            "\t\tTrain step - Step 17910, Loss 0.0079177962616086\n",
            "\t\tTrain step - Step 17940, Loss 0.007504203822463751\n",
            "\t\tTrain step - Step 17970, Loss 0.009050167165696621\n",
            "\t\tTrain step - Step 18000, Loss 0.008790749125182629\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.008714409079402685 - Train Accuracy: 0.8521805775316456\n",
            "\t\t\tVal Loss: 0.01789934056190153 - Val Accuracy: 0.6868888888888889\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 18030, Loss 0.006417719181627035\n",
            "\t\tTrain step - Step 18060, Loss 0.007589174900203943\n",
            "\t\tTrain step - Step 18090, Loss 0.00767497206106782\n",
            "\t\tTrain step - Step 18120, Loss 0.007608442101627588\n",
            "\t\tTrain step - Step 18150, Loss 0.00879477709531784\n",
            "\t\tTrain step - Step 18180, Loss 0.008570029400289059\n",
            "\t\tTrain step - Step 18210, Loss 0.008009458892047405\n",
            "\t\tTrain step - Step 18240, Loss 0.009927473962306976\n",
            "\t\tTrain step - Step 18270, Loss 0.008121218532323837\n",
            "\t\tTrain step - Step 18300, Loss 0.007168303709477186\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.008650959000769483 - Train Accuracy: 0.8535403481012658\n",
            "\t\t\tVal Loss: 0.01734626344922516 - Val Accuracy: 0.688\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 18330, Loss 0.010932466946542263\n",
            "\t\tTrain step - Step 18360, Loss 0.009522760286927223\n",
            "\t\tTrain step - Step 18390, Loss 0.008370987139642239\n",
            "\t\tTrain step - Step 18420, Loss 0.00792202539741993\n",
            "\t\tTrain step - Step 18450, Loss 0.007373282685875893\n",
            "\t\tTrain step - Step 18480, Loss 0.008268604055047035\n",
            "\t\tTrain step - Step 18510, Loss 0.006669061258435249\n",
            "\t\tTrain step - Step 18540, Loss 0.00909400824457407\n",
            "\t\tTrain step - Step 18570, Loss 0.006286070682108402\n",
            "\t\tTrain step - Step 18600, Loss 0.011192834004759789\n",
            "\t\tTrain step - Step 18630, Loss 0.008307143114507198\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.008550393747319055 - Train Accuracy: 0.8567543512658228\n",
            "\t\t\tVal Loss: 0.01769097356332673 - Val Accuracy: 0.6791111111111111\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 18660, Loss 0.008029247634112835\n",
            "\t\tTrain step - Step 18690, Loss 0.00811663269996643\n",
            "\t\tTrain step - Step 18720, Loss 0.008393198251724243\n",
            "\t\tTrain step - Step 18750, Loss 0.007900229655206203\n",
            "\t\tTrain step - Step 18780, Loss 0.009022746235132217\n",
            "\t\tTrain step - Step 18810, Loss 0.009066729806363583\n",
            "\t\tTrain step - Step 18840, Loss 0.008020695298910141\n",
            "\t\tTrain step - Step 18870, Loss 0.007525457069277763\n",
            "\t\tTrain step - Step 18900, Loss 0.008620425127446651\n",
            "\t\tTrain step - Step 18930, Loss 0.009277832694351673\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.008513129855612223 - Train Accuracy: 0.854356210443038\n",
            "\t\t\tVal Loss: 0.017772964408828154 - Val Accuracy: 0.6855555555555556\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 18960, Loss 0.008167200721800327\n",
            "\t\tTrain step - Step 18990, Loss 0.008824404329061508\n",
            "\t\tTrain step - Step 19020, Loss 0.007468892727047205\n",
            "\t\tTrain step - Step 19050, Loss 0.008015159517526627\n",
            "\t\tTrain step - Step 19080, Loss 0.008911424316465855\n",
            "\t\tTrain step - Step 19110, Loss 0.0066024670377373695\n",
            "\t\tTrain step - Step 19140, Loss 0.007768274284899235\n",
            "\t\tTrain step - Step 19170, Loss 0.00847481470555067\n",
            "\t\tTrain step - Step 19200, Loss 0.008475893177092075\n",
            "\t\tTrain step - Step 19230, Loss 0.008330686949193478\n",
            "\t\tTrain step - Step 19260, Loss 0.007064364850521088\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.008412486626000344 - Train Accuracy: 0.8572240901898734\n",
            "\t\t\tVal Loss: 0.01768114598881867 - Val Accuracy: 0.6862222222222222\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 19290, Loss 0.006675569340586662\n",
            "\t\tTrain step - Step 19320, Loss 0.011646809056401253\n",
            "\t\tTrain step - Step 19350, Loss 0.006511386949568987\n",
            "\t\tTrain step - Step 19380, Loss 0.008218890987336636\n",
            "\t\tTrain step - Step 19410, Loss 0.008993499912321568\n",
            "\t\tTrain step - Step 19440, Loss 0.010040747933089733\n",
            "\t\tTrain step - Step 19470, Loss 0.007696269080042839\n",
            "\t\tTrain step - Step 19500, Loss 0.01007093209773302\n",
            "\t\tTrain step - Step 19530, Loss 0.008835261687636375\n",
            "\t\tTrain step - Step 19560, Loss 0.007912051863968372\n",
            "\t\tTrain step - Step 19590, Loss 0.008788389153778553\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.00833631400461014 - Train Accuracy: 0.8598200158227848\n",
            "\t\t\tVal Loss: 0.01836710203335517 - Val Accuracy: 0.6704444444444444\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 19620, Loss 0.007145498413592577\n",
            "\t\tTrain step - Step 19650, Loss 0.0076242112554609776\n",
            "\t\tTrain step - Step 19680, Loss 0.007989282719790936\n",
            "\t\tTrain step - Step 19710, Loss 0.007473083678632975\n",
            "\t\tTrain step - Step 19740, Loss 0.007062847260385752\n",
            "\t\tTrain step - Step 19770, Loss 0.0075278570875525475\n",
            "\t\tTrain step - Step 19800, Loss 0.007072049658745527\n",
            "\t\tTrain step - Step 19830, Loss 0.007578587159514427\n",
            "\t\tTrain step - Step 19860, Loss 0.007743082009255886\n",
            "\t\tTrain step - Step 19890, Loss 0.008216088637709618\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.008237586484903681 - Train Accuracy: 0.8615753560126582\n",
            "\t\t\tVal Loss: 0.018014074872351356 - Val Accuracy: 0.6766666666666666\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 19920, Loss 0.008850031532347202\n",
            "\t\tTrain step - Step 19950, Loss 0.006613775156438351\n",
            "\t\tTrain step - Step 19980, Loss 0.008132267743349075\n",
            "\t\tTrain step - Step 20010, Loss 0.006333812139928341\n",
            "\t\tTrain step - Step 20040, Loss 0.0066582756116986275\n",
            "\t\tTrain step - Step 20070, Loss 0.008303472772240639\n",
            "\t\tTrain step - Step 20100, Loss 0.009022141806781292\n",
            "\t\tTrain step - Step 20130, Loss 0.006412416696548462\n",
            "\t\tTrain step - Step 20160, Loss 0.008240205235779285\n",
            "\t\tTrain step - Step 20190, Loss 0.005745359696447849\n",
            "\t\tTrain step - Step 20220, Loss 0.009589282795786858\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.007046751738408038 - Train Accuracy: 0.8883751977848101\n",
            "\t\t\tVal Loss: 0.017139175596336525 - Val Accuracy: 0.7026666666666667\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 20250, Loss 0.008323874324560165\n",
            "\t\tTrain step - Step 20280, Loss 0.0060771917924284935\n",
            "\t\tTrain step - Step 20310, Loss 0.005888236220926046\n",
            "\t\tTrain step - Step 20340, Loss 0.005421534646302462\n",
            "\t\tTrain step - Step 20370, Loss 0.006741083227097988\n",
            "\t\tTrain step - Step 20400, Loss 0.005848164204508066\n",
            "\t\tTrain step - Step 20430, Loss 0.005748759489506483\n",
            "\t\tTrain step - Step 20460, Loss 0.004762250930070877\n",
            "\t\tTrain step - Step 20490, Loss 0.007103521842509508\n",
            "\t\tTrain step - Step 20520, Loss 0.008712466806173325\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.00663181575592843 - Train Accuracy: 0.8967810522151899\n",
            "\t\t\tVal Loss: 0.016728021644262805 - Val Accuracy: 0.7097777777777777\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 20550, Loss 0.006133698858320713\n",
            "\t\tTrain step - Step 20580, Loss 0.006404179148375988\n",
            "\t\tTrain step - Step 20610, Loss 0.006677926518023014\n",
            "\t\tTrain step - Step 20640, Loss 0.007260889280587435\n",
            "\t\tTrain step - Step 20670, Loss 0.007858801633119583\n",
            "\t\tTrain step - Step 20700, Loss 0.006269559729844332\n",
            "\t\tTrain step - Step 20730, Loss 0.0071585155092179775\n",
            "\t\tTrain step - Step 20760, Loss 0.006137286312878132\n",
            "\t\tTrain step - Step 20790, Loss 0.006724933162331581\n",
            "\t\tTrain step - Step 20820, Loss 0.008066697046160698\n",
            "\t\tTrain step - Step 20850, Loss 0.00568013172596693\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.006445476592259034 - Train Accuracy: 0.9007861946202531\n",
            "\t\t\tVal Loss: 0.016958646398658555 - Val Accuracy: 0.6995555555555556\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 20880, Loss 0.004847313277423382\n",
            "\t\tTrain step - Step 20910, Loss 0.005524960812181234\n",
            "\t\tTrain step - Step 20940, Loss 0.006119688507169485\n",
            "\t\tTrain step - Step 20970, Loss 0.007319123484194279\n",
            "\t\tTrain step - Step 21000, Loss 0.0074269878678023815\n",
            "\t\tTrain step - Step 21030, Loss 0.00777905760332942\n",
            "\t\tTrain step - Step 21060, Loss 0.0061490498483181\n",
            "\t\tTrain step - Step 21090, Loss 0.006111728027462959\n",
            "\t\tTrain step - Step 21120, Loss 0.007530638016760349\n",
            "\t\tTrain step - Step 21150, Loss 0.00588013743981719\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.006349823043440009 - Train Accuracy: 0.9015278876582279\n",
            "\t\t\tVal Loss: 0.016793124662298296 - Val Accuracy: 0.7057777777777777\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 21180, Loss 0.005297346971929073\n",
            "\t\tTrain step - Step 21210, Loss 0.00542831514030695\n",
            "\t\tTrain step - Step 21240, Loss 0.005787617992609739\n",
            "\t\tTrain step - Step 21270, Loss 0.006678236182779074\n",
            "\t\tTrain step - Step 21300, Loss 0.007279892917722464\n",
            "\t\tTrain step - Step 21330, Loss 0.005500648636370897\n",
            "\t\tTrain step - Step 21360, Loss 0.007118506357073784\n",
            "\t\tTrain step - Step 21390, Loss 0.006902768276631832\n",
            "\t\tTrain step - Step 21420, Loss 0.005303960759192705\n",
            "\t\tTrain step - Step 21450, Loss 0.005701628979295492\n",
            "\t\tTrain step - Step 21480, Loss 0.0062429229728877544\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.006255793918655077 - Train Accuracy: 0.9034810126582279\n",
            "\t\t\tVal Loss: 0.016689077381872468 - Val Accuracy: 0.7111111111111111\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 21510, Loss 0.005874992348253727\n",
            "\t\tTrain step - Step 21540, Loss 0.0058118985034525394\n",
            "\t\tTrain step - Step 21570, Loss 0.006677526514977217\n",
            "\t\tTrain step - Step 21600, Loss 0.007103166542947292\n",
            "\t\tTrain step - Step 21630, Loss 0.006183273624628782\n",
            "\t\tTrain step - Step 21660, Loss 0.0063043092377483845\n",
            "\t\tTrain step - Step 21690, Loss 0.005602296441793442\n",
            "\t\tTrain step - Step 21720, Loss 0.00655920896679163\n",
            "\t\tTrain step - Step 21750, Loss 0.006635329686105251\n",
            "\t\tTrain step - Step 21780, Loss 0.007396406959742308\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.006102727415169813 - Train Accuracy: 0.9078570015822784\n",
            "\t\t\tVal Loss: 0.01701476652589109 - Val Accuracy: 0.7097777777777777\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 21810, Loss 0.007354510482400656\n",
            "\t\tTrain step - Step 21840, Loss 0.006452169734984636\n",
            "\t\tTrain step - Step 21870, Loss 0.006169195752590895\n",
            "\t\tTrain step - Step 21900, Loss 0.007128377445042133\n",
            "\t\tTrain step - Step 21930, Loss 0.005453610327094793\n",
            "\t\tTrain step - Step 21960, Loss 0.005392769351601601\n",
            "\t\tTrain step - Step 21990, Loss 0.00545493233948946\n",
            "\t\tTrain step - Step 22020, Loss 0.005819014739245176\n",
            "\t\tTrain step - Step 22050, Loss 0.003830013796687126\n",
            "\t\tTrain step - Step 22080, Loss 0.007025640923529863\n",
            "\t\tTrain step - Step 22110, Loss 0.007810673676431179\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/71 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.006101973116091347 - Train Accuracy: 0.9059533227848101\n",
            "\t\t\tVal Loss: 0.01690119629104932 - Val Accuracy: 0.6986666666666667\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 71/71 [00:02<00:00, 28.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 9:\n",
            "\t\tTrain Mean Accuracy: 0.7493473101265823\n",
            "\t\tVal Mean Accuracy: 0.6040603174603175\n",
            "\t\tTest Accuracy: 0.6917777777777778\n",
            "\n",
            "STARTING JOINT TRAINING STAGE 10...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n",
            "\t\tTrain step - Step 30, Loss 0.018495306372642517\n",
            "\t\tTrain step - Step 60, Loss 0.017978714779019356\n",
            "\t\tTrain step - Step 90, Loss 0.018051862716674805\n",
            "\t\tTrain step - Step 120, Loss 0.02147437445819378\n",
            "\t\tTrain step - Step 150, Loss 0.018055791035294533\n",
            "\t\tTrain step - Step 180, Loss 0.01491030864417553\n",
            "\t\tTrain step - Step 210, Loss 0.02047092467546463\n",
            "\t\tTrain step - Step 240, Loss 0.018119201064109802\n",
            "\t\tTrain step - Step 270, Loss 0.019915936514735222\n",
            "\t\tTrain step - Step 300, Loss 0.019450994208455086\n",
            "\t\tTrain step - Step 330, Loss 0.0187518410384655\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.019138516200191615 - Train Accuracy: 0.6501290954415955\n",
            "\t\t\tVal Loss: 0.025067963148467244 - Val Accuracy: 0.5494\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.019295237958431244\n",
            "\t\tTrain step - Step 390, Loss 0.016563797369599342\n",
            "\t\tTrain step - Step 420, Loss 0.019376613199710846\n",
            "\t\tTrain step - Step 450, Loss 0.01890558749437332\n",
            "\t\tTrain step - Step 480, Loss 0.01844453252851963\n",
            "\t\tTrain step - Step 510, Loss 0.01903841644525528\n",
            "\t\tTrain step - Step 540, Loss 0.01834450475871563\n",
            "\t\tTrain step - Step 570, Loss 0.01943071000277996\n",
            "\t\tTrain step - Step 600, Loss 0.015515145845711231\n",
            "\t\tTrain step - Step 630, Loss 0.017644772306084633\n",
            "\t\tTrain step - Step 660, Loss 0.019249696284532547\n",
            "\t\tTrain step - Step 690, Loss 0.01597345620393753\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.018232451587321074 - Train Accuracy: 0.6640402421652422\n",
            "\t\t\tVal Loss: 0.025600013113580643 - Val Accuracy: 0.5342\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.016397854313254356\n",
            "\t\tTrain step - Step 750, Loss 0.019387805834412575\n",
            "\t\tTrain step - Step 780, Loss 0.01670456863939762\n",
            "\t\tTrain step - Step 810, Loss 0.016391728073358536\n",
            "\t\tTrain step - Step 840, Loss 0.018930720165371895\n",
            "\t\tTrain step - Step 870, Loss 0.019591649994254112\n",
            "\t\tTrain step - Step 900, Loss 0.01567426323890686\n",
            "\t\tTrain step - Step 930, Loss 0.01926163211464882\n",
            "\t\tTrain step - Step 960, Loss 0.020135311409831047\n",
            "\t\tTrain step - Step 990, Loss 0.01905784010887146\n",
            "\t\tTrain step - Step 1020, Loss 0.018673833459615707\n",
            "\t\tTrain step - Step 1050, Loss 0.020244240760803223\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.018120044606215083 - Train Accuracy: 0.6679798789173789\n",
            "\t\t\tVal Loss: 0.023505146778188647 - Val Accuracy: 0.5716\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 1080, Loss 0.01660258322954178\n",
            "\t\tTrain step - Step 1110, Loss 0.015467296354472637\n",
            "\t\tTrain step - Step 1140, Loss 0.01812141388654709\n",
            "\t\tTrain step - Step 1170, Loss 0.020293477922677994\n",
            "\t\tTrain step - Step 1200, Loss 0.020209133625030518\n",
            "\t\tTrain step - Step 1230, Loss 0.02108139544725418\n",
            "\t\tTrain step - Step 1260, Loss 0.017437735572457314\n",
            "\t\tTrain step - Step 1290, Loss 0.017454860731959343\n",
            "\t\tTrain step - Step 1320, Loss 0.01917172595858574\n",
            "\t\tTrain step - Step 1350, Loss 0.01990118809044361\n",
            "\t\tTrain step - Step 1380, Loss 0.020688069984316826\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.017920176594112165 - Train Accuracy: 0.6701834045584045\n",
            "\t\t\tVal Loss: 0.026064428919926285 - Val Accuracy: 0.5202\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.016819436103105545\n",
            "\t\tTrain step - Step 1440, Loss 0.018905034288764\n",
            "\t\tTrain step - Step 1470, Loss 0.015318888239562511\n",
            "\t\tTrain step - Step 1500, Loss 0.017852842807769775\n",
            "\t\tTrain step - Step 1530, Loss 0.01921205408871174\n",
            "\t\tTrain step - Step 1560, Loss 0.01808428019285202\n",
            "\t\tTrain step - Step 1590, Loss 0.01933174580335617\n",
            "\t\tTrain step - Step 1620, Loss 0.01958560012280941\n",
            "\t\tTrain step - Step 1650, Loss 0.018307862803339958\n",
            "\t\tTrain step - Step 1680, Loss 0.018169263377785683\n",
            "\t\tTrain step - Step 1710, Loss 0.021335484459996223\n",
            "\t\tTrain step - Step 1740, Loss 0.01638241671025753\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.017797363340918325 - Train Accuracy: 0.6731436965811965\n",
            "\t\t\tVal Loss: 0.025277000619098544 - Val Accuracy: 0.551\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 1770, Loss 0.0164861511439085\n",
            "\t\tTrain step - Step 1800, Loss 0.015581745654344559\n",
            "\t\tTrain step - Step 1830, Loss 0.01753200963139534\n",
            "\t\tTrain step - Step 1860, Loss 0.016645755618810654\n",
            "\t\tTrain step - Step 1890, Loss 0.015179111622273922\n",
            "\t\tTrain step - Step 1920, Loss 0.019705528393387794\n",
            "\t\tTrain step - Step 1950, Loss 0.017733830958604813\n",
            "\t\tTrain step - Step 1980, Loss 0.020528508350253105\n",
            "\t\tTrain step - Step 2010, Loss 0.01885378360748291\n",
            "\t\tTrain step - Step 2040, Loss 0.0159673560410738\n",
            "\t\tTrain step - Step 2070, Loss 0.018845241516828537\n",
            "\t\tTrain step - Step 2100, Loss 0.020599670708179474\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.01779477924182799 - Train Accuracy: 0.6720308048433048\n",
            "\t\t\tVal Loss: 0.026194385020062327 - Val Accuracy: 0.53\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 2130, Loss 0.018255600705742836\n",
            "\t\tTrain step - Step 2160, Loss 0.01807960495352745\n",
            "\t\tTrain step - Step 2190, Loss 0.01676039956510067\n",
            "\t\tTrain step - Step 2220, Loss 0.019802799448370934\n",
            "\t\tTrain step - Step 2250, Loss 0.020544370636343956\n",
            "\t\tTrain step - Step 2280, Loss 0.019504811614751816\n",
            "\t\tTrain step - Step 2310, Loss 0.0171719528734684\n",
            "\t\tTrain step - Step 2340, Loss 0.018611321225762367\n",
            "\t\tTrain step - Step 2370, Loss 0.021396785974502563\n",
            "\t\tTrain step - Step 2400, Loss 0.020915068686008453\n",
            "\t\tTrain step - Step 2430, Loss 0.018190134316682816\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.01773477542317576 - Train Accuracy: 0.6741898148148148\n",
            "\t\t\tVal Loss: 0.02519710287451744 - Val Accuracy: 0.5358\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 2460, Loss 0.013637188822031021\n",
            "\t\tTrain step - Step 2490, Loss 0.01771482825279236\n",
            "\t\tTrain step - Step 2520, Loss 0.016584983095526695\n",
            "\t\tTrain step - Step 2550, Loss 0.018904410302639008\n",
            "\t\tTrain step - Step 2580, Loss 0.018940474838018417\n",
            "\t\tTrain step - Step 2610, Loss 0.018701106309890747\n",
            "\t\tTrain step - Step 2640, Loss 0.019496213644742966\n",
            "\t\tTrain step - Step 2670, Loss 0.018419446423649788\n",
            "\t\tTrain step - Step 2700, Loss 0.017865601927042007\n",
            "\t\tTrain step - Step 2730, Loss 0.01899842731654644\n",
            "\t\tTrain step - Step 2760, Loss 0.018652891740202904\n",
            "\t\tTrain step - Step 2790, Loss 0.01656818576157093\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.017602543160849995 - Train Accuracy: 0.6781739672364673\n",
            "\t\t\tVal Loss: 0.02398703689686954 - Val Accuracy: 0.563\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 2820, Loss 0.015351742506027222\n",
            "\t\tTrain step - Step 2850, Loss 0.016354689374566078\n",
            "\t\tTrain step - Step 2880, Loss 0.016883838921785355\n",
            "\t\tTrain step - Step 2910, Loss 0.01683724671602249\n",
            "\t\tTrain step - Step 2940, Loss 0.019482390955090523\n",
            "\t\tTrain step - Step 2970, Loss 0.018304266035556793\n",
            "\t\tTrain step - Step 3000, Loss 0.018441464751958847\n",
            "\t\tTrain step - Step 3030, Loss 0.016018087044358253\n",
            "\t\tTrain step - Step 3060, Loss 0.017416279762983322\n",
            "\t\tTrain step - Step 3090, Loss 0.014783565886318684\n",
            "\t\tTrain step - Step 3120, Loss 0.02033344656229019\n",
            "\t\tTrain step - Step 3150, Loss 0.018810657784342766\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.0177296936602207 - Train Accuracy: 0.6738782051282052\n",
            "\t\t\tVal Loss: 0.024657333828508855 - Val Accuracy: 0.5476\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 3180, Loss 0.014546973630785942\n",
            "\t\tTrain step - Step 3210, Loss 0.016585443168878555\n",
            "\t\tTrain step - Step 3240, Loss 0.01607992872595787\n",
            "\t\tTrain step - Step 3270, Loss 0.014816805720329285\n",
            "\t\tTrain step - Step 3300, Loss 0.017050137743353844\n",
            "\t\tTrain step - Step 3330, Loss 0.015099536627531052\n",
            "\t\tTrain step - Step 3360, Loss 0.019881751388311386\n",
            "\t\tTrain step - Step 3390, Loss 0.01812141388654709\n",
            "\t\tTrain step - Step 3420, Loss 0.016525084152817726\n",
            "\t\tTrain step - Step 3450, Loss 0.017065836116671562\n",
            "\t\tTrain step - Step 3480, Loss 0.016971547156572342\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.017624768141943675 - Train Accuracy: 0.6773281695156695\n",
            "\t\t\tVal Loss: 0.02459458007942885 - Val Accuracy: 0.5536\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 3510, Loss 0.018606290221214294\n",
            "\t\tTrain step - Step 3540, Loss 0.01594087854027748\n",
            "\t\tTrain step - Step 3570, Loss 0.01592559926211834\n",
            "\t\tTrain step - Step 3600, Loss 0.017447272315621376\n",
            "\t\tTrain step - Step 3630, Loss 0.018281307071447372\n",
            "\t\tTrain step - Step 3660, Loss 0.015969224274158478\n",
            "\t\tTrain step - Step 3690, Loss 0.017377709969878197\n",
            "\t\tTrain step - Step 3720, Loss 0.019355973228812218\n",
            "\t\tTrain step - Step 3750, Loss 0.018201759085059166\n",
            "\t\tTrain step - Step 3780, Loss 0.01734444685280323\n",
            "\t\tTrain step - Step 3810, Loss 0.018695197999477386\n",
            "\t\tTrain step - Step 3840, Loss 0.016935694962739944\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.01756369020588208 - Train Accuracy: 0.6771278490028491\n",
            "\t\t\tVal Loss: 0.024331737379543483 - Val Accuracy: 0.5522\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 3870, Loss 0.013326559215784073\n",
            "\t\tTrain step - Step 3900, Loss 0.018895016983151436\n",
            "\t\tTrain step - Step 3930, Loss 0.01704564318060875\n",
            "\t\tTrain step - Step 3960, Loss 0.01692967861890793\n",
            "\t\tTrain step - Step 3990, Loss 0.018112855032086372\n",
            "\t\tTrain step - Step 4020, Loss 0.02251269854605198\n",
            "\t\tTrain step - Step 4050, Loss 0.016087155789136887\n",
            "\t\tTrain step - Step 4080, Loss 0.017723392695188522\n",
            "\t\tTrain step - Step 4110, Loss 0.017226915806531906\n",
            "\t\tTrain step - Step 4140, Loss 0.0193179864436388\n",
            "\t\tTrain step - Step 4170, Loss 0.017346002161502838\n",
            "\t\tTrain step - Step 4200, Loss 0.01821480505168438\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.01755262818452809 - Train Accuracy: 0.6793313746438746\n",
            "\t\t\tVal Loss: 0.024144564708694815 - Val Accuracy: 0.559\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 4230, Loss 0.015374688431620598\n",
            "\t\tTrain step - Step 4260, Loss 0.015044975094497204\n",
            "\t\tTrain step - Step 4290, Loss 0.014770020730793476\n",
            "\t\tTrain step - Step 4320, Loss 0.02066943608224392\n",
            "\t\tTrain step - Step 4350, Loss 0.015155320055782795\n",
            "\t\tTrain step - Step 4380, Loss 0.01769281178712845\n",
            "\t\tTrain step - Step 4410, Loss 0.019228145480155945\n",
            "\t\tTrain step - Step 4440, Loss 0.017745329067111015\n",
            "\t\tTrain step - Step 4470, Loss 0.019150570034980774\n",
            "\t\tTrain step - Step 4500, Loss 0.01716465689241886\n",
            "\t\tTrain step - Step 4530, Loss 0.018973281607031822\n",
            "\t\tTrain step - Step 4560, Loss 0.016074998304247856\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.01749714494197287 - Train Accuracy: 0.6795762108262108\n",
            "\t\t\tVal Loss: 0.024459629063494505 - Val Accuracy: 0.5474\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 4590, Loss 0.016393516212701797\n",
            "\t\tTrain step - Step 4620, Loss 0.015727370977401733\n",
            "\t\tTrain step - Step 4650, Loss 0.01615043170750141\n",
            "\t\tTrain step - Step 4680, Loss 0.01853831671178341\n",
            "\t\tTrain step - Step 4710, Loss 0.018918270245194435\n",
            "\t\tTrain step - Step 4740, Loss 0.01706111803650856\n",
            "\t\tTrain step - Step 4770, Loss 0.018165530636906624\n",
            "\t\tTrain step - Step 4800, Loss 0.016488347202539444\n",
            "\t\tTrain step - Step 4830, Loss 0.019045991823077202\n",
            "\t\tTrain step - Step 4860, Loss 0.019179541617631912\n",
            "\t\tTrain step - Step 4890, Loss 0.017057739198207855\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.0174445484889581 - Train Accuracy: 0.6806445868945868\n",
            "\t\t\tVal Loss: 0.02406637272797525 - Val Accuracy: 0.5644\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 4920, Loss 0.01615622453391552\n",
            "\t\tTrain step - Step 4950, Loss 0.015926523134112358\n",
            "\t\tTrain step - Step 4980, Loss 0.01614893041551113\n",
            "\t\tTrain step - Step 5010, Loss 0.017017381265759468\n",
            "\t\tTrain step - Step 5040, Loss 0.01536385528743267\n",
            "\t\tTrain step - Step 5070, Loss 0.020468566566705704\n",
            "\t\tTrain step - Step 5100, Loss 0.0160553976893425\n",
            "\t\tTrain step - Step 5130, Loss 0.015326783061027527\n",
            "\t\tTrain step - Step 5160, Loss 0.014811784029006958\n",
            "\t\tTrain step - Step 5190, Loss 0.021964695304632187\n",
            "\t\tTrain step - Step 5220, Loss 0.01870814710855484\n",
            "\t\tTrain step - Step 5250, Loss 0.018557073548436165\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.017420012479982316 - Train Accuracy: 0.6813123219373219\n",
            "\t\t\tVal Loss: 0.02534255585633218 - Val Accuracy: 0.5358\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 5280, Loss 0.016439164057374\n",
            "\t\tTrain step - Step 5310, Loss 0.015700828284025192\n",
            "\t\tTrain step - Step 5340, Loss 0.01614660769701004\n",
            "\t\tTrain step - Step 5370, Loss 0.01619615964591503\n",
            "\t\tTrain step - Step 5400, Loss 0.01839439757168293\n",
            "\t\tTrain step - Step 5430, Loss 0.019807765260338783\n",
            "\t\tTrain step - Step 5460, Loss 0.016682345420122147\n",
            "\t\tTrain step - Step 5490, Loss 0.018697405233979225\n",
            "\t\tTrain step - Step 5520, Loss 0.015607761219143867\n",
            "\t\tTrain step - Step 5550, Loss 0.016559431329369545\n",
            "\t\tTrain step - Step 5580, Loss 0.02003769762814045\n",
            "\t\tTrain step - Step 5610, Loss 0.0182651374489069\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.01736418712098799 - Train Accuracy: 0.6830706908831908\n",
            "\t\t\tVal Loss: 0.023491937620565295 - Val Accuracy: 0.566\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 5640, Loss 0.01606184057891369\n",
            "\t\tTrain step - Step 5670, Loss 0.020754313096404076\n",
            "\t\tTrain step - Step 5700, Loss 0.015170063823461533\n",
            "\t\tTrain step - Step 5730, Loss 0.015360070392489433\n",
            "\t\tTrain step - Step 5760, Loss 0.015326809138059616\n",
            "\t\tTrain step - Step 5790, Loss 0.01764960214495659\n",
            "\t\tTrain step - Step 5820, Loss 0.020392639562487602\n",
            "\t\tTrain step - Step 5850, Loss 0.0192714836448431\n",
            "\t\tTrain step - Step 5880, Loss 0.019160857424139977\n",
            "\t\tTrain step - Step 5910, Loss 0.01983199268579483\n",
            "\t\tTrain step - Step 5940, Loss 0.017503513023257256\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.01746132723360914 - Train Accuracy: 0.6800658831908832\n",
            "\t\t\tVal Loss: 0.02333207558840513 - Val Accuracy: 0.5738\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 5970, Loss 0.01537369191646576\n",
            "\t\tTrain step - Step 6000, Loss 0.016315938904881477\n",
            "\t\tTrain step - Step 6030, Loss 0.014398162253201008\n",
            "\t\tTrain step - Step 6060, Loss 0.017741108313202858\n",
            "\t\tTrain step - Step 6090, Loss 0.02037857286632061\n",
            "\t\tTrain step - Step 6120, Loss 0.015851911157369614\n",
            "\t\tTrain step - Step 6150, Loss 0.01726950891315937\n",
            "\t\tTrain step - Step 6180, Loss 0.01671062782406807\n",
            "\t\tTrain step - Step 6210, Loss 0.016736144199967384\n",
            "\t\tTrain step - Step 6240, Loss 0.019704414531588554\n",
            "\t\tTrain step - Step 6270, Loss 0.016637861728668213\n",
            "\t\tTrain step - Step 6300, Loss 0.016290590167045593\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.017269626785165224 - Train Accuracy: 0.6848513176638177\n",
            "\t\t\tVal Loss: 0.024948371481150387 - Val Accuracy: 0.547\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 6330, Loss 0.01668936014175415\n",
            "\t\tTrain step - Step 6360, Loss 0.017290309071540833\n",
            "\t\tTrain step - Step 6390, Loss 0.018017590045928955\n",
            "\t\tTrain step - Step 6420, Loss 0.018922893330454826\n",
            "\t\tTrain step - Step 6450, Loss 0.018804384395480156\n",
            "\t\tTrain step - Step 6480, Loss 0.016725456342101097\n",
            "\t\tTrain step - Step 6510, Loss 0.019850250333547592\n",
            "\t\tTrain step - Step 6540, Loss 0.015559065155684948\n",
            "\t\tTrain step - Step 6570, Loss 0.01993594504892826\n",
            "\t\tTrain step - Step 6600, Loss 0.015898533165454865\n",
            "\t\tTrain step - Step 6630, Loss 0.021988634020090103\n",
            "\t\tTrain step - Step 6660, Loss 0.01787424460053444\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.017303124218754618 - Train Accuracy: 0.6853855056980057\n",
            "\t\t\tVal Loss: 0.025589200528338553 - Val Accuracy: 0.5334\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 6690, Loss 0.01771201752126217\n",
            "\t\tTrain step - Step 6720, Loss 0.013572201132774353\n",
            "\t\tTrain step - Step 6750, Loss 0.018264753744006157\n",
            "\t\tTrain step - Step 6780, Loss 0.016763314604759216\n",
            "\t\tTrain step - Step 6810, Loss 0.016356641426682472\n",
            "\t\tTrain step - Step 6840, Loss 0.014409761875867844\n",
            "\t\tTrain step - Step 6870, Loss 0.018274791538715363\n",
            "\t\tTrain step - Step 6900, Loss 0.015296058729290962\n",
            "\t\tTrain step - Step 6930, Loss 0.018167871981859207\n",
            "\t\tTrain step - Step 6960, Loss 0.015714731067419052\n",
            "\t\tTrain step - Step 6990, Loss 0.018628012388944626\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.01729074380814265 - Train Accuracy: 0.6825142450142451\n",
            "\t\t\tVal Loss: 0.02416593146044761 - Val Accuracy: 0.554\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 7020, Loss 0.014440574683248997\n",
            "\t\tTrain step - Step 7050, Loss 0.017207488417625427\n",
            "\t\tTrain step - Step 7080, Loss 0.01634243130683899\n",
            "\t\tTrain step - Step 7110, Loss 0.01995004341006279\n",
            "\t\tTrain step - Step 7140, Loss 0.016301287338137627\n",
            "\t\tTrain step - Step 7170, Loss 0.016152266412973404\n",
            "\t\tTrain step - Step 7200, Loss 0.018492456525564194\n",
            "\t\tTrain step - Step 7230, Loss 0.019414398819208145\n",
            "\t\tTrain step - Step 7260, Loss 0.01889338158071041\n",
            "\t\tTrain step - Step 7290, Loss 0.01619013585150242\n",
            "\t\tTrain step - Step 7320, Loss 0.01905057393014431\n",
            "\t\tTrain step - Step 7350, Loss 0.01968967355787754\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.017327076750157395 - Train Accuracy: 0.6844506766381766\n",
            "\t\t\tVal Loss: 0.024321190221235155 - Val Accuracy: 0.5546\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 7380, Loss 0.015109693631529808\n",
            "\t\tTrain step - Step 7410, Loss 0.015800420194864273\n",
            "\t\tTrain step - Step 7440, Loss 0.017317570745944977\n",
            "\t\tTrain step - Step 7470, Loss 0.01890045404434204\n",
            "\t\tTrain step - Step 7500, Loss 0.01735958643257618\n",
            "\t\tTrain step - Step 7530, Loss 0.017621546983718872\n",
            "\t\tTrain step - Step 7560, Loss 0.01765556074678898\n",
            "\t\tTrain step - Step 7590, Loss 0.015748484060168266\n",
            "\t\tTrain step - Step 7620, Loss 0.0184257123619318\n",
            "\t\tTrain step - Step 7650, Loss 0.01759530045092106\n",
            "\t\tTrain step - Step 7680, Loss 0.016988692805171013\n",
            "\t\tTrain step - Step 7710, Loss 0.019504712894558907\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.017233755463399947 - Train Accuracy: 0.6842058404558404\n",
            "\t\t\tVal Loss: 0.025365939387120305 - Val Accuracy: 0.5454\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 7740, Loss 0.016032658517360687\n",
            "\t\tTrain step - Step 7770, Loss 0.01591816172003746\n",
            "\t\tTrain step - Step 7800, Loss 0.018124431371688843\n",
            "\t\tTrain step - Step 7830, Loss 0.0173216313123703\n",
            "\t\tTrain step - Step 7860, Loss 0.01753992773592472\n",
            "\t\tTrain step - Step 7890, Loss 0.02071671187877655\n",
            "\t\tTrain step - Step 7920, Loss 0.016253190115094185\n",
            "\t\tTrain step - Step 7950, Loss 0.015225066803395748\n",
            "\t\tTrain step - Step 7980, Loss 0.016712598502635956\n",
            "\t\tTrain step - Step 8010, Loss 0.01569109410047531\n",
            "\t\tTrain step - Step 8040, Loss 0.015566655434668064\n",
            "\t\tTrain step - Step 8070, Loss 0.015507514588534832\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.017182272081488897 - Train Accuracy: 0.6854522792022792\n",
            "\t\t\tVal Loss: 0.02516132581513375 - Val Accuracy: 0.5432\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 8100, Loss 0.016201090067625046\n",
            "\t\tTrain step - Step 8130, Loss 0.01357552595436573\n",
            "\t\tTrain step - Step 8160, Loss 0.01435150858014822\n",
            "\t\tTrain step - Step 8190, Loss 0.01943417452275753\n",
            "\t\tTrain step - Step 8220, Loss 0.015846379101276398\n",
            "\t\tTrain step - Step 8250, Loss 0.018147386610507965\n",
            "\t\tTrain step - Step 8280, Loss 0.01660362258553505\n",
            "\t\tTrain step - Step 8310, Loss 0.01892058365046978\n",
            "\t\tTrain step - Step 8340, Loss 0.01781848818063736\n",
            "\t\tTrain step - Step 8370, Loss 0.015972912311553955\n",
            "\t\tTrain step - Step 8400, Loss 0.018843675032258034\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.01715512701875379 - Train Accuracy: 0.6875445156695157\n",
            "\t\t\tVal Loss: 0.024076567217707633 - Val Accuracy: 0.5584\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 8430, Loss 0.014953456819057465\n",
            "\t\tTrain step - Step 8460, Loss 0.018878715112805367\n",
            "\t\tTrain step - Step 8490, Loss 0.014733605086803436\n",
            "\t\tTrain step - Step 8520, Loss 0.01802377589046955\n",
            "\t\tTrain step - Step 8550, Loss 0.01723543554544449\n",
            "\t\tTrain step - Step 8580, Loss 0.016812089830636978\n",
            "\t\tTrain step - Step 8610, Loss 0.014056326821446419\n",
            "\t\tTrain step - Step 8640, Loss 0.013985618948936462\n",
            "\t\tTrain step - Step 8670, Loss 0.018600748851895332\n",
            "\t\tTrain step - Step 8700, Loss 0.015408007428050041\n",
            "\t\tTrain step - Step 8730, Loss 0.016649555414915085\n",
            "\t\tTrain step - Step 8760, Loss 0.01830953173339367\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.01716058252066204 - Train Accuracy: 0.6848513176638177\n",
            "\t\t\tVal Loss: 0.023531686118803918 - Val Accuracy: 0.5594\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 8790, Loss 0.015615582466125488\n",
            "\t\tTrain step - Step 8820, Loss 0.017824018374085426\n",
            "\t\tTrain step - Step 8850, Loss 0.019882189109921455\n",
            "\t\tTrain step - Step 8880, Loss 0.015283765271306038\n",
            "\t\tTrain step - Step 8910, Loss 0.019312169402837753\n",
            "\t\tTrain step - Step 8940, Loss 0.018722882494330406\n",
            "\t\tTrain step - Step 8970, Loss 0.02017209306359291\n",
            "\t\tTrain step - Step 9000, Loss 0.015360849909484386\n",
            "\t\tTrain step - Step 9030, Loss 0.015249188989400864\n",
            "\t\tTrain step - Step 9060, Loss 0.016855258494615555\n",
            "\t\tTrain step - Step 9090, Loss 0.01590440236032009\n",
            "\t\tTrain step - Step 9120, Loss 0.018844088539481163\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.017143830569445066 - Train Accuracy: 0.6873219373219374\n",
            "\t\t\tVal Loss: 0.024348242534324528 - Val Accuracy: 0.5462\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 9150, Loss 0.014220893383026123\n",
            "\t\tTrain step - Step 9180, Loss 0.015108875930309296\n",
            "\t\tTrain step - Step 9210, Loss 0.018721159547567368\n",
            "\t\tTrain step - Step 9240, Loss 0.016424093395471573\n",
            "\t\tTrain step - Step 9270, Loss 0.02017628215253353\n",
            "\t\tTrain step - Step 9300, Loss 0.01923959329724312\n",
            "\t\tTrain step - Step 9330, Loss 0.019145304337143898\n",
            "\t\tTrain step - Step 9360, Loss 0.018794052302837372\n",
            "\t\tTrain step - Step 9390, Loss 0.015165426768362522\n",
            "\t\tTrain step - Step 9420, Loss 0.015197014436125755\n",
            "\t\tTrain step - Step 9450, Loss 0.017316529527306557\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.017167882707256537 - Train Accuracy: 0.6868322649572649\n",
            "\t\t\tVal Loss: 0.024083034810610117 - Val Accuracy: 0.5596\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 9480, Loss 0.017181353643536568\n",
            "\t\tTrain step - Step 9510, Loss 0.013791178353130817\n",
            "\t\tTrain step - Step 9540, Loss 0.016662592068314552\n",
            "\t\tTrain step - Step 9570, Loss 0.01712586171925068\n",
            "\t\tTrain step - Step 9600, Loss 0.016221506521105766\n",
            "\t\tTrain step - Step 9630, Loss 0.01726222038269043\n",
            "\t\tTrain step - Step 9660, Loss 0.01699485443532467\n",
            "\t\tTrain step - Step 9690, Loss 0.016757870092988014\n",
            "\t\tTrain step - Step 9720, Loss 0.018358075991272926\n",
            "\t\tTrain step - Step 9750, Loss 0.01652117632329464\n",
            "\t\tTrain step - Step 9780, Loss 0.018168022856116295\n",
            "\t\tTrain step - Step 9810, Loss 0.015540208667516708\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.017097164722865293 - Train Accuracy: 0.6882345085470085\n",
            "\t\t\tVal Loss: 0.02501235839445144 - Val Accuracy: 0.5558\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 9840, Loss 0.017450625076889992\n",
            "\t\tTrain step - Step 9870, Loss 0.015741964802145958\n",
            "\t\tTrain step - Step 9900, Loss 0.020858125761151314\n",
            "\t\tTrain step - Step 9930, Loss 0.017442647367715836\n",
            "\t\tTrain step - Step 9960, Loss 0.016665756702423096\n",
            "\t\tTrain step - Step 9990, Loss 0.015653327107429504\n",
            "\t\tTrain step - Step 10020, Loss 0.018688427284359932\n",
            "\t\tTrain step - Step 10050, Loss 0.017446961253881454\n",
            "\t\tTrain step - Step 10080, Loss 0.018541239202022552\n",
            "\t\tTrain step - Step 10110, Loss 0.017548756673932076\n",
            "\t\tTrain step - Step 10140, Loss 0.020990289747714996\n",
            "\t\tTrain step - Step 10170, Loss 0.014392344281077385\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.017065964986774488 - Train Accuracy: 0.6889022435897436\n",
            "\t\t\tVal Loss: 0.02346017484087497 - Val Accuracy: 0.5764\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 10200, Loss 0.016685232520103455\n",
            "\t\tTrain step - Step 10230, Loss 0.018566574901342392\n",
            "\t\tTrain step - Step 10260, Loss 0.016396192833781242\n",
            "\t\tTrain step - Step 10290, Loss 0.020120859146118164\n",
            "\t\tTrain step - Step 10320, Loss 0.020543761551380157\n",
            "\t\tTrain step - Step 10350, Loss 0.017926311120390892\n",
            "\t\tTrain step - Step 10380, Loss 0.016312500461935997\n",
            "\t\tTrain step - Step 10410, Loss 0.019253963604569435\n",
            "\t\tTrain step - Step 10440, Loss 0.0177605040371418\n",
            "\t\tTrain step - Step 10470, Loss 0.01675695925951004\n",
            "\t\tTrain step - Step 10500, Loss 0.01771312952041626\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.017141237385316282 - Train Accuracy: 0.6854745370370371\n",
            "\t\t\tVal Loss: 0.024816225003451108 - Val Accuracy: 0.5502\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 10530, Loss 0.015941981226205826\n",
            "\t\tTrain step - Step 10560, Loss 0.015021062456071377\n",
            "\t\tTrain step - Step 10590, Loss 0.015893016010522842\n",
            "\t\tTrain step - Step 10620, Loss 0.015294081531465054\n",
            "\t\tTrain step - Step 10650, Loss 0.015622075647115707\n",
            "\t\tTrain step - Step 10680, Loss 0.01744656264781952\n",
            "\t\tTrain step - Step 10710, Loss 0.01805376261472702\n",
            "\t\tTrain step - Step 10740, Loss 0.01876707747578621\n",
            "\t\tTrain step - Step 10770, Loss 0.01802385225892067\n",
            "\t\tTrain step - Step 10800, Loss 0.01744292862713337\n",
            "\t\tTrain step - Step 10830, Loss 0.016604192554950714\n",
            "\t\tTrain step - Step 10860, Loss 0.020107492804527283\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.01717732341540845 - Train Accuracy: 0.6868767806267806\n",
            "\t\t\tVal Loss: 0.024677152559161187 - Val Accuracy: 0.5598\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 10890, Loss 0.015740789473056793\n",
            "\t\tTrain step - Step 10920, Loss 0.01455949991941452\n",
            "\t\tTrain step - Step 10950, Loss 0.01694146916270256\n",
            "\t\tTrain step - Step 10980, Loss 0.015314753167331219\n",
            "\t\tTrain step - Step 11010, Loss 0.01871880330145359\n",
            "\t\tTrain step - Step 11040, Loss 0.015913421288132668\n",
            "\t\tTrain step - Step 11070, Loss 0.016866862773895264\n",
            "\t\tTrain step - Step 11100, Loss 0.017905710265040398\n",
            "\t\tTrain step - Step 11130, Loss 0.016249865293502808\n",
            "\t\tTrain step - Step 11160, Loss 0.015388120897114277\n",
            "\t\tTrain step - Step 11190, Loss 0.017170235514640808\n",
            "\t\tTrain step - Step 11220, Loss 0.017904315143823624\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.017032671568549086 - Train Accuracy: 0.6892361111111112\n",
            "\t\t\tVal Loss: 0.023491445812396705 - Val Accuracy: 0.5672\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 11250, Loss 0.017889969050884247\n",
            "\t\tTrain step - Step 11280, Loss 0.015578947961330414\n",
            "\t\tTrain step - Step 11310, Loss 0.01643919199705124\n",
            "\t\tTrain step - Step 11340, Loss 0.0185646153986454\n",
            "\t\tTrain step - Step 11370, Loss 0.015839163213968277\n",
            "\t\tTrain step - Step 11400, Loss 0.017509229481220245\n",
            "\t\tTrain step - Step 11430, Loss 0.017753558233380318\n",
            "\t\tTrain step - Step 11460, Loss 0.020157262682914734\n",
            "\t\tTrain step - Step 11490, Loss 0.015941573306918144\n",
            "\t\tTrain step - Step 11520, Loss 0.016203679144382477\n",
            "\t\tTrain step - Step 11550, Loss 0.01887693628668785\n",
            "\t\tTrain step - Step 11580, Loss 0.018262013792991638\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.017004599521451357 - Train Accuracy: 0.689926103988604\n",
            "\t\t\tVal Loss: 0.02358850701712072 - Val Accuracy: 0.562\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 11610, Loss 0.01542732398957014\n",
            "\t\tTrain step - Step 11640, Loss 0.017557570710778236\n",
            "\t\tTrain step - Step 11670, Loss 0.01585138775408268\n",
            "\t\tTrain step - Step 11700, Loss 0.016456497833132744\n",
            "\t\tTrain step - Step 11730, Loss 0.016049329191446304\n",
            "\t\tTrain step - Step 11760, Loss 0.020645469427108765\n",
            "\t\tTrain step - Step 11790, Loss 0.015966396778821945\n",
            "\t\tTrain step - Step 11820, Loss 0.015941791236400604\n",
            "\t\tTrain step - Step 11850, Loss 0.019501464441418648\n",
            "\t\tTrain step - Step 11880, Loss 0.01566450484097004\n",
            "\t\tTrain step - Step 11910, Loss 0.016872014850378036\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.01707541761903936 - Train Accuracy: 0.6886351495726496\n",
            "\t\t\tVal Loss: 0.025416522333398462 - Val Accuracy: 0.5364\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 11940, Loss 0.015453198924660683\n",
            "\t\tTrain step - Step 11970, Loss 0.018539955839514732\n",
            "\t\tTrain step - Step 12000, Loss 0.017404139041900635\n",
            "\t\tTrain step - Step 12030, Loss 0.01672581396996975\n",
            "\t\tTrain step - Step 12060, Loss 0.0171408262103796\n",
            "\t\tTrain step - Step 12090, Loss 0.015482488088309765\n",
            "\t\tTrain step - Step 12120, Loss 0.017197292298078537\n",
            "\t\tTrain step - Step 12150, Loss 0.017518116161227226\n",
            "\t\tTrain step - Step 12180, Loss 0.013592708855867386\n",
            "\t\tTrain step - Step 12210, Loss 0.01547243818640709\n",
            "\t\tTrain step - Step 12240, Loss 0.020121967419981956\n",
            "\t\tTrain step - Step 12270, Loss 0.018958060070872307\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.017076883711812332 - Train Accuracy: 0.6889245014245015\n",
            "\t\t\tVal Loss: 0.02455030686687678 - Val Accuracy: 0.5602\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 12300, Loss 0.01771334931254387\n",
            "\t\tTrain step - Step 12330, Loss 0.016177866607904434\n",
            "\t\tTrain step - Step 12360, Loss 0.01668592356145382\n",
            "\t\tTrain step - Step 12390, Loss 0.013793406076729298\n",
            "\t\tTrain step - Step 12420, Loss 0.015607097186148167\n",
            "\t\tTrain step - Step 12450, Loss 0.019051682204008102\n",
            "\t\tTrain step - Step 12480, Loss 0.018120786175131798\n",
            "\t\tTrain step - Step 12510, Loss 0.01459251344203949\n",
            "\t\tTrain step - Step 12540, Loss 0.017563343048095703\n",
            "\t\tTrain step - Step 12570, Loss 0.020002026110887527\n",
            "\t\tTrain step - Step 12600, Loss 0.019718317314982414\n",
            "\t\tTrain step - Step 12630, Loss 0.018049251288175583\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.01695811491395928 - Train Accuracy: 0.6902822293447294\n",
            "\t\t\tVal Loss: 0.024643235187977553 - Val Accuracy: 0.552\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 12660, Loss 0.013283033855259418\n",
            "\t\tTrain step - Step 12690, Loss 0.015954148024320602\n",
            "\t\tTrain step - Step 12720, Loss 0.016633061692118645\n",
            "\t\tTrain step - Step 12750, Loss 0.017238957807421684\n",
            "\t\tTrain step - Step 12780, Loss 0.01423558872193098\n",
            "\t\tTrain step - Step 12810, Loss 0.01771160587668419\n",
            "\t\tTrain step - Step 12840, Loss 0.016943885013461113\n",
            "\t\tTrain step - Step 12870, Loss 0.015711842104792595\n",
            "\t\tTrain step - Step 12900, Loss 0.01816105656325817\n",
            "\t\tTrain step - Step 12930, Loss 0.01851607672870159\n",
            "\t\tTrain step - Step 12960, Loss 0.01677647978067398\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.016995048153073528 - Train Accuracy: 0.6894141737891738\n",
            "\t\t\tVal Loss: 0.029713015211746095 - Val Accuracy: 0.501\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 12990, Loss 0.016709569841623306\n",
            "\t\tTrain step - Step 13020, Loss 0.017409292981028557\n",
            "\t\tTrain step - Step 13050, Loss 0.01642352156341076\n",
            "\t\tTrain step - Step 13080, Loss 0.017189910635352135\n",
            "\t\tTrain step - Step 13110, Loss 0.018401434645056725\n",
            "\t\tTrain step - Step 13140, Loss 0.018393920734524727\n",
            "\t\tTrain step - Step 13170, Loss 0.01618300937116146\n",
            "\t\tTrain step - Step 13200, Loss 0.019587934017181396\n",
            "\t\tTrain step - Step 13230, Loss 0.01678829826414585\n",
            "\t\tTrain step - Step 13260, Loss 0.017229899764060974\n",
            "\t\tTrain step - Step 13290, Loss 0.01903718337416649\n",
            "\t\tTrain step - Step 13320, Loss 0.014920210465788841\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.01703813621652262 - Train Accuracy: 0.6894141737891738\n",
            "\t\t\tVal Loss: 0.025403871620073914 - Val Accuracy: 0.5482\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 13350, Loss 0.013581384904682636\n",
            "\t\tTrain step - Step 13380, Loss 0.016353879123926163\n",
            "\t\tTrain step - Step 13410, Loss 0.013924689032137394\n",
            "\t\tTrain step - Step 13440, Loss 0.017137538641691208\n",
            "\t\tTrain step - Step 13470, Loss 0.01707790605723858\n",
            "\t\tTrain step - Step 13500, Loss 0.014561564661562443\n",
            "\t\tTrain step - Step 13530, Loss 0.012960338033735752\n",
            "\t\tTrain step - Step 13560, Loss 0.01674610935151577\n",
            "\t\tTrain step - Step 13590, Loss 0.016076091676950455\n",
            "\t\tTrain step - Step 13620, Loss 0.016464948654174805\n",
            "\t\tTrain step - Step 13650, Loss 0.01685880683362484\n",
            "\t\tTrain step - Step 13680, Loss 0.018626166507601738\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.017043036931430514 - Train Accuracy: 0.6898370726495726\n",
            "\t\t\tVal Loss: 0.023686670302413403 - Val Accuracy: 0.572\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 13710, Loss 0.015440518967807293\n",
            "\t\tTrain step - Step 13740, Loss 0.015148324891924858\n",
            "\t\tTrain step - Step 13770, Loss 0.015343734994530678\n",
            "\t\tTrain step - Step 13800, Loss 0.01905098371207714\n",
            "\t\tTrain step - Step 13830, Loss 0.016760151833295822\n",
            "\t\tTrain step - Step 13860, Loss 0.018735207617282867\n",
            "\t\tTrain step - Step 13890, Loss 0.01632223278284073\n",
            "\t\tTrain step - Step 13920, Loss 0.018825044855475426\n",
            "\t\tTrain step - Step 13950, Loss 0.0179367046803236\n",
            "\t\tTrain step - Step 13980, Loss 0.020921912044286728\n",
            "\t\tTrain step - Step 14010, Loss 0.017344428226351738\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.016835951256934566 - Train Accuracy: 0.6914618945868946\n",
            "\t\t\tVal Loss: 0.026054762699641288 - Val Accuracy: 0.532\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 14040, Loss 0.017739752307534218\n",
            "\t\tTrain step - Step 14070, Loss 0.01505406852811575\n",
            "\t\tTrain step - Step 14100, Loss 0.016080697998404503\n",
            "\t\tTrain step - Step 14130, Loss 0.014670471660792828\n",
            "\t\tTrain step - Step 14160, Loss 0.01948331855237484\n",
            "\t\tTrain step - Step 14190, Loss 0.017064271494746208\n",
            "\t\tTrain step - Step 14220, Loss 0.018649818375706673\n",
            "\t\tTrain step - Step 14250, Loss 0.01612924411892891\n",
            "\t\tTrain step - Step 14280, Loss 0.018756231293082237\n",
            "\t\tTrain step - Step 14310, Loss 0.016152087599039078\n",
            "\t\tTrain step - Step 14340, Loss 0.018356870859861374\n",
            "\t\tTrain step - Step 14370, Loss 0.01874903216958046\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.01697383899018805 - Train Accuracy: 0.6885238603988604\n",
            "\t\t\tVal Loss: 0.023065617633983494 - Val Accuracy: 0.5782\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 14400, Loss 0.016617171466350555\n",
            "\t\tTrain step - Step 14430, Loss 0.014883286319673061\n",
            "\t\tTrain step - Step 14460, Loss 0.01616494171321392\n",
            "\t\tTrain step - Step 14490, Loss 0.01737014204263687\n",
            "\t\tTrain step - Step 14520, Loss 0.016995342448353767\n",
            "\t\tTrain step - Step 14550, Loss 0.016742384061217308\n",
            "\t\tTrain step - Step 14580, Loss 0.01657671295106411\n",
            "\t\tTrain step - Step 14610, Loss 0.01774446666240692\n",
            "\t\tTrain step - Step 14640, Loss 0.017962638288736343\n",
            "\t\tTrain step - Step 14670, Loss 0.019718622788786888\n",
            "\t\tTrain step - Step 14700, Loss 0.01947014406323433\n",
            "\t\tTrain step - Step 14730, Loss 0.019443446770310402\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.017011797464216535 - Train Accuracy: 0.6912838319088319\n",
            "\t\t\tVal Loss: 0.023071125033311546 - Val Accuracy: 0.5784\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 14760, Loss 0.015438749454915524\n",
            "\t\tTrain step - Step 14790, Loss 0.016300145536661148\n",
            "\t\tTrain step - Step 14820, Loss 0.016607675701379776\n",
            "\t\tTrain step - Step 14850, Loss 0.01891087181866169\n",
            "\t\tTrain step - Step 14880, Loss 0.018409663811326027\n",
            "\t\tTrain step - Step 14910, Loss 0.01953202486038208\n",
            "\t\tTrain step - Step 14940, Loss 0.01995839551091194\n",
            "\t\tTrain step - Step 14970, Loss 0.017411023378372192\n",
            "\t\tTrain step - Step 15000, Loss 0.019357427954673767\n",
            "\t\tTrain step - Step 15030, Loss 0.015384319238364697\n",
            "\t\tTrain step - Step 15060, Loss 0.019359104335308075\n",
            "\t\tTrain step - Step 15090, Loss 0.01711001992225647\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.01692934391059597 - Train Accuracy: 0.6903267450142451\n",
            "\t\t\tVal Loss: 0.02363405437208712 - Val Accuracy: 0.5674\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 15120, Loss 0.016373369842767715\n",
            "\t\tTrain step - Step 15150, Loss 0.01785273477435112\n",
            "\t\tTrain step - Step 15180, Loss 0.01712382771074772\n",
            "\t\tTrain step - Step 15210, Loss 0.016208965331315994\n",
            "\t\tTrain step - Step 15240, Loss 0.01706170290708542\n",
            "\t\tTrain step - Step 15270, Loss 0.01746375672519207\n",
            "\t\tTrain step - Step 15300, Loss 0.015361902303993702\n",
            "\t\tTrain step - Step 15330, Loss 0.0179288387298584\n",
            "\t\tTrain step - Step 15360, Loss 0.016944417729973793\n",
            "\t\tTrain step - Step 15390, Loss 0.020854134112596512\n",
            "\t\tTrain step - Step 15420, Loss 0.01761532574892044\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.016935277143838228 - Train Accuracy: 0.6908609330484331\n",
            "\t\t\tVal Loss: 0.021837331051938236 - Val Accuracy: 0.5954\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 15450, Loss 0.014341261237859726\n",
            "\t\tTrain step - Step 15480, Loss 0.018222570419311523\n",
            "\t\tTrain step - Step 15510, Loss 0.017568713054060936\n",
            "\t\tTrain step - Step 15540, Loss 0.017626594752073288\n",
            "\t\tTrain step - Step 15570, Loss 0.0160655714571476\n",
            "\t\tTrain step - Step 15600, Loss 0.017625940963625908\n",
            "\t\tTrain step - Step 15630, Loss 0.016162404790520668\n",
            "\t\tTrain step - Step 15660, Loss 0.018452133983373642\n",
            "\t\tTrain step - Step 15690, Loss 0.01874827966094017\n",
            "\t\tTrain step - Step 15720, Loss 0.01702284626662731\n",
            "\t\tTrain step - Step 15750, Loss 0.016664989292621613\n",
            "\t\tTrain step - Step 15780, Loss 0.017137734219431877\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.01697970834160038 - Train Accuracy: 0.6890803062678063\n",
            "\t\t\tVal Loss: 0.025789774954319 - Val Accuracy: 0.5456\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 15810, Loss 0.015099563635885715\n",
            "\t\tTrain step - Step 15840, Loss 0.014571156352758408\n",
            "\t\tTrain step - Step 15870, Loss 0.015535783022642136\n",
            "\t\tTrain step - Step 15900, Loss 0.016676710918545723\n",
            "\t\tTrain step - Step 15930, Loss 0.018519524484872818\n",
            "\t\tTrain step - Step 15960, Loss 0.015363097190856934\n",
            "\t\tTrain step - Step 15990, Loss 0.01608462817966938\n",
            "\t\tTrain step - Step 16020, Loss 0.014730613678693771\n",
            "\t\tTrain step - Step 16050, Loss 0.021965235471725464\n",
            "\t\tTrain step - Step 16080, Loss 0.015314864926040173\n",
            "\t\tTrain step - Step 16110, Loss 0.02065025456249714\n",
            "\t\tTrain step - Step 16140, Loss 0.016145292669534683\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.01693756051860389 - Train Accuracy: 0.6922186609686609\n",
            "\t\t\tVal Loss: 0.023370524402707815 - Val Accuracy: 0.5688\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 16170, Loss 0.016818618401885033\n",
            "\t\tTrain step - Step 16200, Loss 0.015744313597679138\n",
            "\t\tTrain step - Step 16230, Loss 0.018104713410139084\n",
            "\t\tTrain step - Step 16260, Loss 0.01554847601801157\n",
            "\t\tTrain step - Step 16290, Loss 0.012851780280470848\n",
            "\t\tTrain step - Step 16320, Loss 0.01709412969648838\n",
            "\t\tTrain step - Step 16350, Loss 0.016633793711662292\n",
            "\t\tTrain step - Step 16380, Loss 0.016874831169843674\n",
            "\t\tTrain step - Step 16410, Loss 0.017386136576533318\n",
            "\t\tTrain step - Step 16440, Loss 0.01822267659008503\n",
            "\t\tTrain step - Step 16470, Loss 0.018283380195498466\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.016904271494310636 - Train Accuracy: 0.6933538105413105\n",
            "\t\t\tVal Loss: 0.02480088237207383 - Val Accuracy: 0.5556\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 16500, Loss 0.015914592891931534\n",
            "\t\tTrain step - Step 16530, Loss 0.013771045953035355\n",
            "\t\tTrain step - Step 16560, Loss 0.01452353410422802\n",
            "\t\tTrain step - Step 16590, Loss 0.015587531961500645\n",
            "\t\tTrain step - Step 16620, Loss 0.017486009746789932\n",
            "\t\tTrain step - Step 16650, Loss 0.019942820072174072\n",
            "\t\tTrain step - Step 16680, Loss 0.017002249136567116\n",
            "\t\tTrain step - Step 16710, Loss 0.017121970653533936\n",
            "\t\tTrain step - Step 16740, Loss 0.016850564628839493\n",
            "\t\tTrain step - Step 16770, Loss 0.01992121897637844\n",
            "\t\tTrain step - Step 16800, Loss 0.018146274611353874\n",
            "\t\tTrain step - Step 16830, Loss 0.017277205362915993\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.016840818749363946 - Train Accuracy: 0.6938434829059829\n",
            "\t\t\tVal Loss: 0.024212186806835234 - Val Accuracy: 0.5548\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 16860, Loss 0.012857235036790371\n",
            "\t\tTrain step - Step 16890, Loss 0.01845691353082657\n",
            "\t\tTrain step - Step 16920, Loss 0.017322905361652374\n",
            "\t\tTrain step - Step 16950, Loss 0.015206729993224144\n",
            "\t\tTrain step - Step 16980, Loss 0.019038889557123184\n",
            "\t\tTrain step - Step 17010, Loss 0.015114709734916687\n",
            "\t\tTrain step - Step 17040, Loss 0.014572286047041416\n",
            "\t\tTrain step - Step 17070, Loss 0.016059204936027527\n",
            "\t\tTrain step - Step 17100, Loss 0.01471399050205946\n",
            "\t\tTrain step - Step 17130, Loss 0.018529072403907776\n",
            "\t\tTrain step - Step 17160, Loss 0.01716657541692257\n",
            "\t\tTrain step - Step 17190, Loss 0.015209885314106941\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.01689679577331088 - Train Accuracy: 0.6938657407407407\n",
            "\t\t\tVal Loss: 0.023301367065869272 - Val Accuracy: 0.5646\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 17220, Loss 0.01486501656472683\n",
            "\t\tTrain step - Step 17250, Loss 0.014089181087911129\n",
            "\t\tTrain step - Step 17280, Loss 0.01165903452783823\n",
            "\t\tTrain step - Step 17310, Loss 0.010918409563601017\n",
            "\t\tTrain step - Step 17340, Loss 0.011283952742815018\n",
            "\t\tTrain step - Step 17370, Loss 0.010476579889655113\n",
            "\t\tTrain step - Step 17400, Loss 0.012476036325097084\n",
            "\t\tTrain step - Step 17430, Loss 0.012697511352598667\n",
            "\t\tTrain step - Step 17460, Loss 0.012005805969238281\n",
            "\t\tTrain step - Step 17490, Loss 0.008955287747085094\n",
            "\t\tTrain step - Step 17520, Loss 0.012458163313567638\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.012597895795187549 - Train Accuracy: 0.781517094017094\n",
            "\t\t\tVal Loss: 0.017385872034355997 - Val Accuracy: 0.6764\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 17550, Loss 0.011693798936903477\n",
            "\t\tTrain step - Step 17580, Loss 0.013604983687400818\n",
            "\t\tTrain step - Step 17610, Loss 0.012455174699425697\n",
            "\t\tTrain step - Step 17640, Loss 0.012935852631926537\n",
            "\t\tTrain step - Step 17670, Loss 0.010717878118157387\n",
            "\t\tTrain step - Step 17700, Loss 0.011285948567092419\n",
            "\t\tTrain step - Step 17730, Loss 0.010190355591475964\n",
            "\t\tTrain step - Step 17760, Loss 0.010779480449855328\n",
            "\t\tTrain step - Step 17790, Loss 0.009245435707271099\n",
            "\t\tTrain step - Step 17820, Loss 0.009210892952978611\n",
            "\t\tTrain step - Step 17850, Loss 0.00910179503262043\n",
            "\t\tTrain step - Step 17880, Loss 0.012162444181740284\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.01121110006890915 - Train Accuracy: 0.8074029558404558\n",
            "\t\t\tVal Loss: 0.017159230494871735 - Val Accuracy: 0.6922\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 17910, Loss 0.010938053019344807\n",
            "\t\tTrain step - Step 17940, Loss 0.010087189264595509\n",
            "\t\tTrain step - Step 17970, Loss 0.010105926543474197\n",
            "\t\tTrain step - Step 18000, Loss 0.011013910174369812\n",
            "\t\tTrain step - Step 18030, Loss 0.011801623739302158\n",
            "\t\tTrain step - Step 18060, Loss 0.011218382976949215\n",
            "\t\tTrain step - Step 18090, Loss 0.011228793300688267\n",
            "\t\tTrain step - Step 18120, Loss 0.011052848771214485\n",
            "\t\tTrain step - Step 18150, Loss 0.008674963377416134\n",
            "\t\tTrain step - Step 18180, Loss 0.00980819296091795\n",
            "\t\tTrain step - Step 18210, Loss 0.01024844590574503\n",
            "\t\tTrain step - Step 18240, Loss 0.011499782092869282\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.010705986893351092 - Train Accuracy: 0.8152822293447294\n",
            "\t\t\tVal Loss: 0.01732460337225348 - Val Accuracy: 0.6848\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 18270, Loss 0.009401487186551094\n",
            "\t\tTrain step - Step 18300, Loss 0.01027336809784174\n",
            "\t\tTrain step - Step 18330, Loss 0.010757126845419407\n",
            "\t\tTrain step - Step 18360, Loss 0.011815451085567474\n",
            "\t\tTrain step - Step 18390, Loss 0.008203313685953617\n",
            "\t\tTrain step - Step 18420, Loss 0.01140535343438387\n",
            "\t\tTrain step - Step 18450, Loss 0.01024527009576559\n",
            "\t\tTrain step - Step 18480, Loss 0.010936154052615166\n",
            "\t\tTrain step - Step 18510, Loss 0.010071095079183578\n",
            "\t\tTrain step - Step 18540, Loss 0.008719374425709248\n",
            "\t\tTrain step - Step 18570, Loss 0.009634312242269516\n",
            "\t\tTrain step - Step 18600, Loss 0.00984247587621212\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.010443050537704147 - Train Accuracy: 0.8209802350427351\n",
            "\t\t\tVal Loss: 0.017159886355511845 - Val Accuracy: 0.6968\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 18630, Loss 0.010044174268841743\n",
            "\t\tTrain step - Step 18660, Loss 0.010835912078619003\n",
            "\t\tTrain step - Step 18690, Loss 0.011085140518844128\n",
            "\t\tTrain step - Step 18720, Loss 0.00932671781629324\n",
            "\t\tTrain step - Step 18750, Loss 0.008891534991562366\n",
            "\t\tTrain step - Step 18780, Loss 0.010265679098665714\n",
            "\t\tTrain step - Step 18810, Loss 0.013126487843692303\n",
            "\t\tTrain step - Step 18840, Loss 0.011519287712872028\n",
            "\t\tTrain step - Step 18870, Loss 0.009044689126312733\n",
            "\t\tTrain step - Step 18900, Loss 0.010595593601465225\n",
            "\t\tTrain step - Step 18930, Loss 0.008073593489825726\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.010243769922158402 - Train Accuracy: 0.8245414886039886\n",
            "\t\t\tVal Loss: 0.017124403663910926 - Val Accuracy: 0.6886\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 18960, Loss 0.00899500586092472\n",
            "\t\tTrain step - Step 18990, Loss 0.009041153825819492\n",
            "\t\tTrain step - Step 19020, Loss 0.008582726120948792\n",
            "\t\tTrain step - Step 19050, Loss 0.011043176054954529\n",
            "\t\tTrain step - Step 19080, Loss 0.010361268185079098\n",
            "\t\tTrain step - Step 19110, Loss 0.012268168851733208\n",
            "\t\tTrain step - Step 19140, Loss 0.008250338956713676\n",
            "\t\tTrain step - Step 19170, Loss 0.009656243957579136\n",
            "\t\tTrain step - Step 19200, Loss 0.01165547501295805\n",
            "\t\tTrain step - Step 19230, Loss 0.01257599238306284\n",
            "\t\tTrain step - Step 19260, Loss 0.011237476021051407\n",
            "\t\tTrain step - Step 19290, Loss 0.010498985648155212\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.01002854311790986 - Train Accuracy: 0.8272346866096866\n",
            "\t\t\tVal Loss: 0.017766414990182965 - Val Accuracy: 0.6764\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 19320, Loss 0.007185361348092556\n",
            "\t\tTrain step - Step 19350, Loss 0.009705089032649994\n",
            "\t\tTrain step - Step 19380, Loss 0.01031818799674511\n",
            "\t\tTrain step - Step 19410, Loss 0.010542773641645908\n",
            "\t\tTrain step - Step 19440, Loss 0.011282439343631268\n",
            "\t\tTrain step - Step 19470, Loss 0.007877230644226074\n",
            "\t\tTrain step - Step 19500, Loss 0.00987328216433525\n",
            "\t\tTrain step - Step 19530, Loss 0.011518825776875019\n",
            "\t\tTrain step - Step 19560, Loss 0.008703124709427357\n",
            "\t\tTrain step - Step 19590, Loss 0.009395088069140911\n",
            "\t\tTrain step - Step 19620, Loss 0.010177708230912685\n",
            "\t\tTrain step - Step 19650, Loss 0.010930395685136318\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.009900631482561683 - Train Accuracy: 0.8301504629629629\n",
            "\t\t\tVal Loss: 0.01809605918824673 - Val Accuracy: 0.6792\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 19680, Loss 0.010404631495475769\n",
            "\t\tTrain step - Step 19710, Loss 0.011613387614488602\n",
            "\t\tTrain step - Step 19740, Loss 0.00951196625828743\n",
            "\t\tTrain step - Step 19770, Loss 0.010105926543474197\n",
            "\t\tTrain step - Step 19800, Loss 0.007483945693820715\n",
            "\t\tTrain step - Step 19830, Loss 0.009318191558122635\n",
            "\t\tTrain step - Step 19860, Loss 0.010796899907290936\n",
            "\t\tTrain step - Step 19890, Loss 0.01045368891209364\n",
            "\t\tTrain step - Step 19920, Loss 0.008179150521755219\n",
            "\t\tTrain step - Step 19950, Loss 0.01145843230187893\n",
            "\t\tTrain step - Step 19980, Loss 0.00894832145422697\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.009755155124682986 - Train Accuracy: 0.8338007478632479\n",
            "\t\t\tVal Loss: 0.018379386980086565 - Val Accuracy: 0.6676\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 20010, Loss 0.010666503570973873\n",
            "\t\tTrain step - Step 20040, Loss 0.009402642957866192\n",
            "\t\tTrain step - Step 20070, Loss 0.009349262341856956\n",
            "\t\tTrain step - Step 20100, Loss 0.008823120035231113\n",
            "\t\tTrain step - Step 20130, Loss 0.008277316577732563\n",
            "\t\tTrain step - Step 20160, Loss 0.009652845561504364\n",
            "\t\tTrain step - Step 20190, Loss 0.01078060083091259\n",
            "\t\tTrain step - Step 20220, Loss 0.00826344732195139\n",
            "\t\tTrain step - Step 20250, Loss 0.010476457886397839\n",
            "\t\tTrain step - Step 20280, Loss 0.010068826377391815\n",
            "\t\tTrain step - Step 20310, Loss 0.008534382097423077\n",
            "\t\tTrain step - Step 20340, Loss 0.008371780626475811\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.009644806859988263 - Train Accuracy: 0.8352697649572649\n",
            "\t\t\tVal Loss: 0.017860816977918147 - Val Accuracy: 0.6736\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 20370, Loss 0.009826966561377048\n",
            "\t\tTrain step - Step 20400, Loss 0.009195476770401001\n",
            "\t\tTrain step - Step 20430, Loss 0.010898062027990818\n",
            "\t\tTrain step - Step 20460, Loss 0.008627585135400295\n",
            "\t\tTrain step - Step 20490, Loss 0.010963181965053082\n",
            "\t\tTrain step - Step 20520, Loss 0.008650507777929306\n",
            "\t\tTrain step - Step 20550, Loss 0.010304082185029984\n",
            "\t\tTrain step - Step 20580, Loss 0.008917275816202164\n",
            "\t\tTrain step - Step 20610, Loss 0.012094676494598389\n",
            "\t\tTrain step - Step 20640, Loss 0.009539616294205189\n",
            "\t\tTrain step - Step 20670, Loss 0.008907748386263847\n",
            "\t\tTrain step - Step 20700, Loss 0.009557848796248436\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.00951942397106407 - Train Accuracy: 0.8380742521367521\n",
            "\t\t\tVal Loss: 0.018383145309053363 - Val Accuracy: 0.675\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 20730, Loss 0.009392776526510715\n",
            "\t\tTrain step - Step 20760, Loss 0.009138541296124458\n",
            "\t\tTrain step - Step 20790, Loss 0.008939391933381557\n",
            "\t\tTrain step - Step 20820, Loss 0.008130250498652458\n",
            "\t\tTrain step - Step 20850, Loss 0.00982119981199503\n",
            "\t\tTrain step - Step 20880, Loss 0.010102620348334312\n",
            "\t\tTrain step - Step 20910, Loss 0.009006976149976254\n",
            "\t\tTrain step - Step 20940, Loss 0.010513095185160637\n",
            "\t\tTrain step - Step 20970, Loss 0.010194714181125164\n",
            "\t\tTrain step - Step 21000, Loss 0.009806804358959198\n",
            "\t\tTrain step - Step 21030, Loss 0.01023185346275568\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.00951967349918055 - Train Accuracy: 0.8370281339031339\n",
            "\t\t\tVal Loss: 0.017771834065206348 - Val Accuracy: 0.681\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 21060, Loss 0.00928649865090847\n",
            "\t\tTrain step - Step 21090, Loss 0.008540211245417595\n",
            "\t\tTrain step - Step 21120, Loss 0.008714364841580391\n",
            "\t\tTrain step - Step 21150, Loss 0.011563221924006939\n",
            "\t\tTrain step - Step 21180, Loss 0.0088283009827137\n",
            "\t\tTrain step - Step 21210, Loss 0.00756274675950408\n",
            "\t\tTrain step - Step 21240, Loss 0.007810264825820923\n",
            "\t\tTrain step - Step 21270, Loss 0.009845537133514881\n",
            "\t\tTrain step - Step 21300, Loss 0.00877191498875618\n",
            "\t\tTrain step - Step 21330, Loss 0.009512551128864288\n",
            "\t\tTrain step - Step 21360, Loss 0.011960756964981556\n",
            "\t\tTrain step - Step 21390, Loss 0.014197715558111668\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.009361076195249361 - Train Accuracy: 0.8398103632478633\n",
            "\t\t\tVal Loss: 0.018462758301757275 - Val Accuracy: 0.6752\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 21420, Loss 0.010291755199432373\n",
            "\t\tTrain step - Step 21450, Loss 0.011058865115046501\n",
            "\t\tTrain step - Step 21480, Loss 0.010343775153160095\n",
            "\t\tTrain step - Step 21510, Loss 0.009739801287651062\n",
            "\t\tTrain step - Step 21540, Loss 0.009139064699411392\n",
            "\t\tTrain step - Step 21570, Loss 0.00789683684706688\n",
            "\t\tTrain step - Step 21600, Loss 0.009759492240846157\n",
            "\t\tTrain step - Step 21630, Loss 0.009104502387344837\n",
            "\t\tTrain step - Step 21660, Loss 0.00715146167203784\n",
            "\t\tTrain step - Step 21690, Loss 0.009194540791213512\n",
            "\t\tTrain step - Step 21720, Loss 0.010054194368422031\n",
            "\t\tTrain step - Step 21750, Loss 0.010405335575342178\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.009408545456136818 - Train Accuracy: 0.8405893874643875\n",
            "\t\t\tVal Loss: 0.01847952075768262 - Val Accuracy: 0.674\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 21780, Loss 0.00770140253007412\n",
            "\t\tTrain step - Step 21810, Loss 0.00818995013833046\n",
            "\t\tTrain step - Step 21840, Loss 0.007097662892192602\n",
            "\t\tTrain step - Step 21870, Loss 0.009424407035112381\n",
            "\t\tTrain step - Step 21900, Loss 0.010313732549548149\n",
            "\t\tTrain step - Step 21930, Loss 0.01083680335432291\n",
            "\t\tTrain step - Step 21960, Loss 0.005681268870830536\n",
            "\t\tTrain step - Step 21990, Loss 0.01110705267637968\n",
            "\t\tTrain step - Step 22020, Loss 0.009151856414973736\n",
            "\t\tTrain step - Step 22050, Loss 0.012401697225868702\n",
            "\t\tTrain step - Step 22080, Loss 0.008429187349975109\n",
            "\t\tTrain step - Step 22110, Loss 0.010575584135949612\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.009309548943003699 - Train Accuracy: 0.8425703347578347\n",
            "\t\t\tVal Loss: 0.018521364335902034 - Val Accuracy: 0.6768\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 22140, Loss 0.009435085579752922\n",
            "\t\tTrain step - Step 22170, Loss 0.008222268894314766\n",
            "\t\tTrain step - Step 22200, Loss 0.009283638559281826\n",
            "\t\tTrain step - Step 22230, Loss 0.00890044029802084\n",
            "\t\tTrain step - Step 22260, Loss 0.006228554528206587\n",
            "\t\tTrain step - Step 22290, Loss 0.00595805374905467\n",
            "\t\tTrain step - Step 22320, Loss 0.007758807856589556\n",
            "\t\tTrain step - Step 22350, Loss 0.007269257679581642\n",
            "\t\tTrain step - Step 22380, Loss 0.007852637208998203\n",
            "\t\tTrain step - Step 22410, Loss 0.007849842309951782\n",
            "\t\tTrain step - Step 22440, Loss 0.008970769122242928\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.007955031314243874 - Train Accuracy: 0.8721955128205128\n",
            "\t\t\tVal Loss: 0.01703768246807158 - Val Accuracy: 0.6982\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 22470, Loss 0.006645703222602606\n",
            "\t\tTrain step - Step 22500, Loss 0.007331998087465763\n",
            "\t\tTrain step - Step 22530, Loss 0.0072708590887486935\n",
            "\t\tTrain step - Step 22560, Loss 0.008630911819636822\n",
            "\t\tTrain step - Step 22590, Loss 0.008331762626767159\n",
            "\t\tTrain step - Step 22620, Loss 0.00854679848998785\n",
            "\t\tTrain step - Step 22650, Loss 0.00516483886167407\n",
            "\t\tTrain step - Step 22680, Loss 0.007391782011836767\n",
            "\t\tTrain step - Step 22710, Loss 0.007932174019515514\n",
            "\t\tTrain step - Step 22740, Loss 0.007504178211092949\n",
            "\t\tTrain step - Step 22770, Loss 0.0073511335067451\n",
            "\t\tTrain step - Step 22800, Loss 0.008432239294052124\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.007533799022425528 - Train Accuracy: 0.8818554131054132\n",
            "\t\t\tVal Loss: 0.017083146166987716 - Val Accuracy: 0.6958\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 22830, Loss 0.007187237497419119\n",
            "\t\tTrain step - Step 22860, Loss 0.004635967314243317\n",
            "\t\tTrain step - Step 22890, Loss 0.008282472379505634\n",
            "\t\tTrain step - Step 22920, Loss 0.008717156015336514\n",
            "\t\tTrain step - Step 22950, Loss 0.007470929995179176\n",
            "\t\tTrain step - Step 22980, Loss 0.00580103462561965\n",
            "\t\tTrain step - Step 23010, Loss 0.007710042875260115\n",
            "\t\tTrain step - Step 23040, Loss 0.006960717961192131\n",
            "\t\tTrain step - Step 23070, Loss 0.008952549658715725\n",
            "\t\tTrain step - Step 23100, Loss 0.0067079197615385056\n",
            "\t\tTrain step - Step 23130, Loss 0.007344934623688459\n",
            "\t\tTrain step - Step 23160, Loss 0.005800486076623201\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.007341205450225929 - Train Accuracy: 0.8851495726495726\n",
            "\t\t\tVal Loss: 0.016903774440288545 - Val Accuracy: 0.6998\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 23190, Loss 0.007067887112498283\n",
            "\t\tTrain step - Step 23220, Loss 0.007666626013815403\n",
            "\t\tTrain step - Step 23250, Loss 0.008575472049415112\n",
            "\t\tTrain step - Step 23280, Loss 0.007403039839118719\n",
            "\t\tTrain step - Step 23310, Loss 0.006147926207631826\n",
            "\t\tTrain step - Step 23340, Loss 0.00626138923689723\n",
            "\t\tTrain step - Step 23370, Loss 0.006612772587686777\n",
            "\t\tTrain step - Step 23400, Loss 0.007100733462721109\n",
            "\t\tTrain step - Step 23430, Loss 0.007144748233258724\n",
            "\t\tTrain step - Step 23460, Loss 0.007969154044985771\n",
            "\t\tTrain step - Step 23490, Loss 0.006460191681981087\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.007246551910505506 - Train Accuracy: 0.8861734330484331\n",
            "\t\t\tVal Loss: 0.0170826674439013 - Val Accuracy: 0.6968\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 23520, Loss 0.005861809942871332\n",
            "\t\tTrain step - Step 23550, Loss 0.00817274209111929\n",
            "\t\tTrain step - Step 23580, Loss 0.008361443877220154\n",
            "\t\tTrain step - Step 23610, Loss 0.00826309248805046\n",
            "\t\tTrain step - Step 23640, Loss 0.0077536264434456825\n",
            "\t\tTrain step - Step 23670, Loss 0.006865671835839748\n",
            "\t\tTrain step - Step 23700, Loss 0.007544520311057568\n",
            "\t\tTrain step - Step 23730, Loss 0.008740364573895931\n",
            "\t\tTrain step - Step 23760, Loss 0.008156165480613708\n",
            "\t\tTrain step - Step 23790, Loss 0.007251508068293333\n",
            "\t\tTrain step - Step 23820, Loss 0.006227312609553337\n",
            "\t\tTrain step - Step 23850, Loss 0.006933512166142464\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.0071703154511452575 - Train Accuracy: 0.8880876068376068\n",
            "\t\t\tVal Loss: 0.01709652100689709 - Val Accuracy: 0.6962\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 23880, Loss 0.005493004806339741\n",
            "\t\tTrain step - Step 23910, Loss 0.007383421529084444\n",
            "\t\tTrain step - Step 23940, Loss 0.007211330346763134\n",
            "\t\tTrain step - Step 23970, Loss 0.007179840002208948\n",
            "\t\tTrain step - Step 24000, Loss 0.007697587832808495\n",
            "\t\tTrain step - Step 24030, Loss 0.007903773337602615\n",
            "\t\tTrain step - Step 24060, Loss 0.008134696632623672\n",
            "\t\tTrain step - Step 24090, Loss 0.008071644231677055\n",
            "\t\tTrain step - Step 24120, Loss 0.006646046880632639\n",
            "\t\tTrain step - Step 24150, Loss 0.00824583787471056\n",
            "\t\tTrain step - Step 24180, Loss 0.005970210302621126\n",
            "\t\tTrain step - Step 24210, Loss 0.006921547465026379\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.007047657631974445 - Train Accuracy: 0.8916488603988604\n",
            "\t\t\tVal Loss: 0.01677190619520843 - Val Accuracy: 0.7004\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 24240, Loss 0.006743564270436764\n",
            "\t\tTrain step - Step 24270, Loss 0.007546395994722843\n",
            "\t\tTrain step - Step 24300, Loss 0.005607956554740667\n",
            "\t\tTrain step - Step 24330, Loss 0.005824523977935314\n",
            "\t\tTrain step - Step 24360, Loss 0.0076324474066495895\n",
            "\t\tTrain step - Step 24390, Loss 0.006114381831139326\n",
            "\t\tTrain step - Step 24420, Loss 0.00618228642269969\n",
            "\t\tTrain step - Step 24450, Loss 0.007468725088983774\n",
            "\t\tTrain step - Step 24480, Loss 0.007394356653094292\n",
            "\t\tTrain step - Step 24510, Loss 0.007683166302740574\n",
            "\t\tTrain step - Step 24540, Loss 0.008008607663214207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/79 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.006924305851451862 - Train Accuracy: 0.8936965811965812\n",
            "\t\t\tVal Loss: 0.01733816529158503 - Val Accuracy: 0.693\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [00:02<00:00, 26.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 10:\n",
            "\t\tTrain Mean Accuracy: 0.7324093152218152\n",
            "\t\tVal Mean Accuracy: 0.5933714285714285\n",
            "\t\tTest Accuracy: 0.6996\n",
            "\n",
            "\n",
            "JOINT TRAININGTotal time: 129 min 22 sec\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciGlvEWabcbD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa25848d-1faf-4a7a-a7e0-60672a6fd9c8"
      },
      "source": [
        "import libs.plots as plots\n",
        "\n",
        "method = TRAINING_TYPE\n",
        "plots.plot_accuracy_trend(test_accuracies, method, SEED)\n",
        "plots.plot_confusion_matrix(y_true, y_preds, method, SEED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amC8Qy-yVw8W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d550a94d-0dec-44aa-c30e-136db07e4e2b"
      },
      "source": [
        "def save_accuracies(train_accuracies, val_accuracies, test_accuracies, output=OUTPUT_PATH):\n",
        "  with open(f\"{output}_accuracies.csv\", \"w\", encoding=\"utf8\") as f:\n",
        "    f.write(\"mean_train_acc,mean_val_acc,test_acc\\n\")\n",
        "    for train, val, test in zip(train_accuracies, val_accuracies, test_accuracies):\n",
        "      f.write(f\"{train},{val},{test}\\n\")\n",
        "    print(\"********** FILE SAVED **********\")\n",
        "\n",
        "\n",
        "save_accuracies(train_accuracies, val_accuracies, test_accuracies)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "********** FILE SAVED **********\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}